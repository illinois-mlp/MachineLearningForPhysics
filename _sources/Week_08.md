# <span style="color: blue;"><b>Attention Mechanism and Transformers</b></span>

## *Overview*
You will learn the basics of Attention Mechanism and Transformers

## *Goals*
* Learn about Attention Mechanism and Transformers

## *Lecture Materials*
* [Slides](https://docs.google.com/presentation/d/1ZHuK7TopASFSoyUoELKeCGT8bullhtSLcEkrp4ZueGg/edit?usp=sharing)
* {doc}`lectures/Attention`
* {doc}`lectures/Transformers`
* {doc}`lectures/VisionTransformer`

## *Homework Assignment*
* None

## *Supplemental Readings*
* [Attention Is All You Need](https://arxiv.org/abs/1706.03762)
* [Neural Machine Translation By Jointly Learning To Align and Translate](https://arxiv.org/pdf/1409.0473)
* [Transformer: A Novel Neural Network Architecture for Language Understanding (Jakob Uszkoreit, 2017)](https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html) - The original Google blog post about the Transformer paper, focusing on the application in machine translation.
* [The Illustrated Transformer (Jay Alammar, 2018)](http://jalammar.github.io/illustrated-transformer/)
* [Attention? Attention! (Lilian Weng, 2018)](https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html)
* [Illustrated: Self-Attention (Raimi Karim, 2019)](https://towardsdatascience.com/illustrated-self-attention-2d627e33b20a)
* [The Transformer family (Lilian Weng, 2020)](https://lilianweng.github.io/lil-log/2020/04/07/the-transformer-family.html)