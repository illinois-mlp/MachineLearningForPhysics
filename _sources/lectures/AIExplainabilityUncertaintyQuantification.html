

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>AI Explainability and Uncertainty Quantification &#8212; PHYS 498 MLP</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_sources/lectures/AIExplainabilityUncertaintyQuantification';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Homework 08: Detecting Distribution Shift on MNIST using Bayesian Neural Networks" href="../homework/Homework_08.html" />
    <link rel="prev" title="AI Explainablility and Uncertainty Quantification" href="../Week_11.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.png" class="logo__image only-light" alt="PHYS 498 MLP - Home"/>
    <script>document.write(`<img src="../../_static/logo.png" class="logo__image only-dark" alt="PHYS 498 MLP - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    <span style="color:Blue">Machine Learning for Physics</span>
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_01.html"><span style="color: blue;"><b>Introduction to Data Science</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1cQJycGyQ07qSOoeskr6GjjTD3byIkxDbdi228NRgFeU/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="JupyterNumpy.html">Jupyter Notebooks and Numerical Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="Pandas.html">Handling Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="Visualization.html">Visualizing Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="Clustering.html">Finding Structure in Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="Dimensionality.html">Measuring and Reducing Dimensionality</a></li>
<li class="toctree-l2"><a class="reference internal" href="Nonlinear.html">Adapting Linear Methods to Non-Linear Data and Kernel Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_01.html">Homework 01: Introduction to Data Science</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_02.html"><span style="color: blue;"><b>Probability Theory and Density Estimation</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1o9tM9ppKZWIa9B3WIHy5JDF4myR5NkO02W6WAlyiTSg/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="ProbabilityTheory.html">Probability Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="ProbabilityDistributions.html">Important Probability Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="DensityEstimation.html">Estimating Probability Density from Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_02.html">Homework 02: Probability Theory and Density Estimation</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_03.html"><span style="color: blue;"><b>Bayesian Statistics I</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1h2SMuH-Z5a_OE6UMDbFjysEiL2NmYT1tGww6VF5jzsA/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="Statistics.html">Statistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="BayesianInference.html">Bayesian Statistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="MarkovChainMonteCarlo.html">Markov Chain Monte Carlo in Practice</a></li>
<li class="toctree-l2"><a class="reference internal" href="MarkovChains.html">Stochastic Processes and Markov-Chain Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_03.html">Homework 03: Bayesian Statistics and Markov Chains</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_04.html"><span style="color: blue;"><b>Bayesian Statistics II</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/18bft9_CiBLjjBy0MHvT_vN7E95kfakvhm_7d7WKHXyY/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="ModelSelection.html">Bayesian Model Selection</a></li>
<li class="toctree-l2"><a class="reference internal" href="VariationalInference.html">Variational Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="Optimization.html">Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="CrossValidation.html">Cross Validation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_04.html">Homework 04: Metropolis-Hastings and Cross Validation</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_05.html"><span style="color: blue;"><b>Introduction to Artificial Intelligence</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1by3-6jDEorKi7_WEr6PTMfEBE8f4xrS94fNdtSuATVg/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="SupervisedLearning.html">Supervised Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="Learning.html">Artificial Intelligence and Machine Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="ArtificialNeuralNetworks.html">Artificial Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="DeepLearning.html">Deep Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_05.html">Homework 05: Artificial Neural Networks</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_06.html"><span style="color: blue;"><b>Convolutional and Recurrent Neural Networks</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1cDFVtEVGLaWd4256OShSb3Roto0x4y4GwG6LkhVozg0/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="ConvolutionalRecurrentNeuralNetworks.html">Convolutional and Recurrent Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_06.html">Homework 06: Forecasting Projectile Motion with Recurrent Neural Networks</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_07.html"><span style="color: blue;"><b>Geometric Deep Learning and Graph Neural Networks</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1jK61M3QGH7bxFU7TMBm16G3YDb-7HOFtgNdqlj3Gs38/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="GraphNeuralNetworks.html">Geometric Deep Learning and Graph Neural Networks</a></li>





</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_08.html"><span style="color: blue;"><b>Attention Mechanism and Transformers</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1ZHuK7TopASFSoyUoELKeCGT8bullhtSLcEkrp4ZueGg/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="Attention.html">Attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="Transformers.html">Transformers</a></li>
<li class="toctree-l2"><a class="reference internal" href="VisionTransformer.html">Vision Transformer</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Project_01.html"><span style="color: blue;"><b>Project 01</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_01_HiggsTauTau.html">Higgs Boson Decaying to Tau Leptons</a></li>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_01_ExoticParticles.html">Searching for Exotic Particles</a></li>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_01_GalaxyZoo.html">Galaxy Zoo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_01_NuclearGeometryQGP.html">Nuclear Geometry and Characterization of the Quark Gluon Plasma</a></li>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_01_AberratedImages.html">Aberrated Image Recovery of Ultracold Atoms</a></li>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_01_DarkEnergySurvey.html">Dark Energy Survey</a></li>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_01_GravitationalWaves.html">Detection of Gravitational Waves</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_09.html"><span style="color: blue;"><b>Generative Modeling and Simulation-Based Inference</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1h13YeUjtTU_WHLxghxFBBQJO3uRr1GtsIyO4DVZviJo/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="GenerativeModeling.html">Generative Modeling</a></li>
<li class="toctree-l2"><a class="reference internal" href="AutoEncoders.html">Autoencoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="VariationalAutoEncoders.html">Variational AutoEncoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="GenerativeAdversarialNetworks.html">Generative Adversarial Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="Diffusion.html">Diffusion Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="NormalizingFlows.html">Normalizing Flows</a></li>
<li class="toctree-l2"><a class="reference internal" href="SimulationBasedInference.html">Simulation Based Inference</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_10.html"><span style="color: blue;"><b>Reinforcement Learning</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1EsW71u3hdNdXyhlDfkmOX__9c4wJZUee_pjlsmlv_Vg/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="ReinforcementLearning.html">Reinforcement Learning</a></li>




<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_07.html">Homework 07: Reinforcement Learning: Implementing a Deep Q-Network</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../Week_11.html"><span style="color: blue;"><b>AI Explainablility and Uncertainty Quantification</b></span></a><input checked="" class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1ydzY7IEYzALTR6ez5gvwwKDduf_7wUtZddq0SUSuvI0/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">AI Explainability and Uncertainty Quantification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_08.html">Homework 08: Detecting Distribution Shift on MNIST using Bayesian Neural Networks</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_12.html"><span style="color: blue;"><b>Unsupervised Learning and Anomaly Detection</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1ydzY7IEYzALTR6ez5gvwwKDduf_7wUtZddq0SUSuvI0/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="UnsupervisedLearningAnomalyDetection.html">Unsupervised Learning and Anomaly Detection</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_13.html"><span style="color: blue;"><b>Physics Informed Neural Networks</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1C-Z8b6WP5rE8yohZQdSxyH8O_bHIbllq97QhEJYyh0w/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="PhysicsInformedNeuralNetworks.html">Physics Informed Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="LearningTheSchrodingerEquation.html">Solving the Time Dependent Schrodinger Equation with Physics-Informed Deep Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="SymbolicRegression.html">Introduction to Symbolic Regression</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Project_02.html"><span style="color: blue;"><b>Project 02</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_02_AnisotropyQGP.html">Anisotropy in the Quark Gluon Plasma</a></li>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_02_AberratedImages.html">Aberrated Image Recovery of Ultracold Atoms</a></li>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_02_Radiotherapy.html">Beam Angle Optimization for Radiative Cancer Therapy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_02_TailPulsePileupRejection.html">Precision Neutron Counting with Tail Pulse Pileup Rejection</a></li>






<li class="toctree-l2"><a class="reference internal" href="../projects/Project_02_BentPipeSurrogate.html">Fluid Dynamics of a Bent Pipe</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_14.html"><span style="color: blue;"><b>Learning from the Machines</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1hkfaU7JVy1f5S8jURZvTY67KRzP7I8zGRf4Zku_bpM4/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="LearningPhysicsMachines.html">Learning Physics from the Machines</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_15.html"><span style="color: blue;"><b>Future of AI and Physics: What Lies Ahead?</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-17"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1eB1qCn5J07D5he_DCpkBiKjbVjdI6OexUzMQ351GCaI/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="LookingForward.html">Future of AI and Physics: What Lies Ahead?</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/illinois-mlp/MachineLearningForPhysics/blob/main/_sources/lectures/AIExplainabilityUncertaintyQuantification.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>



<a href="https://github.com/illinois-mlp/MachineLearningForPhysics" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/_sources/lectures/AIExplainabilityUncertaintyQuantification.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>AI Explainability and Uncertainty Quantification</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-overview-span"><span style="color:Orange">Overview</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-simulate-data-span"><span style="color:Orange">Simulate Data</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-define-non-bayesian-neural-network-span"><span style="color:Orange">Define non-Bayesian Neural Network</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-train-one-deterministic-nn-span"><span style="color:Orange">Train one deterministic NN</span></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-training-span"><span style="color:LightGreen">Training</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-evaluate-span"><span style="color:LightGreen">Evaluate</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-deep-ensemble-span"><span style="color:Orange">Deep Ensemble</span></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1"><span style="color:LightGreen">Training</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2"><span style="color:LightGreen">Evaluate</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-monte-carlo-dropout-span"><span style="color:Orange">Monte Carlo Dropout</span></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3"><span style="color:LightGreen">Training</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4"><span style="color:LightGreen">Evaluate</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-conformal-prediction-span"><span style="color:Orange">Conformal Prediction</span></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5"><span style="color:LightGreen">Training</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6"><span style="color:LightGreen">Evaluate</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-bayesian-neural-networks-span"><span style="color:Orange">Bayesian Neural Networks</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id7"><span style="color:Orange">Simulate data</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-getting-started-with-pyro-span"><span style="color:Orange">Getting Started with Pyro</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-bayesian-neural-network-with-gaussian-prior-and-likelihood-span"><span style="color:Orange">Bayesian Neural Network with Gaussian Prior and Likelihood</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-define-and-run-markov-chain-monte-carlo-sampler-span"><span style="color:Orange">Define and run Markov chain Monte Carlo sampler</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-exercise-1-deep-bayesian-neural-network-span"><span style="color:Orange"> Exercise 1: Deep Bayesian Neural Network</span></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-train-the-deep-bnn-with-mcmc-span"><span style="color:LightGreen">Train the deep BNN with MCMC</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-compute-predictive-distribution-span"><span style="color:LightGreen">Compute predictive distribution</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-train-bnns-with-mean-field-variational-inference-span"><span style="color:LightGreen">Train BNNs with mean-field variational inference</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-exercise-2-bayesian-updating-with-variational-inference-span"><span style="color:Orange">Exercise 2: Bayesian updating with variational inference</span></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-bayesian-update-span"><span style="color:LightGreen">Bayesian update</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-implementation-in-pyro-span"><span style="color:LightGreen">Implementation in Pyro</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-exercise-2-1-learn-a-model-on-the-old-observations-span"><span style="color:LightGreen">Exercise 2.1 Learn a model on the old observations</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-exercise-2-2-initialize-a-second-model-with-the-variational-parameters-span"><span style="color:LightGreen">Exercise 2.2 Initialize a second model with the variational parameters</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-exercise-2-3-perform-variational-inference-on-the-new-model-span"><span style="color:LightGreen">Exercise 2.3 Perform variational inference on the new model</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id8"></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-acknowledgments-span"><span style="color:Orange">Acknowledgments</span></a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="ai-explainability-and-uncertainty-quantification">
<h1>AI Explainability and Uncertainty Quantification<a class="headerlink" href="#ai-explainability-and-uncertainty-quantification" title="Permalink to this heading">#</a></h1>
<section id="span-style-color-orange-overview-span">
<h2><span style="color:Orange">Overview</span><a class="headerlink" href="#span-style-color-orange-overview-span" title="Permalink to this heading">#</a></h2>
<p>In this lecture, we will investigate what are some benefits of <span style="color:violet">Bayesian Neural Networks</span> (BNN) over point estimate Neural Networks. We will also look at other uncertainty quantification methods, including conformal prediction.</p>
<p>Import standard libraries and setting random seeds for reproducibility.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tqdm.auto</span><span class="w"> </span><span class="kn">import</span> <span class="n">trange</span><span class="p">,</span> <span class="n">tqdm</span>

<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="span-style-color-orange-simulate-data-span">
<h2><span style="color:Orange">Simulate Data</span><a class="headerlink" href="#span-style-color-orange-simulate-data-span" title="Permalink to this heading">#</a></h2>
<p>Let’s simulate a wiggly line and draw observations in separated regions…</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_simple_data_train</span><span class="p">():</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">.2</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">.6</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">500</span><span class="p">)])</span>
    <span class="n">eps</span> <span class="o">=</span> <span class="mf">0.02</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="mf">0.3</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">eps</span><span class="p">))</span> <span class="o">+</span> <span class="mf">0.3</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">4</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">eps</span><span class="p">))</span> <span class="o">+</span> <span class="n">eps</span>
    <span class="n">x_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()[:,</span> <span class="kc">None</span><span class="p">]</span>
    <span class="n">y_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">plot_generic</span><span class="p">(</span><span class="n">add_to_plot</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Y&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>

    <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">get_simple_data_train</span><span class="p">()</span>
    
    <span class="n">x_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
    <span class="n">y_true</span> <span class="o">=</span> <span class="n">x_true</span> <span class="o">+</span> <span class="mf">0.3</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">x_true</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.3</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">4</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">x_true</span><span class="p">)</span>
    
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="s1">&#39;ko&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;observations&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_true</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="s1">&#39;b-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;true function&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">add_to_plot</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">add_to_plot</span><span class="p">(</span><span class="n">ax</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">frameon</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_generic</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/4b7983cb6186853da8711ffaf5868c13eea7566b74ed05b648d31f633b810585.png" src="../../_images/4b7983cb6186853da8711ffaf5868c13eea7566b74ed05b648d31f633b810585.png" />
</div>
</div>
<p>As you can see, we have the true function in blue. The observations are observable in two regions of the function and there is some noise in their measurement. We will use this simple data to showcase the differences between BNNs and deterministic NNs.</p>
</section>
<section id="span-style-color-orange-define-non-bayesian-neural-network-span">
<h2><span style="color:Orange">Define non-Bayesian Neural Network</span><a class="headerlink" href="#span-style-color-orange-define-non-bayesian-neural-network-span" title="Permalink to this heading">#</a></h2>
<p>First let’s create our point estimate neural network, in other words a standard fully connected MLP. We will define the number of hidden layers dynamically so we can reuse the same class for different depths.  We will also add a <em><strong><span style="color:violet">dropout</span></strong></em> flag, this will allow us to easily use the same architecture for our BNN.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">MLP</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_hidden_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">use_dropout</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">use_dropout</span> <span class="o">=</span> <span class="n">use_dropout</span>
        <span class="k">if</span> <span class="n">use_dropout</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()</span>

        <span class="c1"># dynamically define architecture</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="n">input_dim</span><span class="p">]</span> <span class="o">+</span> <span class="n">n_hidden_layers</span> <span class="o">*</span> <span class="p">[</span><span class="n">hidden_dim</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">output_dim</span><span class="p">]</span>
        <span class="n">layer_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layer_sizes</span><span class="p">[</span><span class="n">idx</span> <span class="o">-</span> <span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_sizes</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span>
                      <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layer_sizes</span><span class="p">))]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">layer_list</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="nb">input</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
            <span class="n">hidden_temp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">layer</span><span class="p">(</span><span class="n">hidden</span><span class="p">))</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_dropout</span><span class="p">:</span>
                <span class="n">hidden_temp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">hidden_temp</span><span class="p">)</span>

            <span class="n">hidden</span> <span class="o">=</span> <span class="n">hidden_temp</span> <span class="o">+</span> <span class="n">hidden</span>  <span class="c1"># residual connection</span>

        <span class="n">output_mean</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">](</span><span class="n">hidden</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">output_mean</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="span-style-color-orange-train-one-deterministic-nn-span">
<h2><span style="color:Orange">Train one deterministic NN</span><a class="headerlink" href="#span-style-color-orange-train-one-deterministic-nn-span" title="Permalink to this heading">#</a></h2>
<section id="span-style-color-lightgreen-training-span">
<h3><span style="color:LightGreen">Training</span><a class="headerlink" href="#span-style-color-lightgreen-training-span" title="Permalink to this heading">#</a></h3>
<p>Now let’s train our MLP with the training data we generated above:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">train_data</span><span class="p">):</span>
    <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">train_data</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>

    <span class="n">progress_bar</span> <span class="o">=</span> <span class="n">trange</span><span class="p">(</span><span class="mi">3000</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">progress_bar</span><span class="p">:</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">net</span><span class="p">(</span><span class="n">x_train</span><span class="p">))</span>
        <span class="n">progress_bar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">loss</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">net</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_data</span> <span class="o">=</span> <span class="n">get_simple_data_train</span><span class="p">()</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mi">3000</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>  <span class="c1"># test over the whole range</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">(</span><span class="n">hidden_dim</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">n_hidden_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">train_data</span><span class="p">)</span>
<span class="n">y_preds</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "b98d48a50fcd41b7842921d7c43a7050", "version_major": 2, "version_minor": 0}</script></div>
</div>
</section>
<section id="span-style-color-lightgreen-evaluate-span">
<h3><span style="color:LightGreen">Evaluate</span><a class="headerlink" href="#span-style-color-lightgreen-evaluate-span" title="Permalink to this heading">#</a></h3>
<p>Let’s investigate how our deterministic MLP generalizes over the entire domain of our input variable <span class="math notranslate nohighlight">\(x\)</span> (the model was only trained on the observations, now we will also pass in data outside this region)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">plot_predictions</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_preds</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">add_predictions</span><span class="p">(</span><span class="n">ax</span><span class="p">):</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_preds</span><span class="p">,</span> <span class="s1">&#39;r-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;neural net prediction&#39;</span><span class="p">)</span>

    <span class="n">plot_generic</span><span class="p">(</span><span class="n">add_predictions</span><span class="p">)</span>
<span class="n">plot_predictions</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_preds</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/1556401259bc6bbdcb7d45194ffc21af33f5773a2a316a60f86c7047f2392456.png" src="../../_images/1556401259bc6bbdcb7d45194ffc21af33f5773a2a316a60f86c7047f2392456.png" />
</div>
</div>
<p>We can see that our deterministic MLP (red line) has correctly learned the data distribution in the training regions, however, as the model has not learned the underlying sinusoidal wave function, it’s predictions outside the training region are inaccurate. As our MLP is a point estimate NN we have no measure confidence in the predictions outside the training region. In the upcoming sections let’s see how this compares to BNN.</p>
</section>
</section>
<section id="span-style-color-orange-deep-ensemble-span">
<h2><span style="color:Orange">Deep Ensemble</span><a class="headerlink" href="#span-style-color-orange-deep-ensemble-span" title="Permalink to this heading">#</a></h2>
<p>Deep ensembles were first introduced by <a class="reference external" href="https://arxiv.org/abs/1612.01474">Lakshminarayanan et al. (2017)</a>. As the name implies multiple point estimate NN are trained, <em><strong><span style="color:violet">an ensemble</span></strong></em>, and the final prediction is computed as an average across the models. From a Bayesian perspective the different point estimates correspond to modes of a Bayesian posterior. This can be interpreted as approximating the posterior with a distribution parametrized as multiple Dirac deltas:</p>
<div class="math notranslate nohighlight">
\[ \Large
q_{\phi}(\theta | D) = \sum_{\theta_{i} ∈ ϕ} \alpha_{\theta_{i}} δ_{\theta_{i}}(\theta)
\]</div>
<p>where <span class="math notranslate nohighlight">\(\alpha_{\theta_{i}}\)</span> are positive constants such that their sum is equal to one.</p>
<section id="id1">
<h3><span style="color:LightGreen">Training</span><a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h3>
<p>We will reuse the MLP architecture introduced before, simply now we will train an ensemble of such models</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ensemble_size</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">ensemble</span> <span class="o">=</span> <span class="p">[</span><span class="n">MLP</span><span class="p">(</span><span class="n">hidden_dim</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">n_hidden_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ensemble_size</span><span class="p">)]</span>
<span class="k">for</span> <span class="n">net</span> <span class="ow">in</span> <span class="n">ensemble</span><span class="p">:</span>
    <span class="n">train</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">train_data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "436de84a1f2c4b15a7e26bc6ce38f61f", "version_major": 2, "version_minor": 0}</script><script type="application/vnd.jupyter.widget-view+json">{"model_id": "64e040043ea449e28f211c71279442e0", "version_major": 2, "version_minor": 0}</script><script type="application/vnd.jupyter.widget-view+json">{"model_id": "daba6fa1fe1841b3a6fb2d6f26287d8c", "version_major": 2, "version_minor": 0}</script><script type="application/vnd.jupyter.widget-view+json">{"model_id": "db4810c997eb4f9c8dbac5c026d952ce", "version_major": 2, "version_minor": 0}</script><script type="application/vnd.jupyter.widget-view+json">{"model_id": "7c327f87a46a4d4f9a793b7f2925dce3", "version_major": 2, "version_minor": 0}</script></div>
</div>
</section>
<section id="id2">
<h3><span style="color:LightGreen">Evaluate</span><a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h3>
<p>Same as before, let’s investigate how our Deep Ensemble performs on the entire data domain of our input variable <span class="math notranslate nohighlight">\(x\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_preds</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">net</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span> <span class="k">for</span> <span class="n">net</span> <span class="ow">in</span> <span class="n">ensemble</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Plot each ensemble member’s predictive function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">plot_multiple_predictions</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_preds</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">add_multiple_predictions</span><span class="p">(</span><span class="n">ax</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_preds</span><span class="p">)):</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_preds</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

    <span class="n">plot_generic</span><span class="p">(</span><span class="n">add_multiple_predictions</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_multiple_predictions</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_preds</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/0b754bbd5070680b6628763e2cf642f624bfe573c41176d35d5084f357dd1203.png" src="../../_images/0b754bbd5070680b6628763e2cf642f624bfe573c41176d35d5084f357dd1203.png" />
</div>
</div>
<p>In this plot the benefit of an ensemble approach is not immediately clear. Still on the regions outside the training data each of the trained NN is inaccurate. So, you might ask: “What is the benefit?”</p>
<p>Well let’s plot the above in a slightly different way: let’s visualize the ensemble’s <em><strong><span style="color:violet">uncertainty bands</span></strong></em>.</p>
<blockquote>
<div><p>From a Bayesian perspective we want to quantify the model’s uncertainty on its prediction. This is done via the marginal <span class="math notranslate nohighlight">\(p(y|x, D)\)</span>, which can be computed as:</p>
</div></blockquote>
<div class="math notranslate nohighlight">
\[ \Large
p(y|x, D) = \int_{\theta}p(y|x,\theta')p(\theta'|D)d\theta'
\]</div>
<blockquote>
<div><p>In practice, for Deep Ensembles we approximate the above by computing the mean and standard deviation across the ensemble. Meaning <span class="math notranslate nohighlight">\(p(\theta|D)\)</span> represents the parameters of one of the trained models, <span class="math notranslate nohighlight">\(\theta_{i} ∼ p(\theta|D)\)</span>, which we then use to compute <span class="math notranslate nohighlight">\(y_{i} = f(x,\theta_{i})\)</span>, representing <span class="math notranslate nohighlight">\(p(y|x,\theta')\)</span>.</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">plot_uncertainty_bands</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_preds</span><span class="p">):</span>
    <span class="n">y_preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_preds</span><span class="p">)</span>
    <span class="n">y_mean</span> <span class="o">=</span> <span class="n">y_preds</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">y_std</span> <span class="o">=</span> <span class="n">y_preds</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">add_uncertainty</span><span class="p">(</span><span class="n">ax</span><span class="p">):</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_mean</span><span class="p">,</span> <span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#408765&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;predictive mean&quot;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">x_test</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">y_mean</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">y_std</span><span class="p">,</span> <span class="n">y_mean</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">y_std</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#86cfac&#39;</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

    <span class="n">plot_generic</span><span class="p">(</span><span class="n">add_uncertainty</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_uncertainty_bands</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_preds</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/85f4340a9f9427f3cb0f89c4ac36c3ea5c51cd803fba62a39fd83eb3437df25d.png" src="../../_images/85f4340a9f9427f3cb0f89c4ac36c3ea5c51cd803fba62a39fd83eb3437df25d.png" />
</div>
</div>
<p>Now we see the benefit of a Bayesian approach. Outside the training region we not only have the point estimate, but also model’s uncertainty about its prediction.</p>
</section>
</section>
<section id="span-style-color-orange-monte-carlo-dropout-span">
<h2><span style="color:Orange">Monte Carlo Dropout</span><a class="headerlink" href="#span-style-color-orange-monte-carlo-dropout-span" title="Permalink to this heading">#</a></h2>
<p>First we create our MC-Dropout Network. As you can see in the code below, creating a dropout network is extremely simple:
We can reuse our existing network architecture, the only alteration is that during the forward pass we randomly <em>switch off</em> (zero) some of the elements of the input tensor.</p>
<p>The Bayesian interpretation of MC-Dropout is that we can see each dropout configuration as a different sample from the approximate posterior distribution <span class="math notranslate nohighlight">\(\theta_{i} ∼ q(\theta|D)\)</span>.</p>
<section id="id3">
<h3><span style="color:LightGreen">Training</span><a class="headerlink" href="#id3" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">net_dropout</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">(</span><span class="n">hidden_dim</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">n_hidden_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">use_dropout</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">net_dropout</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">net_dropout</span><span class="p">,</span> <span class="n">train_data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "e189ad72feb547eb84887a937a5537c6", "version_major": 2, "version_minor": 0}</script></div>
</div>
</section>
<section id="id4">
<h3><span style="color:LightGreen">Evaluate</span><a class="headerlink" href="#id4" title="Permalink to this heading">#</a></h3>
<p>Similarly to Deep Ensembles, we pass the test data multiple times through the MC-Dropout network. We do so to obtain <span class="math notranslate nohighlight">\(y_{i}\)</span> at the different parameter settings, <span class="math notranslate nohighlight">\(\theta_{i}\)</span> of the network, <span class="math notranslate nohighlight">\(y_{i}=f(x,\theta_{i})\)</span>, governed by the dropout mask.</p>
<blockquote>
<div><p>This is the main difference compared to dropout implementation in a deterministic NN where it serves as a regularization term. In normal dropout application during test time the dropout is <strong>not</strong> applied. Meaning that all connections are present, but the weights are <a class="reference external" href="https://cs231n.github.io/neural-networks-2/">adjusted</a></p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_dropout_samples</span> <span class="o">=</span> <span class="mi">100</span>

<span class="c1"># compute predictions, resampling dropout mask for each forward pass</span>
<span class="n">y_preds</span> <span class="o">=</span> <span class="p">[</span><span class="n">net_dropout</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_dropout_samples</span><span class="p">)]</span>
<span class="n">y_preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_preds</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_multiple_predictions</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_preds</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/c5739269c64f5a4aff57581341edb3719cb39a453f200a757adad2914809400d.png" src="../../_images/c5739269c64f5a4aff57581341edb3719cb39a453f200a757adad2914809400d.png" />
</div>
</div>
<p>In the above plot each colored line (apart from blue) represents a different parametrization, <span class="math notranslate nohighlight">\(\theta_{i}\)</span>, of our MC-Dropout Network.</p>
<p>Likewise to the Deep Ensemble Network, we can also compute the MC-dropout’s <em><strong><span style="color:violet">uncertainty bands</span></strong></em>.</p>
<blockquote>
<div><p>The approach in practice is the same as before: we compute the mean and standard deviation across each dropout mask, which corresponds to the marginal estimation we discussed earlier.</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_uncertainty_bands</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_preds</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/e25c507d6bc66b539ee8dbec133352e9919421ae91f8f61911852dd747e77343.png" src="../../_images/e25c507d6bc66b539ee8dbec133352e9919421ae91f8f61911852dd747e77343.png" />
</div>
</div>
<p>In the same way as Deep Ensembles, MC-Dropout allows us to have an uncertainty estimate next to our point wise predictions. However, for the given use-case this has come with the cost of an overall drop in the model’s performance on the training regions. We observe this because at every pass through our network we randomly choose which nodes to keep, so one could argue that we hinder the networks optimal performance.</p>
</section>
</section>
<section id="span-style-color-orange-conformal-prediction-span">
<h2><span style="color:Orange">Conformal Prediction</span><a class="headerlink" href="#span-style-color-orange-conformal-prediction-span" title="Permalink to this heading">#</a></h2>
<p><span style="color:violet">Conformal prediction</span> is a statistical uncertainty quantification approach that has gained interest in the Machine Learning community more recently. Originally proposed by <a class="reference external" href="https://www.jmlr.org/papers/volume9/shafer08a/shafer08a.pdf">Vovk et al.</a>, it allows us to construct statistically rigorous uncertainty bands around our predictions, without requiring any modifications to our prediction model. This is achieved by comparing true and predicted values on out-of-sample data (more precisely we are looking at <em>inductive</em> conformal prediction), and computing an empirical quantile <span class="math notranslate nohighlight">\(\hat{q}\)</span> based on these comparisons that defines the magnitude of the uncertainy bands. How we compare true and predicted values is a modelling decision, and there are different ways to do so. The comparison results are also called <em>(non)conformity scores</em>, hence the naming of the method.</p>
<p>If we follow the conformal recipe, with minimal assumptions our uncertainty bands will be statistically rigorous in the sense that they satisfy a nice property for any test sample <span class="math notranslate nohighlight">\((X_{n+1},Y_{n+1})\)</span>:</p>
<div class="math notranslate nohighlight">
\[ \Large
\mathbb{P}(Y_{n+1} \in \hat{C}(X_{n+1})) \ge 1-\alpha
\]</div>
<p>, i.e. with probability at least <span class="math notranslate nohighlight">\(1-\alpha\)</span>, our computed uncertainty band <span class="math notranslate nohighlight">\(\hat{C}(X_{n+1})\)</span> around our point estimate <span class="math notranslate nohighlight">\(\hat{Y}_{n+1}\)</span> will contain the <em>true</em> unknown value <span class="math notranslate nohighlight">\(Y_{n+1}\)</span>. This is called a (marginal) coverage guarantee, and provides us with a measure of confidence in the quality of our uncertainty bands.</p>
<p>We will now see that the implementation of conformal prediction for our example is in fact very simple, which is part of its attractiveness.</p>
<section id="id5">
<h3><span style="color:LightGreen">Training</span><a class="headerlink" href="#id5" title="Permalink to this heading">#</a></h3>
<p>Firstly, we split our training samples into two different data sets, the true training set and a hold-out data set, which we call the calibration set (you can think of it as a specific kind of validation set). We will take 20% of our data for calibration. Usually this is a random sample, but for reproducebility we select them evenly spaced.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># split data into training and calibration sets</span>
<span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">get_simple_data_train</span><span class="p">()</span>
<span class="n">cal_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="c1"># cal_idx = np.random.choice(len(x), size=int(len(x) * 0.2), replace=False) # random selection</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
<span class="n">mask</span><span class="p">[</span><span class="n">cal_idx</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">x_cal</span><span class="p">,</span> <span class="n">y_cal</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">mask</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="o">~</span><span class="n">mask</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="o">~</span><span class="n">mask</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Then, we train a single standard (non-Bayesian) MLP on the true training set:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">(</span><span class="n">hidden_dim</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">n_hidden_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "38e64b28cda34c109f5e08a5f1728f8a", "version_major": 2, "version_minor": 0}</script></div>
</div>
</section>
<section id="id6">
<h3><span style="color:LightGreen">Evaluate</span><a class="headerlink" href="#id6" title="Permalink to this heading">#</a></h3>
<p>Same as before, we first visualize how the MLP performs on the entire data domain of our input variable <span class="math notranslate nohighlight">\(x\)</span>. We see that training it on only 80% instead of all available data did not notably change its performance.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># compute predictions everywhere</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span> 
<span class="n">y_preds</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_predictions</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_preds</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/7f9cd82dc0c61a8e843c7a5f922973f87d37ceed67e1badf668c737fc39d78e3.png" src="../../_images/7f9cd82dc0c61a8e843c7a5f922973f87d37ceed67e1badf668c737fc39d78e3.png" />
</div>
</div>
<p>We now perform the conformal prediction procedure to obtain our uncertainty bands. In the simplest case, our comparison of predicted and true values on the calibration data is achieved by simply looking at the residuals <span class="math notranslate nohighlight">\(|y-\hat{y}|\)</span>, which form our <span style="color:violet">conformity scores</span>. We then compute <span class="math notranslate nohighlight">\(\hat{q}\)</span> as the</p>
<div class="math notranslate nohighlight">
\[ \Large
\left\lceil \frac{(n+1)(1-\alpha)}{n} \right\rceil
\]</div>
<p>empirical quantile of these residuals, and form our uncertainty bands for every test sample as</p>
<div class="math notranslate nohighlight">
\[ \Large
\hat{C}(X_{n+1})=[\hat{f}(x_{n+1})-\hat{q},\, \hat{f}(x_{n+1}) +\hat{q}]
\]</div>
<p>Our desired coverage rate is <span class="math notranslate nohighlight">\((1-\alpha) \in [0,1]\)</span>, which we set to 90% (i.e. choose <span class="math notranslate nohighlight">\(\alpha=0.1\)</span>).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># compute calibration residuals</span>
<span class="n">y_cal_preds</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">x_cal</span><span class="p">)</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
<span class="n">resid</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">y_cal</span> <span class="o">-</span> <span class="n">y_cal_preds</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># compute conformal quantile</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_cal</span><span class="p">)</span>
<span class="n">q_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span> <span class="o">/</span> <span class="n">n</span>
<span class="n">q</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">resid</span><span class="p">,</span> <span class="n">q_val</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;higher&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># true function</span>
<span class="n">x_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">y_true</span> <span class="o">=</span> <span class="n">x_true</span> <span class="o">+</span> <span class="mf">0.3</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">x_true</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.3</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">4</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">x_true</span><span class="p">)</span> 

<span class="c1"># generate plot</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Y&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_true</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="s1">&#39;b-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;true function&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s1">&#39;ko&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;observations&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_preds</span><span class="p">,</span> <span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#408765&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;predictive mean&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">x_test</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">y_preds</span> <span class="o">-</span> <span class="n">q</span><span class="p">,</span> <span class="n">y_preds</span> <span class="o">+</span> <span class="n">q</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#86cfac&#39;</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">frameon</span><span class="o">=</span><span class="kc">False</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/88b40b40afd681c4428e5e48517e4962474b9f7b5c71a9317dcf98ba4007edd0.png" src="../../_images/88b40b40afd681c4428e5e48517e4962474b9f7b5c71a9317dcf98ba4007edd0.png" />
</div>
</div>
<p>We now obtain an uncertainty band around each test set prediction, which is informed by our performance on the calibration data (as quantified by the residuals). We can also compare our empirical coverage on the available test data against our target coverage of 90%:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># compute empirical coverage across whole test domain</span>
<span class="n">cov</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(((</span><span class="n">y_preds</span> <span class="o">-</span> <span class="n">q</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">y_true</span><span class="p">)</span> <span class="o">*</span> <span class="p">((</span><span class="n">y_preds</span> <span class="o">+</span> <span class="n">q</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">y_true</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Empirical coverage: </span><span class="si">{</span><span class="n">cov</span><span class="si">:</span><span class="s2">%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Empirical coverage: 49.100000%
</pre></div>
</div>
</div>
</div>
<p>We notice that the empirical coverage does not match our target coverage, suggesting that the conformal procedure is not working well for our given test samples (we are under-covering). This is mainly due to the fact that our calibration data, which is selected from available observations, is very localized and therefore not representative of the whole test domain. In other words, the information we get from the calibration data does not translate well to the whole test domain. Therefore the computed quantile <span class="math notranslate nohighlight">\(\hat{q}\)</span> is inadequate on unseen sample spaces. Compare this to our empirical coverage for test samples from the domain of our calibration data:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># compute empirical coverage only on previously observed test domain</span>
<span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_true</span> <span class="o">&gt;=</span> <span class="o">-</span><span class="mf">.2</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">x_true</span> <span class="o">&lt;</span> <span class="mf">0.2</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">x_true</span> <span class="o">&gt;=</span> <span class="mf">.6</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">x_true</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">cov</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(((</span><span class="n">y_preds</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">-</span> <span class="n">q</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">y_true</span><span class="p">[</span><span class="n">mask</span><span class="p">])</span> <span class="o">*</span> <span class="p">((</span><span class="n">y_preds</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">+</span> <span class="n">q</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">y_true</span><span class="p">[</span><span class="n">mask</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Empirical coverage: </span><span class="si">{</span><span class="n">cov</span><span class="si">:</span><span class="s2">%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Empirical coverage: 100.000000%
</pre></div>
</div>
</div>
</div>
<p>Here we are in fact over-covering, i.e. being overly conservative in the magnitude of our uncertainty bands. Note that the coverage guarantee only holds <em>marginally</em>, i.e. across <em>all possible</em> sets of calibration and test samples; this is particularly obvious in our case. Other factors playing a role in obtaining useful uncertainty bands are the choice of <span class="math notranslate nohighlight">\(\alpha\)</span>, size of the calibration set and the predictive model’s performance.</p>
</section>
</section>
<section id="span-style-color-orange-bayesian-neural-networks-span">
<h2><span style="color:Orange">Bayesian Neural Networks</span><a class="headerlink" href="#span-style-color-orange-bayesian-neural-networks-span" title="Permalink to this heading">#</a></h2>
<p>A Bayesian neural network is a probabilistic model that allows us to estimate uncertainty in predictions by representing the weights and biases of the network as probability distributions rather than fixed values. This allows us to <em>incorporate prior knowledge</em> about the weights and biases into the model, and <em>update our beliefs</em> about them as we observe data.</p>
<p>Mathematically, a Bayesian neural network can be represented as follows:</p>
<p>Given a set of input data <span class="math notranslate nohighlight">\(x\)</span>, we want to predict the corresponding output <span class="math notranslate nohighlight">\(y\)</span>. The neural network represents this relationship as a function <span class="math notranslate nohighlight">\(f(x, \theta)\)</span>, where <span class="math notranslate nohighlight">\(\theta\)</span> are the weights and biases of the network. In a Bayesian neural network, we represent the weights and biases as probability distributions, so <span class="math notranslate nohighlight">\(f(x, \theta)\)</span> becomes a probability distribution over possible outputs:</p>
<div class="math notranslate nohighlight">
\[ \Large
p(y|x, \mathcal{D}) = \int p(y|x, \theta)p(\theta|\mathcal{D}) d\theta
\]</div>
<p>where <span class="math notranslate nohighlight">\(p(y|x, \theta)\)</span> is the likelihood function, which gives the probability of observing <span class="math notranslate nohighlight">\(y\)</span> given <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(\theta\)</span>, and <span class="math notranslate nohighlight">\(p(\theta|\mathcal{D})\)</span> is the posterior distribution over the weights and biases given the observed data <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>.</p>
<p>To make predictions, we use the posterior predictive distribution:</p>
<div class="math notranslate nohighlight">
\[ \Large
p(y^*|x^*, \mathcal{D}) = \int p(y^*|x^*, \theta)p(\theta|\mathcal{D}) d\theta
\]</div>
<p>where <span class="math notranslate nohighlight">\(x^*\)</span> is a new input and <span class="math notranslate nohighlight">\(y^*\)</span> is the corresponding predicted output.</p>
<p>To estimate the (intractable) posterior distribution <span class="math notranslate nohighlight">\(p(\theta|\mathcal{D})\)</span>, we can use either Markov Chain Monte Carlo (MCMC) or Variational Inference (VI).</p>
</section>
<section id="id7">
<h2><span style="color:Orange">Simulate data</span><a class="headerlink" href="#id7" title="Permalink to this heading">#</a></h2>
<p>Let’s generate noisy observations from a sinusoidal function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="c1"># Set random seed for reproducibility</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Generate data</span>
<span class="n">x_obs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mi">500</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.6</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">500</span><span class="p">)])</span>
<span class="n">noise</span> <span class="o">=</span> <span class="mf">0.02</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">x_obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">y_obs</span> <span class="o">=</span> <span class="n">x_obs</span> <span class="o">+</span> <span class="mf">0.3</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="p">(</span><span class="n">x_obs</span> <span class="o">+</span> <span class="n">noise</span><span class="p">))</span> <span class="o">+</span> <span class="mf">0.3</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">4</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="p">(</span><span class="n">x_obs</span> <span class="o">+</span> <span class="n">noise</span><span class="p">))</span> <span class="o">+</span> <span class="n">noise</span>

<span class="n">x_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">y_true</span> <span class="o">=</span> <span class="n">x_true</span> <span class="o">+</span> <span class="mf">0.3</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">x_true</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.3</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">4</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">x_true</span><span class="p">)</span>

<span class="c1"># Set plot limits and labels</span>
<span class="n">xlims</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">]</span>
<span class="n">ylims</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">]</span>

<span class="c1"># Create plot</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_true</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="s1">&#39;b-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;True function&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_obs</span><span class="p">,</span> <span class="n">y_obs</span><span class="p">,</span> <span class="s1">&#39;ko&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Observations&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">xlims</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="n">ylims</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Y&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">frameon</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/edf012dc4deae92b704f23ac2e5125326d92948dff995077604c6185da7df77e.png" src="../../_images/edf012dc4deae92b704f23ac2e5125326d92948dff995077604c6185da7df77e.png" />
</div>
</div>
</section>
<section id="span-style-color-orange-getting-started-with-pyro-span">
<h2><span style="color:Orange">Getting Started with Pyro</span><a class="headerlink" href="#span-style-color-orange-getting-started-with-pyro-span" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">pip</span> install pyro-ppl
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Collecting pyro-ppl
  Downloading pyro_ppl-1.9.1-py3-none-any.whl.metadata (7.8 kB)
Requirement already satisfied: numpy&gt;=1.7 in /home/msn/repos/illinois-mlp/venv/lib/python3.12/site-packages (from pyro-ppl) (2.2.4)
Collecting opt-einsum&gt;=2.3.2 (from pyro-ppl)
  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)
Collecting pyro-api&gt;=0.1.1 (from pyro-ppl)
  Downloading pyro_api-0.1.2-py3-none-any.whl.metadata (2.5 kB)
Requirement already satisfied: torch&gt;=2.0 in /home/msn/repos/illinois-mlp/venv/lib/python3.12/site-packages (from pyro-ppl) (2.6.0)
Requirement already satisfied: tqdm&gt;=4.36 in /home/msn/repos/illinois-mlp/venv/lib/python3.12/site-packages (from pyro-ppl) (4.67.1)
Requirement already satisfied: filelock in /home/msn/repos/illinois-mlp/venv/lib/python3.12/site-packages (from torch&gt;=2.0-&gt;pyro-ppl) (3.17.0)
Requirement already satisfied: typing-extensions&gt;=4.10.0 in /home/msn/repos/illinois-mlp/venv/lib/python3.12/site-packages (from torch&gt;=2.0-&gt;pyro-ppl) (4.12.2)
Requirement already satisfied: networkx in /home/msn/repos/illinois-mlp/venv/lib/python3.12/site-packages (from torch&gt;=2.0-&gt;pyro-ppl) (3.4.2)
Requirement already satisfied: jinja2 in /home/msn/repos/illinois-mlp/venv/lib/python3.12/site-packages (from torch&gt;=2.0-&gt;pyro-ppl) (3.1.5)
Requirement already satisfied: fsspec in /home/msn/repos/illinois-mlp/venv/lib/python3.12/site-packages (from torch&gt;=2.0-&gt;pyro-ppl) (2025.2.0)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/msn/repos/illinois-mlp/venv/lib/python3.12/site-packages (from torch&gt;=2.0-&gt;pyro-ppl) (12.4.127)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/msn/repos/illinois-mlp/venv/lib/python3.12/site-packages (from torch&gt;=2.0-&gt;pyro-ppl) (12.4.127)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/msn/repos/illinois-mlp/venv/lib/python3.12/site-packages (from torch&gt;=2.0-&gt;pyro-ppl) (12.4.127)
Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/msn/repos/illinois-mlp/venv/lib/python3.12/site-packages (from torch&gt;=2.0-&gt;pyro-ppl) (9.1.0.70)
Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/msn/repos/illinois-mlp/venv/lib/python3.12/site-packages (from torch&gt;=2.0-&gt;pyro-ppl) (12.4.5.8)
Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/msn/repos/illinois-mlp/venv/lib/python3.12/site-packages (from torch&gt;=2.0-&gt;pyro-ppl) (11.2.1.3)
Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/msn/repos/illinois-mlp/venv/lib/python3.12/site-packages (from torch&gt;=2.0-&gt;pyro-ppl) (10.3.5.147)
Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/msn/repos/illinois-mlp/venv/lib/python3.12/site-packages (from torch&gt;=2.0-&gt;pyro-ppl) (11.6.1.9)
Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/msn/repos/illinois-mlp/venv/lib/python3.12/site-packages (from torch&gt;=2.0-&gt;pyro-ppl) (12.3.1.170)
Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/msn/repos/illinois-mlp/venv/lib/python3.12/site-packages (from torch&gt;=2.0-&gt;pyro-ppl) (0.6.2)
Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/msn/repos/illinois-mlp/venv/lib/python3.12/site-packages (from torch&gt;=2.0-&gt;pyro-ppl) (2.21.5)
Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/msn/repos/illinois-mlp/venv/lib/python3.12/site-packages (from torch&gt;=2.0-&gt;pyro-ppl) (12.4.127)
Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/msn/repos/illinois-mlp/venv/lib/python3.12/site-packages (from torch&gt;=2.0-&gt;pyro-ppl) (12.4.127)
Requirement already satisfied: triton==3.2.0 in /home/msn/repos/illinois-mlp/venv/lib/python3.12/site-packages (from torch&gt;=2.0-&gt;pyro-ppl) (3.2.0)
Requirement already satisfied: setuptools in /home/msn/repos/illinois-mlp/venv/lib/python3.12/site-packages (from torch&gt;=2.0-&gt;pyro-ppl) (75.8.1)
Requirement already satisfied: sympy==1.13.1 in /home/msn/repos/illinois-mlp/venv/lib/python3.12/site-packages (from torch&gt;=2.0-&gt;pyro-ppl) (1.13.1)
Requirement already satisfied: mpmath&lt;1.4,&gt;=1.1.0 in /home/msn/repos/illinois-mlp/venv/lib/python3.12/site-packages (from sympy==1.13.1-&gt;torch&gt;=2.0-&gt;pyro-ppl) (1.3.0)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /home/msn/repos/illinois-mlp/venv/lib/python3.12/site-packages (from jinja2-&gt;torch&gt;=2.0-&gt;pyro-ppl) (3.0.2)
Downloading pyro_ppl-1.9.1-py3-none-any.whl (755 kB)
   <span class=" -Color -Color-Red">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Green">756.0/756.0 kB</span> <span class=" -Color -Color-Red">7.5 MB/s</span> eta <span class=" -Color -Color-Cyan">0:00:00</span>
?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)
Downloading pyro_api-0.1.2-py3-none-any.whl (11 kB)
Installing collected packages: pyro-api, opt-einsum, pyro-ppl
Successfully installed opt-einsum-3.4.0 pyro-api-0.1.2 pyro-ppl-1.9.1
Note: you may need to restart the kernel to use updated packages.
</pre></div>
</div>
</div>
</div>
</section>
<section id="span-style-color-orange-bayesian-neural-network-with-gaussian-prior-and-likelihood-span">
<h2><span style="color:Orange">Bayesian Neural Network with Gaussian Prior and Likelihood</span><a class="headerlink" href="#span-style-color-orange-bayesian-neural-network-with-gaussian-prior-and-likelihood-span" title="Permalink to this heading">#</a></h2>
<p>Our first Bayesian neural network employs a Gaussian prior on the weights and a Gaussian likelihood function for the data. The network is a shallow neural network with one hidden layer.</p>
<p>To be specific, we use the following prior on the weights <span class="math notranslate nohighlight">\(\theta\)</span>:</p>
<div class="math notranslate nohighlight">
\[ \Large
p(\theta) = \mathcal{N}(\mathbf{0}, 10\cdot\mathbb{I})
\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbb{I}\)</span> is the identity matrix.</p>
<p>To train the network, we define a likelihood function comparing the predicted outputs of the network with the actual data points:</p>
<div class="math notranslate nohighlight">
\[ \Large
p(y_i| x_i, \theta) = \mathcal{N}\big(NN_{\theta}(x_i), \sigma^2\big)
\]</div>
<p>with prior <span class="math notranslate nohighlight">\(\sigma \sim \Gamma(1,1)\)</span>.</p>
<p>Here, <span class="math notranslate nohighlight">\(y_i\)</span> represents the actual output for the <span class="math notranslate nohighlight">\(i\)</span>-th data point, <span class="math notranslate nohighlight">\(x_i\)</span> represents the input for that data point, <span class="math notranslate nohighlight">\(\sigma\)</span> is the standard deviation parameter for the normal distribution and <span class="math notranslate nohighlight">\(NN_{\theta}\)</span> is the shallow neural network parameterized by <span class="math notranslate nohighlight">\(\theta\)</span>.</p>
<p>Note that we use <span class="math notranslate nohighlight">\(\sigma^2\)</span> instead of <span class="math notranslate nohighlight">\(\sigma\)</span> in the likelihood function because we use a Gaussian prior on <span class="math notranslate nohighlight">\(\sigma\)</span> when performing variational inference and then want to avoid negative values for the standard deviation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pyro</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pyro.distributions</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">dist</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyro.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">PyroModule</span><span class="p">,</span> <span class="n">PyroSample</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>


<span class="k">class</span><span class="w"> </span><span class="nc">MyFirstBNN</span><span class="p">(</span><span class="n">PyroModule</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">hid_dim</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">prior_scale</span><span class="o">=</span><span class="mf">10.</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()</span>  <span class="c1"># or nn.ReLU()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span> <span class="o">=</span> <span class="n">PyroModule</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">](</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">hid_dim</span><span class="p">)</span>  <span class="c1"># Input to hidden layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span> <span class="o">=</span> <span class="n">PyroModule</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">](</span><span class="n">hid_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">)</span>  <span class="c1"># Hidden to output layer</span>

        <span class="c1"># Set layer parameters as random variables</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">PyroSample</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="n">prior_scale</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">([</span><span class="n">hid_dim</span><span class="p">,</span> <span class="n">in_dim</span><span class="p">])</span><span class="o">.</span><span class="n">to_event</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">PyroSample</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="n">prior_scale</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">([</span><span class="n">hid_dim</span><span class="p">])</span><span class="o">.</span><span class="n">to_event</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">PyroSample</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="n">prior_scale</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">([</span><span class="n">out_dim</span><span class="p">,</span> <span class="n">hid_dim</span><span class="p">])</span><span class="o">.</span><span class="n">to_event</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">PyroSample</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="n">prior_scale</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">([</span><span class="n">out_dim</span><span class="p">])</span><span class="o">.</span><span class="n">to_event</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layer1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">mu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
        <span class="n">sigma</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;sigma&quot;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">Gamma</span><span class="p">(</span><span class="mf">.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>  <span class="c1"># Infer the response noise</span>

        <span class="c1"># Sampling model</span>
        <span class="k">with</span> <span class="n">pyro</span><span class="o">.</span><span class="n">plate</span><span class="p">(</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">obs</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;obs&quot;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">*</span> <span class="n">sigma</span><span class="p">),</span> <span class="n">obs</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mu</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="span-style-color-orange-define-and-run-markov-chain-monte-carlo-sampler-span">
<h2><span style="color:Orange">Define and run Markov chain Monte Carlo sampler</span><a class="headerlink" href="#span-style-color-orange-define-and-run-markov-chain-monte-carlo-sampler-span" title="Permalink to this heading">#</a></h2>
<p>To begin with, we can use MCMC to compute an <span style="color:Violet">unbiased estimate</span>
of</p>
<div class="math notranslate nohighlight">
\[ \Large
p(y|x, \mathcal{D}) = \mathbb{E}_{\theta \sim p(\theta|\mathcal{D})}\big[p(y|x,\theta)\big]
\]</div>
<p>through Monte Carlo sampling. Specifically, we can approximate</p>
<div class="math notranslate nohighlight">
\[ \Large
\mathbb{E}_{\theta \sim p(\theta|\mathcal{D})}\big[p(y|x,\theta)\big]
\]</div>
<p>as follows:</p>
<div class="math notranslate nohighlight">
\[ \Large
\mathbb{E}_{\theta \sim p(\theta|\mathcal{D})}\big[p(y|x,\theta)\big] \approx \frac{1}{N} \sum_{i=1}^{N} p(y|x,\theta_{i})
\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[ \Large
\theta_{i} \sim p(\theta_i|\mathcal{D}) \propto p(\mathcal{D}|\theta)p(\theta)
\]</div>
<p>are samples drawn from the posterior distribution. Because the normalizing constant is intractable, we require MCMC methods like Hamiltonian Monte Carlo to draw samples from the non-normalized posterior.</p>
<p>Here, we use the No-U-Turn (<a class="reference external" href="https://arxiv.org/abs/1111.4246">NUTS</a>) kernel.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyro.infer</span><span class="w"> </span><span class="kn">import</span> <span class="n">MCMC</span><span class="p">,</span> <span class="n">NUTS</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">MyFirstBNN</span><span class="p">()</span>

<span class="c1"># Set Pyro random seed</span>
<span class="n">pyro</span><span class="o">.</span><span class="n">set_rng_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Define Hamiltonian Monte Carlo (HMC) kernel</span>
<span class="c1"># NUTS = &quot;No-U-Turn Sampler&quot; (https://arxiv.org/abs/1111.4246), gives HMC an adaptive step size</span>
<span class="n">nuts_kernel</span> <span class="o">=</span> <span class="n">NUTS</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">jit_compile</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>  <span class="c1"># jit_compile=True is faster but requires PyTorch 1.6+</span>

<span class="c1"># Define MCMC sampler, get 50 posterior samples</span>
<span class="n">mcmc</span> <span class="o">=</span> <span class="n">MCMC</span><span class="p">(</span><span class="n">nuts_kernel</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>

<span class="c1"># Convert data to PyTorch tensors</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">x_obs</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_obs</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

<span class="c1"># Run MCMC</span>
<span class="n">mcmc</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sample: 100%|██████████| 100/100 [00:57,  1.73it/s, step size=4.38e-04, acc. prob=0.978]
</pre></div>
</div>
</div>
</div>
<p>We calculate and plot the predictive distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyro.infer</span><span class="w"> </span><span class="kn">import</span> <span class="n">Predictive</span>

<span class="n">predictive</span> <span class="o">=</span> <span class="n">Predictive</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">posterior_samples</span><span class="o">=</span><span class="n">mcmc</span><span class="o">.</span><span class="n">get_samples</span><span class="p">())</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">xlims</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">xlims</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">3000</span><span class="p">)</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">predictive</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">plot_predictions</span><span class="p">(</span><span class="n">preds</span><span class="p">):</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">preds</span><span class="p">[</span><span class="s1">&#39;obs&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">y_std</span> <span class="o">=</span> <span class="n">preds</span><span class="p">[</span><span class="s1">&#39;obs&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
    <span class="n">xlims</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">]</span>
    <span class="n">ylims</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">]</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">xlims</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="n">ylims</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Y&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_true</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="s1">&#39;b-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;true function&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_obs</span><span class="p">,</span> <span class="n">y_obs</span><span class="p">,</span> <span class="s1">&#39;ko&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;observations&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_obs</span><span class="p">,</span> <span class="n">y_obs</span><span class="p">,</span> <span class="s1">&#39;ko&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#408765&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;predictive mean&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">y_std</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">y_std</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#86cfac&#39;</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">frameon</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_predictions</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/67694a78370bb295da6bcc40faa48cbee1e9825ad4b50665c8c6963ec9b3f09a.png" src="../../_images/67694a78370bb295da6bcc40faa48cbee1e9825ad4b50665c8c6963ec9b3f09a.png" />
</div>
</div>
</section>
<section id="span-style-color-orange-exercise-1-deep-bayesian-neural-network-span">
<h2><span style="color:Orange"> Exercise 1: Deep Bayesian Neural Network</span><a class="headerlink" href="#span-style-color-orange-exercise-1-deep-bayesian-neural-network-span" title="Permalink to this heading">#</a></h2>
<p>We can define a deep Bayesian neural network in a similar fashion, with Gaussian priors on the weights:</p>
<div class="math notranslate nohighlight">
\[ \Large 
p(\theta) = \mathcal{N}(\mathbf{0}, 5\cdot\mathbb{I})
\]</div>
<p>The likelihood function is also Gaussian:</p>
<div class="math notranslate nohighlight">
\[ \Large
p(y_i| x_i, \theta) = \mathcal{N}\big(NN_{\theta}(x_i), \sigma^2\big)
\]</div>
<p>with <span class="math notranslate nohighlight">\(\sigma \sim \Gamma(0.5,1)\)</span>.</p>
<blockquote>
<div><p>Implement the deep Bayesian neural network and run MCMC to obtain posterior samples.
Compute and plot the predictive distribution.
Use the following network architecture: Number of hidden layers: 5, Number of hidden units per layer: 10, Activation function: Tanh, Prior scale: 5.</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">BNN</span><span class="p">(</span><span class="n">PyroModule</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">hid_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_hid_layers</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">prior_scale</span><span class="o">=</span><span class="mf">5.</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()</span>  <span class="c1"># could also be ReLU or LeakyReLU</span>
        <span class="k">assert</span> <span class="n">in_dim</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">out_dim</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">hid_dim</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">n_hid_layers</span> <span class="o">&gt;</span> <span class="mi">0</span>  <span class="c1"># make sure the dimensions are valid</span>

        <span class="c1"># Define the layer sizes and the PyroModule layer list</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="n">in_dim</span><span class="p">]</span> <span class="o">+</span> <span class="n">n_hid_layers</span> <span class="o">*</span> <span class="p">[</span><span class="n">hid_dim</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">out_dim</span><span class="p">]</span>
        <span class="n">layer_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">PyroModule</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">](</span><span class="bp">self</span><span class="o">.</span><span class="n">layer_sizes</span><span class="p">[</span><span class="n">idx</span> <span class="o">-</span> <span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_sizes</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span>
                      <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layer_sizes</span><span class="p">))]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">PyroModule</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">](</span><span class="n">layer_list</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">layer_idx</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">):</span>
            <span class="n">layer</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">PyroSample</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="n">prior_scale</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_sizes</span><span class="p">[</span><span class="n">layer_idx</span><span class="p">]))</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span>
                <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">layer_sizes</span><span class="p">[</span><span class="n">layer_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_sizes</span><span class="p">[</span><span class="n">layer_idx</span><span class="p">]])</span><span class="o">.</span><span class="n">to_event</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
            <span class="n">layer</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">PyroSample</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="n">prior_scale</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">layer_sizes</span><span class="p">[</span><span class="n">layer_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]])</span><span class="o">.</span><span class="n">to_event</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">x</span><span class="p">))</span>  <span class="c1"># input --&gt; hidden</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>  <span class="c1"># hidden --&gt; hidden</span>
        <span class="n">mu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">](</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>  <span class="c1"># hidden --&gt; output</span>
        <span class="n">sigma</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;sigma&quot;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">Gamma</span><span class="p">(</span><span class="mf">.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>  <span class="c1"># infer the response noise</span>

        <span class="k">with</span> <span class="n">pyro</span><span class="o">.</span><span class="n">plate</span><span class="p">(</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">obs</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;obs&quot;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">*</span> <span class="n">sigma</span><span class="p">),</span> <span class="n">obs</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mu</span>
</pre></div>
</div>
</div>
</div>
<section id="span-style-color-lightgreen-train-the-deep-bnn-with-mcmc-span">
<h3><span style="color:LightGreen">Train the deep BNN with MCMC</span><a class="headerlink" href="#span-style-color-lightgreen-train-the-deep-bnn-with-mcmc-span" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># define model and data</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">BNN</span><span class="p">(</span><span class="n">hid_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_hid_layers</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">prior_scale</span><span class="o">=</span><span class="mf">5.</span><span class="p">)</span>

<span class="c1"># define MCMC sampler</span>
<span class="n">nuts_kernel</span> <span class="o">=</span> <span class="n">NUTS</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">jit_compile</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">mcmc</span> <span class="o">=</span> <span class="n">MCMC</span><span class="p">(</span><span class="n">nuts_kernel</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="n">mcmc</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sample: 100%|██████████| 100/100 [02:24,  1.45s/it, step size=9.71e-04, acc. prob=0.866]
</pre></div>
</div>
</div>
</div>
</section>
<section id="span-style-color-lightgreen-compute-predictive-distribution-span">
<h3><span style="color:LightGreen">Compute predictive distribution</span><a class="headerlink" href="#span-style-color-lightgreen-compute-predictive-distribution-span" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predictive</span> <span class="o">=</span> <span class="n">Predictive</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">posterior_samples</span><span class="o">=</span><span class="n">mcmc</span><span class="o">.</span><span class="n">get_samples</span><span class="p">())</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">predictive</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="n">plot_predictions</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/31bca53e8aafebb138a96bba0f58949d68b3a620c271bfb6e78be7606a2983fd.png" src="../../_images/31bca53e8aafebb138a96bba0f58949d68b3a620c271bfb6e78be7606a2983fd.png" />
</div>
</div>
</section>
<section id="span-style-color-lightgreen-train-bnns-with-mean-field-variational-inference-span">
<h3><span style="color:LightGreen">Train BNNs with mean-field variational inference</span><a class="headerlink" href="#span-style-color-lightgreen-train-bnns-with-mean-field-variational-inference-span" title="Permalink to this heading">#</a></h3>
<p>We will now move on to variational inference. Since the normalized posterior probability density <span class="math notranslate nohighlight">\(p(\theta|\mathcal{D})\)</span> is intractable, we approximate it with a tractable parametrized density <span class="math notranslate nohighlight">\(q_{\phi}(\theta)\)</span> in a family of probability densities <span class="math notranslate nohighlight">\(\mathcal{Q}\)</span>. The variational parameters are denoted by <span class="math notranslate nohighlight">\(\phi\)</span> and the variational density is called the “guide” in Pyro. The goal is to find the variational probability density that best approximates the posterior by minimizing the KL divergence</p>
<div class="math notranslate nohighlight">
\[ \Large
KL\big(q_{\phi}(\theta)||p(\theta|\mathcal{D})\big)
\]</div>
<p>with respect to the variational parameters.</p>
<p>However, directly minimizing the KL divergence is not tractable because we assume that the posterior density is intractable. To solve this, we use Bayes theorem to obtain</p>
<div class="math notranslate nohighlight">
\[ \Large
\log p(\mathcal{D}|\theta) = KL\big(q_{\phi}(\theta)||p(\theta|\mathcal{D})\big) + ELBO(q_{\phi}(\theta)),
\]</div>
<p>where <span class="math notranslate nohighlight">\(ELBO(q_{\phi}(\theta))\)</span> is the <em>Evidence Lower Bound</em>, given by</p>
<div class="math notranslate nohighlight">
\[ \Large
ELBO(q_{\phi}(\theta)) = \mathbb{E}_{\theta \sim q_{\phi}(\theta)}\big[\log p(y|x,\theta) \big] - KL\big(q_{\phi}(\theta) || p(\theta) \big).
\]</div>
<p>By maximizing the ELBO, we indirectly minimize the KL divergence between the variational probability density and the posterior density.</p>
<p>Set up for stochastic variational inference with the variational density <span class="math notranslate nohighlight">\(q_{\phi}(\theta)\)</span> by using a normal probability density with a diagonal covariance matrix:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyro.infer</span><span class="w"> </span><span class="kn">import</span> <span class="n">SVI</span><span class="p">,</span> <span class="n">Trace_ELBO</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyro.infer.autoguide</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoDiagonalNormal</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tqdm.auto</span><span class="w"> </span><span class="kn">import</span> <span class="n">trange</span>
<span class="n">pyro</span><span class="o">.</span><span class="n">clear_param_store</span><span class="p">()</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">BNN</span><span class="p">(</span><span class="n">hid_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_hid_layers</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">prior_scale</span><span class="o">=</span><span class="mf">5.</span><span class="p">)</span>
<span class="n">mean_field_guide</span> <span class="o">=</span> <span class="n">AutoDiagonalNormal</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">({</span><span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">})</span>

<span class="n">svi</span> <span class="o">=</span> <span class="n">SVI</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">mean_field_guide</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">Trace_ELBO</span><span class="p">())</span>
<span class="n">pyro</span><span class="o">.</span><span class="n">clear_param_store</span><span class="p">()</span>

<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">25000</span>
<span class="n">progress_bar</span> <span class="o">=</span> <span class="n">trange</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">)</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">progress_bar</span><span class="p">:</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">svi</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">progress_bar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">loss</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "932391def01445b3979fdf50b7c4f7bc", "version_major": 2, "version_minor": 0}</script></div>
</div>
<p>As before, we compute the predictive distribution sampling from the trained variational density.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predictive</span> <span class="o">=</span> <span class="n">Predictive</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">guide</span><span class="o">=</span><span class="n">mean_field_guide</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">predictive</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="n">plot_predictions</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/967774d1736fc5e1daa7e7d8df63e5dfe741d83f0f2d9bc13a9e59f46c5c92b9.png" src="../../_images/967774d1736fc5e1daa7e7d8df63e5dfe741d83f0f2d9bc13a9e59f46c5c92b9.png" />
</div>
</div>
</section>
</section>
<section id="span-style-color-orange-exercise-2-bayesian-updating-with-variational-inference-span">
<h2><span style="color:Orange">Exercise 2: Bayesian updating with variational inference</span><a class="headerlink" href="#span-style-color-orange-exercise-2-bayesian-updating-with-variational-inference-span" title="Permalink to this heading">#</a></h2>
<p>What happens if we obtain new data points, denoted as <span class="math notranslate nohighlight">\(\mathcal{D}'\)</span>, after performing variational inference using the observations <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate new observations</span>
<span class="n">x_new</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">noise</span> <span class="o">=</span> <span class="mf">0.02</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">x_new</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">y_new</span> <span class="o">=</span> <span class="n">x_new</span> <span class="o">+</span> <span class="mf">0.3</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="p">(</span><span class="n">x_new</span> <span class="o">+</span> <span class="n">noise</span><span class="p">))</span> <span class="o">+</span> <span class="mf">0.3</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">4</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="p">(</span><span class="n">x_new</span> <span class="o">+</span> <span class="n">noise</span><span class="p">))</span> <span class="o">+</span> <span class="n">noise</span>

<span class="c1"># Generate true function</span>
<span class="n">x_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">y_true</span> <span class="o">=</span> <span class="n">x_true</span> <span class="o">+</span> <span class="mf">0.3</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">x_true</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.3</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">4</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">x_true</span><span class="p">)</span>

<span class="c1"># Set axis limits and labels</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">xlims</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="n">ylims</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Y&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>

<span class="c1"># Plot all datasets</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_true</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="s1">&#39;b-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;True function&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_new</span><span class="p">,</span> <span class="n">y_new</span><span class="p">,</span> <span class="s1">&#39;ko&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;New observations&quot;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_obs</span><span class="p">,</span> <span class="n">y_obs</span><span class="p">,</span> <span class="s1">&#39;ko&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Old observations&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">frameon</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/tmp/ipykernel_5175/1208744758.py:18: UserWarning: color is redundantly defined by the &#39;color&#39; keyword argument and the fmt string &quot;ko&quot; (-&gt; color=&#39;k&#39;). The keyword argument will take precedence.
  plt.plot(x_new, y_new, &#39;ko&#39;, markersize=4, label=&quot;New observations&quot;, c=&quot;r&quot;)
</pre></div>
</div>
<img alt="../../_images/4f2f571735eac84ad7b58b9a7d90243ce40e297dca266b2eefacf6fb1a524c96.png" src="../../_images/4f2f571735eac84ad7b58b9a7d90243ce40e297dca266b2eefacf6fb1a524c96.png" />
</div>
</div>
<section id="span-style-color-lightgreen-bayesian-update-span">
<h3><span style="color:LightGreen">Bayesian update</span><a class="headerlink" href="#span-style-color-lightgreen-bayesian-update-span" title="Permalink to this heading">#</a></h3>
<p>How can we perform a Bayesian update on the model using variational inference when new observations become available?</p>
<p>We can use the previously calculated posterior probability density as the new prior and update the posterior with the new observations. Specifically, the updated posterior probability density is given by:</p>
<div class="math notranslate nohighlight">
\[ \Large
p(\theta|\mathcal{D}') = \frac{p(\mathcal{D}'|\theta)q_{\phi}(\theta)}{\int p(\mathcal{D}'|\theta)q_{\phi}(\theta)}
\]</div>
<p>Note that we want to update our model using only the new observations <span class="math notranslate nohighlight">\(\mathcal{D}'\)</span>, relying on the fact that the variational density used as our new prior carries the necessary information on the old observations <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>.</p>
</section>
<section id="span-style-color-lightgreen-implementation-in-pyro-span">
<h3><span style="color:LightGreen">Implementation in Pyro</span><a class="headerlink" href="#span-style-color-lightgreen-implementation-in-pyro-span" title="Permalink to this heading">#</a></h3>
<p>To implement this in Pyro, we can extract the variational parameters (mean and standard deviation) from the <code class="docutils literal notranslate"><span class="pre">guide</span></code> and use them to initialize the prior in a new model that is similar to the original model used for variational inference.</p>
<p>From the Gaussian <code class="docutils literal notranslate"><span class="pre">guide</span></code> we can extract the variational parameters (mean and standard deviation) as:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">mu</span> <span class="o">=</span> <span class="n">guide</span><span class="o">.</span><span class="n">get_posterior</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="n">guide</span><span class="o">.</span><span class="n">get_posterior</span><span class="p">()</span><span class="o">.</span><span class="n">stddev</span>
</pre></div>
</div>
</section>
<section id="span-style-color-lightgreen-exercise-2-1-learn-a-model-on-the-old-observations-span">
<h3><span style="color:LightGreen">Exercise 2.1 Learn a model on the old observations</span><a class="headerlink" href="#span-style-color-lightgreen-exercise-2-1-learn-a-model-on-the-old-observations-span" title="Permalink to this heading">#</a></h3>
<p>First, as before, we define a model using Gaussian prior <span class="math notranslate nohighlight">\(\mathcal{N}(\mathbf{0}, 10\cdot \mathbb{I})\)</span>.</p>
<blockquote>
<div><p>Train a model <code class="docutils literal notranslate"><span class="pre">MyFirstBNN</span></code> on the old observations <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> using variational inference with <code class="docutils literal notranslate"><span class="pre">AutoDiagonalNormal()</span></code> as guide.</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyro.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>
<span class="n">pyro</span><span class="o">.</span><span class="n">set_rng_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">pyro</span><span class="o">.</span><span class="n">clear_param_store</span><span class="p">()</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">MyFirstBNN</span><span class="p">()</span>
<span class="n">guide</span> <span class="o">=</span> <span class="n">AutoDiagonalNormal</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">optim</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">({</span><span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">0.03</span><span class="p">})</span>
<span class="n">svi</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">infer</span><span class="o">.</span><span class="n">SVI</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">guide</span><span class="p">,</span> <span class="n">optim</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">Trace_ELBO</span><span class="p">())</span>

<span class="n">num_iterations</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">progress_bar</span> <span class="o">=</span> <span class="n">trange</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">)</span>

<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">progress_bar</span><span class="p">:</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">svi</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">progress_bar</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="s2">&quot;[iteration </span><span class="si">%04d</span><span class="s2">] loss: </span><span class="si">%.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_train</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "c2c8b5939bf2404db77b2af3be5b5b3c", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predictive</span> <span class="o">=</span> <span class="n">Predictive</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">guide</span><span class="o">=</span><span class="n">guide</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">5000</span><span class="p">)</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">predictive</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="n">plot_predictions</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/d98f5b9436928cb241d59eb20a416bd453d895102f47748edde4f99abfc6d64b.png" src="../../_images/d98f5b9436928cb241d59eb20a416bd453d895102f47748edde4f99abfc6d64b.png" />
</div>
</div>
<p>Next, we can extract the variational parameters (mean and standard deviation) from the <code class="docutils literal notranslate"><span class="pre">guide</span></code> and use them to initialize the prior in a new model that is similar to the original model used for variational inference.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Extract variational parameters from guide</span>
<span class="n">mu</span> <span class="o">=</span> <span class="n">guide</span><span class="o">.</span><span class="n">get_posterior</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
<span class="n">stddev</span> <span class="o">=</span> <span class="n">guide</span><span class="o">.</span><span class="n">get_posterior</span><span class="p">()</span><span class="o">.</span><span class="n">stddev</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">pyro</span><span class="o">.</span><span class="n">get_param_store</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">pyro</span><span class="o">.</span><span class="n">param</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>AutoDiagonalNormal.loc Parameter containing:
tensor([ 4.4192,  2.0755,  2.5233,  2.9758, -2.8464, -4.5504, -0.6823,  8.6832,
         8.4492,  1.4790,  1.2583,  5.1179,  0.9285, -1.8940,  4.3386,  1.2919,
        -1.0739], requires_grad=True)
AutoDiagonalNormal.scale tensor([1.4527e-02, 2.4028e-03, 2.1597e+00, 1.6082e+00, 4.6766e-03, 1.4399e-02,
        1.4626e-03, 1.5904e+00, 8.8780e-01, 2.9017e-03, 6.1737e-03, 9.5350e-03,
        6.3800e-03, 5.4559e-03, 7.9139e-03, 5.9698e-03, 4.8265e-02],
       grad_fn=&lt;SoftplusBackward0&gt;)
</pre></div>
</div>
</div>
</div>
</section>
<section id="span-style-color-lightgreen-exercise-2-2-initialize-a-second-model-with-the-variational-parameters-span">
<h3><span style="color:LightGreen">Exercise 2.2 Initialize a second model with the variational parameters</span><a class="headerlink" href="#span-style-color-lightgreen-exercise-2-2-initialize-a-second-model-with-the-variational-parameters-span" title="Permalink to this heading">#</a></h3>
<blockquote>
<div><p>Define a new model similar to <code class="docutils literal notranslate"><span class="pre">MyFirstBNN(PyroModule)</span></code>, that takes the variational parameters and uses them to initialize the prior.</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">UpdatedBNN</span><span class="p">(</span><span class="n">PyroModule</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">stddev</span><span class="p">,</span> <span class="n">in_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">hid_dim</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="o">=</span> <span class="n">mu</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stddev</span> <span class="o">=</span> <span class="n">stddev</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span> <span class="o">=</span> <span class="n">PyroModule</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">](</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">hid_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span> <span class="o">=</span> <span class="n">PyroModule</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">](</span><span class="n">hid_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">PyroSample</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">stddev</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">to_event</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">PyroSample</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">[</span><span class="mi">5</span><span class="p">:</span><span class="mi">10</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">stddev</span><span class="p">[</span><span class="mi">5</span><span class="p">:</span><span class="mi">10</span><span class="p">])</span><span class="o">.</span><span class="n">to_event</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">PyroSample</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">[</span><span class="mi">10</span><span class="p">:</span><span class="mi">15</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">stddev</span><span class="p">[</span><span class="mi">10</span><span class="p">:</span><span class="mi">15</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">to_event</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">PyroSample</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">[</span><span class="mi">15</span><span class="p">:</span><span class="mi">16</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">stddev</span><span class="p">[</span><span class="mi">15</span><span class="p">:</span><span class="mi">16</span><span class="p">])</span><span class="o">.</span><span class="n">to_event</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="c1"># 17th parameter is parameter sigma from the Gamma distribution</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layer1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">mu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
        <span class="n">sigma</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;sigma&quot;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">Gamma</span><span class="p">(</span><span class="mf">.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

        <span class="k">with</span> <span class="n">pyro</span><span class="o">.</span><span class="n">plate</span><span class="p">(</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">obs</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;obs&quot;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">*</span> <span class="n">sigma</span><span class="p">),</span> <span class="n">obs</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mu</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="span-style-color-lightgreen-exercise-2-3-perform-variational-inference-on-the-new-model-span">
<h3><span style="color:LightGreen">Exercise 2.3 Perform variational inference on the new model</span><a class="headerlink" href="#span-style-color-lightgreen-exercise-2-3-perform-variational-inference-on-the-new-model-span" title="Permalink to this heading">#</a></h3>
</section>
<section id="id8">
<h3><a class="headerlink" href="#id8" title="Permalink to this heading">#</a></h3>
<blockquote>
<div><p>Then perform variational inference on this new model using the new observations and plot the predictive distribution.
What do you observe? How does the predictive distribution compare to the one obtained in Exercise 2.1?</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_train_new</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">x_new</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="n">y_train_new</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_new</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

<span class="n">pyro</span><span class="o">.</span><span class="n">clear_param_store</span><span class="p">()</span>
<span class="n">new_model</span> <span class="o">=</span> <span class="n">UpdatedBNN</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">stddev</span><span class="p">)</span>
<span class="n">new_guide</span> <span class="o">=</span> <span class="n">AutoDiagonalNormal</span><span class="p">(</span><span class="n">new_model</span><span class="p">)</span>
<span class="n">optim</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">({</span><span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">})</span>
<span class="n">svi</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">infer</span><span class="o">.</span><span class="n">SVI</span><span class="p">(</span><span class="n">new_model</span><span class="p">,</span> <span class="n">new_guide</span><span class="p">,</span> <span class="n">optim</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">Trace_ELBO</span><span class="p">())</span>

<span class="n">num_iterations</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">progress_bar</span> <span class="o">=</span> <span class="n">trange</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">)</span>

<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">progress_bar</span><span class="p">:</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">svi</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">x_train_new</span><span class="p">,</span> <span class="n">y_train_new</span><span class="p">)</span>
    <span class="n">progress_bar</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="s2">&quot;[iteration </span><span class="si">%04d</span><span class="s2">] loss: </span><span class="si">%.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_train</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "add6d6e572f94b0da079b170404956fb", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predictive</span> <span class="o">=</span> <span class="n">Predictive</span><span class="p">(</span><span class="n">new_model</span><span class="p">,</span> <span class="n">guide</span><span class="o">=</span><span class="n">new_guide</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">5000</span><span class="p">)</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">predictive</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="n">plot_predictions</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/2fe6bbdbf56afe38a44cf7c44015dfa0496a834ac02d821ffa19566f46145bc8.png" src="../../_images/2fe6bbdbf56afe38a44cf7c44015dfa0496a834ac02d821ffa19566f46145bc8.png" />
</div>
</div>
</section>
</section>
<section id="span-style-color-orange-acknowledgments-span">
<h2><span style="color:Orange">Acknowledgments</span><a class="headerlink" href="#span-style-color-orange-acknowledgments-span" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Initial version: Mark Neubauer</p></li>
<li><p>Authors: Ilze Amanda Auzina, Leonard Bereska, Alexander Timans and Eric Nalisnick</p></li>
<li><p>From <a class="reference external" href="https://uvadlc-notebooks.readthedocs.io/en/latest/index.html">https://uvadlc-notebooks.readthedocs.io/en/latest/index.html</a></p></li>
</ul>
<p>© Copyright 2025</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./_sources/lectures"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../Week_11.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span style="color: blue;"><b>AI Explainablility and Uncertainty Quantification</b></span></p>
      </div>
    </a>
    <a class="right-next"
       href="../homework/Homework_08.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Homework 08: Detecting Distribution Shift on MNIST using Bayesian Neural Networks</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-overview-span"><span style="color:Orange">Overview</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-simulate-data-span"><span style="color:Orange">Simulate Data</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-define-non-bayesian-neural-network-span"><span style="color:Orange">Define non-Bayesian Neural Network</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-train-one-deterministic-nn-span"><span style="color:Orange">Train one deterministic NN</span></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-training-span"><span style="color:LightGreen">Training</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-evaluate-span"><span style="color:LightGreen">Evaluate</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-deep-ensemble-span"><span style="color:Orange">Deep Ensemble</span></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1"><span style="color:LightGreen">Training</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2"><span style="color:LightGreen">Evaluate</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-monte-carlo-dropout-span"><span style="color:Orange">Monte Carlo Dropout</span></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3"><span style="color:LightGreen">Training</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4"><span style="color:LightGreen">Evaluate</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-conformal-prediction-span"><span style="color:Orange">Conformal Prediction</span></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5"><span style="color:LightGreen">Training</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6"><span style="color:LightGreen">Evaluate</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-bayesian-neural-networks-span"><span style="color:Orange">Bayesian Neural Networks</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id7"><span style="color:Orange">Simulate data</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-getting-started-with-pyro-span"><span style="color:Orange">Getting Started with Pyro</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-bayesian-neural-network-with-gaussian-prior-and-likelihood-span"><span style="color:Orange">Bayesian Neural Network with Gaussian Prior and Likelihood</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-define-and-run-markov-chain-monte-carlo-sampler-span"><span style="color:Orange">Define and run Markov chain Monte Carlo sampler</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-exercise-1-deep-bayesian-neural-network-span"><span style="color:Orange"> Exercise 1: Deep Bayesian Neural Network</span></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-train-the-deep-bnn-with-mcmc-span"><span style="color:LightGreen">Train the deep BNN with MCMC</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-compute-predictive-distribution-span"><span style="color:LightGreen">Compute predictive distribution</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-train-bnns-with-mean-field-variational-inference-span"><span style="color:LightGreen">Train BNNs with mean-field variational inference</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-exercise-2-bayesian-updating-with-variational-inference-span"><span style="color:Orange">Exercise 2: Bayesian updating with variational inference</span></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-bayesian-update-span"><span style="color:LightGreen">Bayesian update</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-implementation-in-pyro-span"><span style="color:LightGreen">Implementation in Pyro</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-exercise-2-1-learn-a-model-on-the-old-observations-span"><span style="color:LightGreen">Exercise 2.1 Learn a model on the old observations</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-exercise-2-2-initialize-a-second-model-with-the-variational-parameters-span"><span style="color:LightGreen">Exercise 2.2 Initialize a second model with the variational parameters</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-exercise-2-3-perform-variational-inference-on-the-new-model-span"><span style="color:LightGreen">Exercise 2.3 Perform variational inference on the new model</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id8"></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-acknowledgments-span"><span style="color:Orange">Acknowledgments</span></a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Mark Neubauer
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>