

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Normalizing Flows &#8212; PHYS 498 MLP</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_sources/lectures/NormalizingFlows';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Simulation Based Inference" href="SimulationBasedInference.html" />
    <link rel="prev" title="Diffusion Models" href="Diffusion.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.png" class="logo__image only-light" alt="PHYS 498 MLP - Home"/>
    <script>document.write(`<img src="../../_static/logo.png" class="logo__image only-dark" alt="PHYS 498 MLP - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    <span style="color:Blue">Machine Learning for Physics</span>
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_01.html"><span style="color: blue;"><b>Introduction to Data Science</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1cQJycGyQ07qSOoeskr6GjjTD3byIkxDbdi228NRgFeU/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="JupyterNumpy.html">Jupyter Notebooks and Numerical Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="Pandas.html">Handling Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="Visualization.html">Visualizing Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="Clustering.html">Finding Structure in Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="Dimensionality.html">Measuring and Reducing Dimensionality</a></li>
<li class="toctree-l2"><a class="reference internal" href="Nonlinear.html">Adapting Linear Methods to Non-Linear Data and Kernel Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_01.html">Homework 01: Introduction to Data Science</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_02.html"><span style="color: blue;"><b>Probability Theory and Density Estimation</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1o9tM9ppKZWIa9B3WIHy5JDF4myR5NkO02W6WAlyiTSg/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="ProbabilityTheory.html">Probability Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="ProbabilityDistributions.html">Important Probability Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="DensityEstimation.html">Estimating Probability Density from Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_02.html">Homework 02: Probability Theory and Density Estimation</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_03.html"><span style="color: blue;"><b>Bayesian Statistics I</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1h2SMuH-Z5a_OE6UMDbFjysEiL2NmYT1tGww6VF5jzsA/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="Statistics.html">Statistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="BayesianInference.html">Bayesian Statistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="MarkovChainMonteCarlo.html">Markov Chain Monte Carlo in Practice</a></li>
<li class="toctree-l2"><a class="reference internal" href="MarkovChains.html">Stochastic Processes and Markov-Chain Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_03.html">Homework 03: Bayesian Statistics and Markov Chains</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_04.html"><span style="color: blue;"><b>Bayesian Statistics II</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/18bft9_CiBLjjBy0MHvT_vN7E95kfakvhm_7d7WKHXyY/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="ModelSelection.html">Bayesian Model Selection</a></li>
<li class="toctree-l2"><a class="reference internal" href="VariationalInference.html">Variational Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="Optimization.html">Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="CrossValidation.html">Cross Validation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_04.html">Homework 04: Metropolis-Hastings and Cross Validation</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_05.html"><span style="color: blue;"><b>Introduction to Artificial Intelligence</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1by3-6jDEorKi7_WEr6PTMfEBE8f4xrS94fNdtSuATVg/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="SupervisedLearning.html">Supervised Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="Learning.html">Artificial Intelligence and Machine Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="ArtificialNeuralNetworks.html">Artificial Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="DeepLearning.html">Deep Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_05.html">Homework 05: Artificial Neural Networks</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_06.html"><span style="color: blue;"><b>Convolutional and Recurrent Neural Networks</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1cDFVtEVGLaWd4256OShSb3Roto0x4y4GwG6LkhVozg0/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="ConvolutionalRecurrentNeuralNetworks.html">Convolutional and Recurrent Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_06.html">Homework 06: Forecasting Projectile Motion with Recurrent Neural Networks</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_07.html"><span style="color: blue;"><b>Geometric Deep Learning and Graph Neural Networks</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1jK61M3QGH7bxFU7TMBm16G3YDb-7HOFtgNdqlj3Gs38/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="GraphNeuralNetworks.html">Geometric Deep Learning and Graph Neural Networks</a></li>





</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_08.html"><span style="color: blue;"><b>Attention Mechanism and Transformers</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1ZHuK7TopASFSoyUoELKeCGT8bullhtSLcEkrp4ZueGg/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="Attention.html">Attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="Transformers.html">Transformers</a></li>
<li class="toctree-l2"><a class="reference internal" href="VisionTransformer.html">Vision Transformer</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Project_01.html"><span style="color: blue;"><b>Project 01</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_01_HiggsTauTau.html">Higgs Boson Decaying to Tau Leptons</a></li>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_01_ExoticParticles.html">Searching for Exotic Particles</a></li>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_01_GalaxyZoo.html">Galaxy Zoo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_01_NuclearGeometryQGP.html">Nuclear Geometry and Characterization of the Quark Gluon Plasma</a></li>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_01_AberratedImages.html">Aberrated Image Recovery of Ultracold Atoms</a></li>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_01_DarkEnergySurvey.html">Dark Energy Survey</a></li>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_01_GravitationalWaves.html">Detection of Gravitational Waves</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../Week_09.html"><span style="color: blue;"><b>Generative Modeling and Simulation-Based Inference</b></span></a><input checked="" class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1h13YeUjtTU_WHLxghxFBBQJO3uRr1GtsIyO4DVZviJo/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="GenerativeModeling.html">Generative Modeling</a></li>
<li class="toctree-l2"><a class="reference internal" href="AutoEncoders.html">Autoencoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="VariationalAutoEncoders.html">Variational AutoEncoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="GenerativeAdversarialNetworks.html">Generative Adversarial Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="Diffusion.html">Diffusion Models</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Normalizing Flows</a></li>
<li class="toctree-l2"><a class="reference internal" href="SimulationBasedInference.html">Simulation Based Inference</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_10.html"><span style="color: blue;"><b>Reinforcement Learning</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1EsW71u3hdNdXyhlDfkmOX__9c4wJZUee_pjlsmlv_Vg/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="ReinforcementLearning.html">Reinforcement Learning</a></li>




<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_07.html">Homework 07: Reinforcement Learning: Implementing a Deep Q-Network</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_11.html"><span style="color: blue;"><b>AI Explainablility and Uncertainty Quantification</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1ydzY7IEYzALTR6ez5gvwwKDduf_7wUtZddq0SUSuvI0/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="AIExplainabilityUncertaintyQuantification.html">AI Explainability and Uncertainty Quantification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_08.html">Homework 08: Detecting Distribution Shift on MNIST using Bayesian Neural Networks</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_12.html"><span style="color: blue;"><b>Unsupervised Learning and Anomaly Detection</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1ydzY7IEYzALTR6ez5gvwwKDduf_7wUtZddq0SUSuvI0/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="UnsupervisedLearningAnomalyDetection.html">Unsupervised Learning and Anomaly Detection</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_13.html"><span style="color: blue;"><b>Physics Informed Neural Networks</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1C-Z8b6WP5rE8yohZQdSxyH8O_bHIbllq97QhEJYyh0w/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="PhysicsInformedNeuralNetworks.html">Physics Informed Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="LearningTheSchrodingerEquation.html">Solving the Time Dependent Schrodinger Equation with Physics-Informed Deep Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="SymbolicRegression.html">Introduction to Symbolic Regression</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Project_02.html"><span style="color: blue;"><b>Project 02</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_02_AnisotropyQGP.html">Anisotropy in the Quark Gluon Plasma</a></li>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_02_AberratedImages.html">Aberrated Image Recovery of Ultracold Atoms</a></li>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_02_Radiotherapy.html">Beam Angle Optimization for Radiative Cancer Therapy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_02_TailPulsePileupRejection.html">Precision Neutron Counting with Tail Pulse Pileup Rejection</a></li>






<li class="toctree-l2"><a class="reference internal" href="../projects/Project_02_BentPipeSurrogate.html">Fluid Dynamics of a Bent Pipe</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_14.html"><span style="color: blue;"><b>Learning from the Machines</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1hkfaU7JVy1f5S8jURZvTY67KRzP7I8zGRf4Zku_bpM4/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="LearningPhysicsMachines.html">Learning Physics from the Machines</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_15.html"><span style="color: blue;"><b>Future of AI and Physics: What Lies Ahead?</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-17"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1eB1qCn5J07D5he_DCpkBiKjbVjdI6OexUzMQ351GCaI/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="LookingForward.html">Future of AI and Physics: What Lies Ahead?</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/illinois-mlp/MachineLearningForPhysics/blob/main/_sources/lectures/NormalizingFlows.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>



<a href="https://github.com/illinois-mlp/MachineLearningForPhysics" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/_sources/lectures/NormalizingFlows.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Normalizing Flows</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-overview-span"><span style="color:Orange">Overview</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-normalizing-flows-as-a-generative-model-span"><span style="color:Orange">Normalizing Flows as a Generative Model</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-key-elements-and-implementation-span"><span style="color:Orange">Key Elements and Implementation</span></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-invertible-transformation-span"><span style="color:LightGreen">Invertible transformation</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-jacobian-matrix-and-determinant-span"><span style="color:LightGreen">Jacobian Matrix and Determinant</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-architectures-span"><span style="color:LightGreen">Architectures</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-pytorch-distributions-span"><span style="color:LightGreen">PyTorch Distributions</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-transforming-distributions-span"><span style="color:Orange">Transforming distributions</span></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-change-of-variables-and-flow-span"><span style="color:LightGreen">Change of Variables and Flow</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-chaining-variable-transforms-flows-span"><span style="color:LightGreen">Chaining Variable Transforms (flows)</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-normalizing-flows-span"><span style="color:Orange">Normalizing Flows</span></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-planar-flow-span"><span style="color:LightGreen">Planar Flow</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-visualizing-parameters-effects-span"><span style="color:LightGreen">Visualizing Parameters Effects</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-optimizing-normalizing-flows-span"><span style="color:Orange">Optimizing Normalizing Flows</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-references-span"><span style="color:Orange">References</span></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-inspirations-and-resources-span"><span style="color:LightGreen">Inspirations and resources</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-acknowledgments-span"><span style="color:Orange">Acknowledgments</span></a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="normalizing-flows">
<h1>Normalizing Flows<a class="headerlink" href="#normalizing-flows" title="Permalink to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span><span class="p">;</span> <span class="n">sns</span><span class="o">.</span><span class="n">set_theme</span><span class="p">()</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">scipy.stats</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="span-style-color-orange-overview-span">
<h2><span style="color:Orange">Overview</span><a class="headerlink" href="#span-style-color-orange-overview-span" title="Permalink to this heading">#</a></h2>
<p>One of the key goals in modern generative models is to find ways of optimizing the probability distribution of a given set of data. To train a model, we typically tune its parameters to maximise the probability of the training dataset under the model. However, most of the real-world distributions that we are interested into are too complex and do not have a closed-form analytical solution. Hence, Gaussians are widely used, but often prove to be too simple to model complex datasets.</p>
<p>The idea of <em><strong><span style="color:violet">Normalizing Flows</span></strong></em> [<span class="xref myst">1</span>,<span class="xref myst">2</span>] has been formalized to address this problem and be able to rely on richer probability distributions. The main idea is to start from a simple probability distribution and approximate a complex multimodal density by <em>transforming</em> the simpler density through a sequence of invertible nonlinear transforms. By repeatedly applying the rule for change of variables, the initial density ‘flows’ through the sequence of invertible mappings. At the end of this sequence we obtain a valid probability distribution and hence this type of flow is referred to as a normalizing flow. This allows to rely on distributions of arbitrary complexity and also learn the parameters of these transforms depending only on some mild conditions.</p>
<p>Two examples of transformations of a Unit Gaussian and Uniform distribution using Normalizing Flows are shown below:</p>
<div>
<img src="https://raw.githubusercontent.com/illinois-mlp/MachineLearningForPhysics/main/img/NormalizingFlows-examples.png" width=1000></img>
</div><p>Normalizing flows typically utilize neural networks to implement the transformation functions that map a simple distribution to a more complex one, allowing them to learn complex data distributions; essentially, the “flow” in a normalizing flow is often modeled by a neural network, making it a key component of the method.</p>
</section>
<section id="span-style-color-orange-normalizing-flows-as-a-generative-model-span">
<h2><span style="color:Orange">Normalizing Flows as a Generative Model</span><a class="headerlink" href="#span-style-color-orange-normalizing-flows-as-a-generative-model-span" title="Permalink to this heading">#</a></h2>
<p>In the previous lectures, we have seen Variational Autoencoders (VAEs), Generative Adversarial Networks (GANs) and Diffusion-based models as examples of generative models. However, none of them explicitly learn the probability density function <span class="math notranslate nohighlight">\(p(x)\)</span> of the real input data. While VAEs model a lower bound, diffusion-based models only implicitly learn the probability density. GANs on the other hand provide us a sampling mechanism for generating new data, without offering a likelihood estimate.</p>
<p>The generative model we will look at here, called <span style="color:violet">Normalizing Flows</span>, actually models the true data distribution <span class="math notranslate nohighlight">\(p(x)\)</span> and provides us with an exact likelihood estimate. Below, we can visually compare VAEs, GANs and Flows
(figure credit - <a class="reference external" href="https://lilianweng.github.io/lil-log/2018/10/13/flow-based-deep-generative-models.html">Lilian Weng</a>):</p>
<div>
<img src="https://raw.githubusercontent.com/illinois-mlp/MachineLearningForPhysics/main/img/NormalizingFlows-comparison_GAN_VAE_NF.png" width=1000></img>
</div><p>The major difference compared to VAEs is that flows use <span style="color:violet">invertible</span> functions <span class="math notranslate nohighlight">\(f\)</span> to map the input data <span class="math notranslate nohighlight">\(x\)</span> to a latent representation <span class="math notranslate nohighlight">\(z\)</span>. To realize this, <span class="math notranslate nohighlight">\(z\)</span> must be of the same shape as <span class="math notranslate nohighlight">\(x\)</span>. This is in contrast to VAEs where <span class="math notranslate nohighlight">\(z\)</span> is usually much lower dimensional than the original input data. However, an invertible mapping also means that for every data point <span class="math notranslate nohighlight">\(x\)</span>, we have a corresponding latent representation <span class="math notranslate nohighlight">\(z\)</span> which allows us to perform lossless reconstruction (<span class="math notranslate nohighlight">\(z\)</span> to <span class="math notranslate nohighlight">\(x\)</span>). In the visualization above, this means that <span class="math notranslate nohighlight">\(x=x'\)</span> for flows, no matter what invertible function <span class="math notranslate nohighlight">\(f\)</span> and input <span class="math notranslate nohighlight">\(x\)</span> we choose.</p>
<p>Nonetheless, how are normalizing flows modeling a probability density with an invertible function? The answer to this question is the rule for change of variables. Specifically, given a prior density <span class="math notranslate nohighlight">\(p_z(z)\)</span> (e.g. Gaussian) and an invertible function <span class="math notranslate nohighlight">\(f\)</span>, we can determine <span class="math notranslate nohighlight">\(p_x(x)\)</span> as follows:</p>
<div class="math notranslate nohighlight">
\[\begin{split} \Large
\begin{split}
    \int p_x(x) dx &amp; = \int p_z(z) dz = 1 \hspace{1cm}\text{(by definition of a probability distribution)}\\
    \Leftrightarrow p_x(x) &amp; = p_z(z) \left|\frac{dz}{dx}\right| = p_z(f(x)) \left|\frac{df(x)}{dx}\right|
\end{split}
\end{split}\]</div>
<p>Hence, in order to determine the probability of <span class="math notranslate nohighlight">\(x\)</span>, we only need to determine its probability in latent space, and get the derivative of <span class="math notranslate nohighlight">\(f\)</span>.</p>
<p>Note that this is for a univariate distribution, and <span class="math notranslate nohighlight">\(f\)</span> is required to be invertible and smooth. For a multivariate case, the derivative becomes a Jacobian of which we need to take the determinant. As we usually use the log-likelihood as objective, we write the multivariate term with logarithms below:</p>
<div class="math notranslate nohighlight">
\[ \Large
\log p_x(\mathbf{x}) = \log p_z(f(\mathbf{x})) + \log{} \left|\det \frac{df(\mathbf{x})}{d\mathbf{x}}\right|
\]</div>
<p>Although we now know how a normalizing flow obtains its likelihood, it might not be clear what a normalizing flow does intuitively. For this, we should look from the inverse perspective of the flow starting with the prior probability density <span class="math notranslate nohighlight">\(p_z(z)\)</span>. If we apply an invertible function on it, we effectively “transform” its probability density.</p>
<p>For instance, if <span class="math notranslate nohighlight">\(f^{-1}(z)=z+1\)</span>, we shift the density by one while still remaining a valid probability distribution, and being invertible. We can also apply more complex transformations, like scaling: <span class="math notranslate nohighlight">\(f^{-1}(z)=2z+1\)</span>, but there you might see a difference. When you scale, you also change the volume of the probability density, as for example on uniform distributions (figure credit - <a class="reference external" href="https://blog.evjang.com/2018/01/nf1.html">Eric Jang</a>):</p>
<div>
<img src="https://raw.githubusercontent.com/illinois-mlp/MachineLearningForPhysics/main/img/NormalizingFlows-uniform_flow.png" width=600></img>
</div><p>You can see that the height of <span class="math notranslate nohighlight">\(p(y)\)</span> should be lower than <span class="math notranslate nohighlight">\(p(x)\)</span> after scaling. This change in volume represents <span class="math notranslate nohighlight">\(\left|\frac{df(x)}{dx}\right|\)</span> in our equation above, and ensures that even after scaling, we still have a valid probability distribution.</p>
<p>We can go on with making our function <span class="math notranslate nohighlight">\(f\)</span> more complex. However, the more complex <span class="math notranslate nohighlight">\(f\)</span> becomes, the harder it will be to find the inverse <span class="math notranslate nohighlight">\(f^{-1}\)</span> of it, and to calculate the log-determinant of the Jacobian <span class="math notranslate nohighlight">\(\log{} \left|\det \frac{df(\mathbf{x})}{d\mathbf{x}}\right|\)</span>.</p>
<p>An easier trick to stack multiple invertible functions <span class="math notranslate nohighlight">\(f_{1,...,K}\)</span> after each other, as all together, they still represent a single, invertible function. Using multiple, learnable invertible functions, a normalizing flow attempts to transform <span class="math notranslate nohighlight">\(p_z(z)\)</span> slowly into a more complex distribution which should finally be <span class="math notranslate nohighlight">\(p_x(x)\)</span>. We visualize the idea below
(figure credit - <a class="reference external" href="https://lilianweng.github.io/lil-log/2018/10/13/flow-based-deep-generative-models.html">Lilian Weng</a>):</p>
<div>
<img src="https://raw.githubusercontent.com/illinois-mlp/MachineLearningForPhysics/main/img/NormalizingFlows-normalizing_flow_layou.png" width=1000></img>
</div><p>Starting from <span class="math notranslate nohighlight">\(z_0\)</span>, which follows the prior Gaussian distribution, we sequentially apply the invertible functions <span class="math notranslate nohighlight">\(f_1,f_2,...,f_K\)</span>, until <span class="math notranslate nohighlight">\(z_K\)</span> represents <span class="math notranslate nohighlight">\(x\)</span>. Note that in the figure above, the functions <span class="math notranslate nohighlight">\(f\)</span> represent the inverted function from <span class="math notranslate nohighlight">\(f\)</span> we had above (here: <span class="math notranslate nohighlight">\(f:Z\to X\)</span>, above: <span class="math notranslate nohighlight">\(f:X\to Z\)</span>). This is just a different notation and has no impact on the actual flow design because all <span class="math notranslate nohighlight">\(f\)</span> need to be invertible anyways.</p>
<p>When we estimate the log likelihood of a data point <span class="math notranslate nohighlight">\(x\)</span> as in the equations above, we run the flows in the opposite direction than visualized above. Multiple flow layers have been proposed that use a neural network as learnable parameters, such as the planar and radial flow. However, we will focus here on flows that are commonly used in image modeling, and will discuss them in the rest of the notebook along with the details of how to train a normalizing flow.</p>
</section>
<section id="span-style-color-orange-key-elements-and-implementation-span">
<h2><span style="color:Orange">Key Elements and Implementation</span><a class="headerlink" href="#span-style-color-orange-key-elements-and-implementation-span" title="Permalink to this heading">#</a></h2>
<section id="span-style-color-lightgreen-invertible-transformation-span">
<h3><span style="color:LightGreen">Invertible transformation</span><a class="headerlink" href="#span-style-color-lightgreen-invertible-transformation-span" title="Permalink to this heading">#</a></h3>
<p><span style="color:violet">Invertible transformation</span>: The core idea of normalizing flows is to use a series of invertible transformations to map a simple distribution (like a Gaussian) to a more complex target distribution, and these transformations are often implemented using neural networks.</p>
</section>
<section id="span-style-color-lightgreen-jacobian-matrix-and-determinant-span">
<h3><span style="color:LightGreen">Jacobian Matrix and Determinant</span><a class="headerlink" href="#span-style-color-lightgreen-jacobian-matrix-and-determinant-span" title="Permalink to this heading">#</a></h3>
<p><span style="color:violet">Jacobian Matrix</span>: of a vector-valued function in several variables, the Jacobian generalizes the gradient of a scalar-valued function in several variables, which in turn generalizes the derivative of a scalar-valued function of a single variable. In other words, the Jacobian matrix of a scalar-valued function in several variables is (the transpose of) its gradient and the gradient of a scalar-valued function of a single variable is its derivative.</p>
<p>At each point where a function is differentiable, its Jacobian matrix can also be thought of as describing the amount of “stretching”, “rotating” or “transforming” that the function imposes locally near that point.</p>
<div>
<img src="https://raw.githubusercontent.com/illinois-mlp/MachineLearningForPhysics/main/img/NormalizingFlows-Jacobian.png" width=800></img>
</div><p><span style="color:violet">Jacobian determinant</span>: The determinant of the Jacobian matrix.</p>
<p>The Jacobian determinant is used when making a change of variables when evaluating a multiple integral of a function over a region within its domain. To accommodate for the change of coordinates the magnitude of the Jacobian determinant arises as a multiplicative factor within the integral. This is because the <span class="math notranslate nohighlight">\(n\)</span>-dimensional <span class="math notranslate nohighlight">\(dV\)</span> element is in general a parallelepiped in the new coordinate system, and the <span class="math notranslate nohighlight">\(n\)</span>-volume of a parallelepiped is the determinant of its edge vectors.</p>
<div>
<img src="https://raw.githubusercontent.com/illinois-mlp/MachineLearningForPhysics/main/img/NormalizingFlows-JacobianDeterminant.png" width=600></img>
</div><p>A nonlinear map <span class="math notranslate nohighlight">\(f\)</span> sends a small square (left, in red) to a distorted parallelogram (right, in red). The Jacobian at a point gives the best linear approximation of the distorted parallelogram near that point (right, in translucent white), and the Jacobian determinant gives the ratio of the area of the approximating parallelogram to that of the original square.</p>
<p>When applying a neural network transformation, the Jacobian determinant needs to be calculated to ensure the change of variables formula can be used to compute the probability density of the transformed data.</p>
</section>
<section id="span-style-color-lightgreen-architectures-span">
<h3><span style="color:LightGreen">Architectures</span><a class="headerlink" href="#span-style-color-lightgreen-architectures-span" title="Permalink to this heading">#</a></h3>
<p>Popular normalizing flow architectures like <span style="color:violet">planar flows</span> or <span style="color:violet">masked autoregressive flows</span> rely on neural networks to define the transformation functions.</p>
</section>
<section id="span-style-color-lightgreen-pytorch-distributions-span">
<h3><span style="color:LightGreen">PyTorch Distributions</span><a class="headerlink" href="#span-style-color-lightgreen-pytorch-distributions-span" title="Permalink to this heading">#</a></h3>
<p><a id="distribs"></a></p>
<p>In this lecture, we are going to rely on the novel <a class="reference external" href="https://pytorch.org/docs/stable/_modules/torch/distributions/">PyTorch distributions module</a>, which is defined in <code class="docutils literal notranslate"><span class="pre">torch.distributions</span></code>. Most notably, we are going to rely both on the <code class="docutils literal notranslate"><span class="pre">Distribution</span></code> and <code class="docutils literal notranslate"><span class="pre">Transform</span></code> objects.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.distributions</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">distrib</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.distributions.transforms</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">transform</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define grids of points (for later plots)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="p">[</span><span class="n">z</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">z</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>Inside this toolbox, we can already find some of the major probability distributions that we are used to deal with</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="n">distrib</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">distrib</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="n">probs</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.5</span><span class="p">]))</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">distrib</span><span class="o">.</span><span class="n">Beta</span><span class="p">(</span><span class="n">concentration1</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.5</span><span class="p">]),</span> <span class="n">concentration0</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.5</span><span class="p">]))</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">distrib</span><span class="o">.</span><span class="n">Gamma</span><span class="p">(</span><span class="n">concentration</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">]),</span> <span class="n">rate</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">]))</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">distrib</span><span class="o">.</span><span class="n">Pareto</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">]),</span> <span class="n">scale</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">]))</span>
</pre></div>
</div>
</div>
</div>
<p>The interesting aspect of these <code class="docutils literal notranslate"><span class="pre">Distribution</span></code> objects is that we can both obtain some samples from it through the <code class="docutils literal notranslate"><span class="pre">sample</span></code> (or <code class="docutils literal notranslate"><span class="pre">sample_n</span></code>) function, but we can also obtain the analytical density at any given point through the <code class="docutils literal notranslate"><span class="pre">log_prob</span></code> function</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Based on a normal</span>
<span class="n">n</span> <span class="o">=</span> <span class="n">distrib</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="c1"># Obtain some samples</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">n</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">1000</span><span class="p">,</span> <span class="p">))</span>
<span class="c1"># Evaluate true density at given points</span>
<span class="n">density</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">n</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="c1"># Plot both samples and density</span>
<span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">);</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Empirical samples&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">);</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">density</span><span class="p">);</span> <span class="n">ax2</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">density</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;True density&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/ea8263e9a5da62ff8d559ad7c5abaa025f6a55283ab14a453684c2c39af3e0ea.png" src="../../_images/ea8263e9a5da62ff8d559ad7c5abaa025f6a55283ab14a453684c2c39af3e0ea.png" />
</div>
</div>
</section>
</section>
<section id="span-style-color-orange-transforming-distributions-span">
<h2><span style="color:Orange">Transforming distributions</span><a class="headerlink" href="#span-style-color-orange-transforming-distributions-span" title="Permalink to this heading">#</a></h2>
<section id="span-style-color-lightgreen-change-of-variables-and-flow-span">
<h3><span style="color:LightGreen">Change of Variables and Flow</span><a class="headerlink" href="#span-style-color-lightgreen-change-of-variables-and-flow-span" title="Permalink to this heading">#</a></h3>
<p>In order to transform a probability distribution, we can perform a <span style="color:violet">change of variable</span>. In general, change of variables can be performed in any number of ways. However, here we are interested in probability distributions, which means that we need to <em>scale</em> our transformed density so that the total probability still sums to one. This is directly measured with the determinant of our transform (if you need more intuitive examples, you can check the great <a class="reference external" href="https://blog.evjang.com/2018/01/nf1.html">Eric Jang’s tutorial</a>).Hence, we can transform a probability distribution by using an invertible mapping and somehow scaling by the determinant of this mapping.</p>
<p>Let <span class="math notranslate nohighlight">\(\mathbf{z}\in\mathcal{R}^d\)</span> be a random variable with distribution <span class="math notranslate nohighlight">\(q(\mathbf{z})\)</span> and <span class="math notranslate nohighlight">\(f:\mathcal{R}^d\rightarrow\mathcal{R}^d\)</span> an invertible smooth mapping (meaning that <span class="math notranslate nohighlight">\(f^{-1} = g\)</span> and <span class="math notranslate nohighlight">\(g\circ f(\mathbf{z})=\mathbf{z}'\)</span>). We can use <span class="math notranslate nohighlight">\(f\)</span> to transform <span class="math notranslate nohighlight">\(\mathbf{z}\sim q(\mathbf{z})\)</span>. The resulting random variable <span class="math notranslate nohighlight">\(\mathbf{z}'=f(\mathbf{z})\)</span> has the following probability distribution</p>
<div class="math notranslate nohighlight">
\[ \Large
q(\mathbf{z}')=q(\mathbf{z})\left|\text{ det}\frac{\delta f^{-1}}{\delta \mathbf{z}'}\right| = q(\mathbf{z})\left|\text{ det}\frac{\delta f}{\delta \mathbf{z}}\right|^{-1}
\]</div>
<p>where the last equality is obtained through the inverse function theorem [1].</p>
<p>Fortunately, this can be easily implemented in PyTorch with the <code class="docutils literal notranslate"><span class="pre">Transform</span></code> classes, that already defines some basic probability distribution transforms. For instance, if we define <span class="math notranslate nohighlight">\(\mathbf{z}\sim q_0(\mathbf{z})=\mathcal{N}(0, 1)\)</span>, we can apply the transform <span class="math notranslate nohighlight">\(\mathbf{z}'=exp(\mathbf{z})\)</span> so that <span class="math notranslate nohighlight">\(\mathbf{z}'\sim q_1(\mathbf{z}')\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">q0</span> <span class="o">=</span> <span class="n">distrib</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">exp_t</span> <span class="o">=</span> <span class="n">transform</span><span class="o">.</span><span class="n">ExpTransform</span><span class="p">()</span>
<span class="n">q1</span> <span class="o">=</span> <span class="n">distrib</span><span class="o">.</span><span class="n">TransformedDistribution</span><span class="p">(</span><span class="n">q0</span><span class="p">,</span> <span class="n">exp_t</span><span class="p">)</span>
<span class="n">samples_q0</span> <span class="o">=</span> <span class="n">q0</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="nb">int</span><span class="p">(</span><span class="mf">1e4</span><span class="p">),))</span>
<span class="n">samples_q1</span> <span class="o">=</span> <span class="n">q1</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="nb">int</span><span class="p">(</span><span class="mf">1e4</span><span class="p">),))</span>
<span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">samples_q0</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">);</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;$q_0 = \mathcal</span><span class="si">{N}</span><span class="s1">(0,1)$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">);</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">samples_q1</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">);</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;$q_1=exp(q_0)$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/92b0bbfece70badaec422ccec072d1c7c0c739abebaaa5c045d2f81dcd992d61.png" src="../../_images/92b0bbfece70badaec422ccec072d1c7c0c739abebaaa5c045d2f81dcd992d61.png" />
</div>
</div>
<p>But remember as the objects <code class="docutils literal notranslate"><span class="pre">q0</span></code> and <code class="docutils literal notranslate"><span class="pre">q1</span></code> are defined as <code class="docutils literal notranslate"><span class="pre">Distribution</span></code>, we can actually observe their true densities instead of just empirical samples</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">q0_density</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">q0</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="c1"># Filter x to contain only positive values for LogNormal distribution</span>
<span class="n">x_positive</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span>  
<span class="n">q1_density</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">q1</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">x_positive</span><span class="p">)))</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> 
<span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">q0_density</span><span class="p">);</span> <span class="n">ax1</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">q0_density</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;$q_0 = \mathcal</span><span class="si">{N}</span><span class="s1">(0,1)$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">);</span>
<span class="c1"># Plot q1_density using x_positive</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_positive</span><span class="p">,</span> <span class="n">q1_density</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">);</span> <span class="n">ax2</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">x_positive</span><span class="p">,</span> <span class="n">q1_density</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">)</span> 
<span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;$q_1=exp(q_0)$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/20afdddd5884f718b4ba61c3bbca7e5ab88a9d9d4069921fac585fc2cf9c0f2d.png" src="../../_images/20afdddd5884f718b4ba61c3bbca7e5ab88a9d9d4069921fac585fc2cf9c0f2d.png" />
</div>
</div>
<p>What we obtain here with <code class="docutils literal notranslate"><span class="pre">q1</span></code> is actually the <code class="docutils literal notranslate"><span class="pre">LogNormal</span></code> distribution. Interestingly, several distributions in the <code class="docutils literal notranslate"><span class="pre">torch.distributions</span></code> module are already defined based on <code class="docutils literal notranslate"><span class="pre">TransformedDistribution</span></code>. You can convince yourself of that by lurking in the code of the <a class="reference external" href="https://pytorch.org/docs/stable/_modules/torch/distributions/log_normal.html#LogNormal"><code class="docutils literal notranslate"><span class="pre">torch.distributions.LogNormal</span></code></a></p>
</section>
<section id="span-style-color-lightgreen-chaining-variable-transforms-flows-span">
<h3><span style="color:LightGreen">Chaining Variable Transforms (flows)</span><a class="headerlink" href="#span-style-color-lightgreen-chaining-variable-transforms-flows-span" title="Permalink to this heading">#</a></h3>
<p><a id="chaining"></a>
Now, if we start with a random vector <span class="math notranslate nohighlight">\(\mathbf{z}_0\)</span> with distribution <span class="math notranslate nohighlight">\(q_0\)</span>, we can apply a series of mappings <span class="math notranslate nohighlight">\(f_i\)</span>, <span class="math notranslate nohighlight">\(i \in 1,\cdots,k\)</span> with <span class="math notranslate nohighlight">\(k\in\mathcal{N}^{+}\)</span> and obtain a normalizing flow. Hence, if we apply <span class="math notranslate nohighlight">\(k\)</span> normalizing flows, we obtain a chain of change of variables</p>
<div class="math notranslate nohighlight">
\[ \Large
\mathbf{z}_k=f_k\circ f_{k-1}\circ...\circ f_1(\mathbf{z}_0)
\]</div>
<p>Therefore the distribution of <span class="math notranslate nohighlight">\(\mathbf{z}_k\sim q_k(\mathbf{z}_k)\)</span> will be given by</p>
<div class="math notranslate nohighlight">
\[\begin{split} \Large
   \begin{align}
   q_k(\mathbf{z}_k) &amp;= q_0(f_1^{-1} \circ f_{2}^{-1} \circ ... \circ f_k^{-1}(\mathbf{z}_k))\prod_{i=1}^k\left|\text{det}\frac{\delta f^{-1}_i}{\delta\mathbf{z}_{i}}\right|\\
   &amp;= q_0(\mathbf{z_0})\prod_{i=1}^k\left|\text{det}\frac{\delta f_i}{\delta\mathbf{z}_{i-1}}\right|^{-1}
   \end{align}
   \end{split}\]</div>
<p>where we compute the determinant of the Jacobian of each normalizing flow (as explained in the previous section). This series of transformations can transform a simple probability distribution (e.g. Gaussian) into a complicated multi-modal one. As usual, we will rely on log-probabilities to simplify the computation and obtain</p>
<div class="math notranslate nohighlight">
\[ \Large
\text{log} q_K(\mathbf{z}_k) = \text{log} q_0(\mathbf{z}_0) - \sum_{i=1}^{k} \text{log} \left|\text{det}\frac{\delta f_i}{\delta\mathbf{z}_{i-1}}\right| 
\]</div>
<p>To be of practical use, however, we can consider only transformations whose determinants of Jacobians are easy to compute. Of course, we can perform any amount of combined transformations, and it also works with multivariate distributions. Here, this is demonstrated by transforming a <code class="docutils literal notranslate"><span class="pre">MultivariateNormal</span></code> successively with an <code class="docutils literal notranslate"><span class="pre">ExpTransform</span></code> and <code class="docutils literal notranslate"><span class="pre">AffineTransform</span></code>. An affine transform is a geometric transformation that preserves lines and parallelism, but not necessarily Euclidean distances and angles.</p>
<p><em><span style="color:violet">Note</span></em>: the final distribution <code class="docutils literal notranslate"><span class="pre">q2</span></code> is defined as a <code class="docutils literal notranslate"><span class="pre">TransformedDistribution</span></code> directly with a <em>sequence</em> of transformations)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.distributions</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">distrib</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.distributions.transforms</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">transform</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="n">q0</span> <span class="o">=</span> <span class="n">distrib</span><span class="o">.</span><span class="n">MultivariateNormal</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
<span class="c1"># Define an affine transform</span>
<span class="n">f1</span> <span class="o">=</span> <span class="n">transform</span><span class="o">.</span><span class="n">ExpTransform</span><span class="p">()</span>
<span class="n">q1</span> <span class="o">=</span> <span class="n">distrib</span><span class="o">.</span><span class="n">TransformedDistribution</span><span class="p">(</span><span class="n">q0</span><span class="p">,</span> <span class="n">f1</span><span class="p">)</span>
<span class="c1"># Define an additional transform</span>
<span class="n">f2</span> <span class="o">=</span> <span class="n">transform</span><span class="o">.</span><span class="n">AffineTransform</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">]))</span>
<span class="c1"># Here I define on purpose q2 as a sequence of transforms on q0</span>
<span class="n">q2</span> <span class="o">=</span> <span class="n">distrib</span><span class="o">.</span><span class="n">TransformedDistribution</span><span class="p">(</span><span class="n">q0</span><span class="p">,</span> <span class="p">[</span><span class="n">f1</span><span class="p">,</span> <span class="n">f2</span><span class="p">])</span>

<span class="c1"># Filter z to contain only positive values for LogNormal distribution</span>
<span class="n">z_positive</span> <span class="o">=</span> <span class="n">z</span><span class="p">[</span><span class="n">z</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span> <span class="c1"># Filter for positive values in the first column</span>
<span class="n">z_positive</span> <span class="o">=</span> <span class="n">z_positive</span><span class="p">[</span><span class="n">z_positive</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span> <span class="c1"># Filter for positive values in the second column</span>

<span class="c1"># Plot all these lads</span>
<span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">,</span> <span class="n">ax3</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">hexbin</span><span class="p">(</span><span class="n">z</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">z</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">C</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">q0</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">z</span><span class="p">))),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;rainbow&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;$q_0 = \mathcal</span><span class="si">{N}</span><span class="s1">(\mathbf</span><span class="si">{0}</span><span class="s1">,\mathbb</span><span class="si">{I}</span><span class="s1">)$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">);</span>

<span class="c1"># Filter values to be in the support of the transformed distributions</span>
<span class="c1"># Apply inverse transforms to check if the original values are valid</span>
<span class="n">z_q1_valid</span> <span class="o">=</span> <span class="n">z</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">f1</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">z</span><span class="p">))</span> <span class="o">&gt;</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span>
<span class="c1"># The change is in the next line: we filter z_q2_valid based on the support of q2</span>
<span class="c1"># Instead of using &gt; 0, we use &gt; -np.inf to allow for negative values that are still in the support of the distribution</span>
<span class="c1"># Apply the inverse of the composed transform to ensure values are within the support of q0</span>
<span class="n">z_q2_valid</span> <span class="o">=</span> <span class="n">z</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">transform</span><span class="o">.</span><span class="n">ComposeTransform</span><span class="p">([</span><span class="n">f2</span><span class="p">,</span> <span class="n">f1</span><span class="p">])</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">z</span><span class="p">))</span> <span class="o">&gt;</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span>  

<span class="n">ax2</span><span class="o">.</span><span class="n">hexbin</span><span class="p">(</span><span class="n">z_q1_valid</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">z_q1_valid</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">C</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">q1</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">z_q1_valid</span><span class="p">))),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;rainbow&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;$q_1=exp(q_0)$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">);</span>
<span class="c1"># Check if z_q2_valid is empty and handle it</span>
<span class="k">if</span> <span class="n">z_q2_valid</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Warning: z_q2_valid is empty. Skipping the plot for q2.&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="c1"># Filter z_q2_valid to be within the support of the transformed distribution</span>
    <span class="n">z_q2_valid_filtered</span> <span class="o">=</span> <span class="n">z_q2_valid</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">z_q2_valid</span><span class="p">)),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span>
    <span class="n">z_q2_valid_filtered</span> <span class="o">=</span> <span class="n">z_q2_valid_filtered</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">f1</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">transform</span><span class="o">.</span><span class="n">ComposeTransform</span><span class="p">([</span><span class="n">f2</span><span class="p">])</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">z_q2_valid_filtered</span><span class="p">)))</span> <span class="o">&gt;</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span>
    <span class="c1"># Calculate log_prob only for valid values</span>
    <span class="n">log_prob_q2</span> <span class="o">=</span> <span class="n">q2</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">z_q2_valid_filtered</span><span class="p">))</span>
    <span class="c1"># Filter out NaN values</span>
    <span class="n">valid_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">log_prob_q2</span><span class="p">)</span>
    <span class="n">z_q2_valid_filtered</span> <span class="o">=</span> <span class="n">z_q2_valid_filtered</span><span class="p">[</span><span class="n">valid_indices</span><span class="p">]</span>
    <span class="n">log_prob_q2</span> <span class="o">=</span> <span class="n">log_prob_q2</span><span class="p">[</span><span class="n">valid_indices</span><span class="p">]</span>

    <span class="n">ax3</span><span class="o">.</span><span class="n">hexbin</span><span class="p">(</span><span class="n">z_q2_valid_filtered</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">z_q2_valid_filtered</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">C</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_prob_q2</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;rainbow&#39;</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;$q_2=Affine(exp(q_0))$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/bb5b31b57a6b79ee4b316fcbd52b666b22f11a96c30cbda9ccb4cccd09394931.png" src="../../_images/bb5b31b57a6b79ee4b316fcbd52b666b22f11a96c30cbda9ccb4cccd09394931.png" />
</div>
</div>
</section>
</section>
<section id="span-style-color-orange-normalizing-flows-span">
<h2><span style="color:Orange">Normalizing Flows</span><a class="headerlink" href="#span-style-color-orange-normalizing-flows-span" title="Permalink to this heading">#</a></h2>
<p><a id="planar"></a>
Now, we are interested in normalizing flows as we could define our own flows. And, most importantly, we could optimize the parameters of these flow in order to fit complex and richer probability distributions. We will see how this plays out by trying to implement the <em>planar flow</em> proposed in the original paper by Rezende [1].</p>
<section id="span-style-color-lightgreen-planar-flow-span">
<h3><span style="color:LightGreen">Planar Flow</span><a class="headerlink" href="#span-style-color-lightgreen-planar-flow-span" title="Permalink to this heading">#</a></h3>
<p>A <span style="color:violet">planar normalizing flow</span> is defined as a function of the form</p>
<div class="math notranslate nohighlight">
\[ \Large
   f(\mathbf{z})=\mathbf{z}+\mathbf{u}h(\mathbf{w}^T\mathbf{z}+b)
   \]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{u}\in\mathbb{R}^D\)</span> and <span class="math notranslate nohighlight">\(\mathbf{w}\in\mathbb{R}^D\)</span> are vectors (called here scale and weight), <span class="math notranslate nohighlight">\(b\in\mathbb{R}\)</span> is a scalar (bias) and <span class="math notranslate nohighlight">\(h\)</span> is an activation function. These transform functions are chosen depending on the fact that:</p>
<ol class="arabic simple">
<li><p>the determinant of their Jacobian can be computed in linear time</p></li>
<li><p>the transformation is invertible (under usually mild conditions only)</p></li>
</ol>
<p>As shown in the paper, for the planar flow, the determinant of the Jacobian can be computed in <span class="math notranslate nohighlight">\(O(D)\)</span> time by relying on the matrix determinant lemma</p>
<div class="math notranslate nohighlight">
\[ \Large
\psi(\mathbf{z})=h'(\mathbf{w}^T\mathbf{z}+b)\mathbf{w}
\]</div>
<div class="math notranslate nohighlight">
\[ \Large
\left|\text{det}\frac{\delta f}{\delta\mathbf{z}}\right| = \left|\text{det}\left(\mathbf{I}+\mathbf{u}\psi(\mathbf{z})^{T}\right)\right|=\left|1+\mathbf{u}^T\psi(\mathbf{z})\right|
\]</div>
<p>Therefore, we have all definitions that we need to implement this flow as a <code class="docutils literal notranslate"><span class="pre">Transform</span></code> object. Note that here the non-linear activation function <span class="math notranslate nohighlight">\(h\)</span> is selected as a <span class="math notranslate nohighlight">\(tanh\)</span>. Therefore the derivative <span class="math notranslate nohighlight">\(h'\)</span> is <span class="math notranslate nohighlight">\(1-tanh(x)^2\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.distributions</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">distrib</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.distributions.transforms</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">transform</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.distributions</span><span class="w"> </span><span class="kn">import</span> <span class="n">constraints</span>

<span class="k">class</span><span class="w"> </span><span class="nc">PlanarFlow</span><span class="p">(</span><span class="n">transform</span><span class="o">.</span><span class="n">Transform</span><span class="p">):</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">bias</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PlanarFlow</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bijective</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">weight</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">bias</span>
        <span class="c1"># Define domain and codomain</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">domain</span> <span class="o">=</span> <span class="n">constraints</span><span class="o">.</span><span class="n">real</span>  <span class="c1"># Input domain is real numbers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">codomain</span> <span class="o">=</span> <span class="n">constraints</span><span class="o">.</span><span class="n">real</span> <span class="c1"># Output domain is real numbers</span>


    <span class="k">def</span><span class="w"> </span><span class="nf">_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">f_z</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">f_z</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">log_abs_det_jacobian</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">f_z</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
        <span class="n">psi</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">f_z</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span>
        <span class="n">det_grad</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">psi</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="o">.</span><span class="n">t</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">det_grad</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span> <span class="o">+</span> <span class="mf">1e-7</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>As before, we can witness the effect of this transform on a given <code class="docutils literal notranslate"><span class="pre">MultivariateNormal</span></code> distribution. You should note here that I am using the density estimation for <code class="docutils literal notranslate"><span class="pre">q0</span></code>, but only display empirical samples from <code class="docutils literal notranslate"><span class="pre">q1</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mf">3.</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">u</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">])</span>
<span class="n">q0</span> <span class="o">=</span> <span class="n">distrib</span><span class="o">.</span><span class="n">MultivariateNormal</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
<span class="n">flow_0</span> <span class="o">=</span> <span class="n">PlanarFlow</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="n">q1</span> <span class="o">=</span> <span class="n">distrib</span><span class="o">.</span><span class="n">TransformedDistribution</span><span class="p">(</span><span class="n">q0</span><span class="p">,</span> <span class="n">flow_0</span><span class="p">)</span>
<span class="n">q1_samples</span> <span class="o">=</span> <span class="n">q1</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="nb">int</span><span class="p">(</span><span class="mf">1e6</span><span class="p">),</span> <span class="p">))</span>
<span class="c1"># Plot this</span>
<span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">hexbin</span><span class="p">(</span><span class="n">z</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">z</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">C</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">q0</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">z</span><span class="p">))),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;rainbow&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;$q_0 = \mathcal</span><span class="si">{N}</span><span class="s1">(\mathbf</span><span class="si">{0}</span><span class="s1">,\mathbb</span><span class="si">{I}</span><span class="s1">)$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">);</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">hexbin</span><span class="p">(</span><span class="n">q1_samples</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">q1_samples</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;rainbow&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;$q_1=planar(q_0)$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/4f269aa7a243d181a43c486c9da386a73dda3fdc13f2b657892b1f5bf844caee.png" src="../../_images/4f269aa7a243d181a43c486c9da386a73dda3fdc13f2b657892b1f5bf844caee.png" />
</div>
</div>
<p>The reason for this is that the <code class="docutils literal notranslate"><span class="pre">PlanarFlow</span></code> is not invertible in all regions of the space. However, if we recall the mathematical reasoning of the previous section, we can see how the change of variables plays out if we are able to compute the determinant of the Jacobian of this transform.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">q0_density</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">q0</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">z</span><span class="p">)))</span>
<span class="c1"># Apply our transform on coordinates</span>
<span class="n">f_z</span> <span class="o">=</span> <span class="n">flow_0</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">z</span><span class="p">))</span>
<span class="c1"># Obtain our density</span>
<span class="n">q1_density</span> <span class="o">=</span> <span class="n">q0_density</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">flow_0</span><span class="o">.</span><span class="n">log_abs_det_jacobian</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">z</span><span class="p">))</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>
<span class="c1"># Plot this</span>
<span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">hexbin</span><span class="p">(</span><span class="n">z</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">z</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">C</span><span class="o">=</span><span class="n">q0_density</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;rainbow&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;$q_0 = \mathcal</span><span class="si">{N}</span><span class="s1">(\mathbf</span><span class="si">{0}</span><span class="s1">,\mathbb</span><span class="si">{I}</span><span class="s1">)$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">);</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">hexbin</span><span class="p">(</span><span class="n">f_z</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">f_z</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">C</span><span class="o">=</span><span class="n">q1_density</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;rainbow&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;$q_1=planar(q_0)$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/606cfb6e85bb1ed0d9d3cc1df0fc6ba8ef0c1aedfb69499f0b48f79efc3de721.png" src="../../_images/606cfb6e85bb1ed0d9d3cc1df0fc6ba8ef0c1aedfb69499f0b48f79efc3de721.png" />
</div>
</div>
<p>So we were able to “split” our distribution and transform a unimodal gaussian into a multimodal distribution ! Pretty neat</p>
</section>
<section id="span-style-color-lightgreen-visualizing-parameters-effects-span">
<h3><span style="color:LightGreen">Visualizing Parameters Effects</span><a class="headerlink" href="#span-style-color-lightgreen-visualizing-parameters-effects-span" title="Permalink to this heading">#</a></h3>
<p>Here, we provide a little toy example so that you can play around with the parameters of the flow in order to get a better understanding of how it operates. As put forward by Rezende [1], this flow is related to the hyperplane defined by <span class="math notranslate nohighlight">\(\mathbf{w}^{T}\mathbf{z}+b=0\)</span> and transforms the original density by applying a series of contractions and expansions in the direction perpendicular to this hyperplane.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">id_figure</span><span class="o">=</span><span class="mi">1</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">18</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <span class="c1"># Draw a random hyperplane</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="mi">5</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mi">5</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
        <span class="c1"># Different effects of scaling factor u on the same hyperplane (row)</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[((</span><span class="n">j</span> <span class="o">&lt;</span> <span class="mi">3</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">j</span> <span class="o">/</span> <span class="mf">2.0</span><span class="p">)</span> <span class="ow">or</span> <span class="mi">0</span><span class="p">),</span> <span class="p">((</span><span class="n">j</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">)</span> <span class="ow">and</span> <span class="p">((</span><span class="n">j</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="mf">2.0</span><span class="p">)</span> <span class="ow">or</span> <span class="mi">0</span><span class="p">)]])</span>
        <span class="n">flow_0</span> <span class="o">=</span> <span class="n">PlanarFlow</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
        <span class="n">q1</span> <span class="o">=</span> <span class="n">distrib</span><span class="o">.</span><span class="n">TransformedDistribution</span><span class="p">(</span><span class="n">q0</span><span class="p">,</span> <span class="n">flow_0</span><span class="p">)</span>
        <span class="n">q1_samples</span> <span class="o">=</span> <span class="n">q1</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="nb">int</span><span class="p">(</span><span class="mf">1e6</span><span class="p">),</span> <span class="p">))</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="n">id_figure</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">hexbin</span><span class="p">(</span><span class="n">q1_samples</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">q1_samples</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;rainbow&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;u=(</span><span class="si">%.1f</span><span class="s2">,</span><span class="si">%.1f</span><span class="s2">)&quot;</span><span class="o">%</span><span class="p">(</span><span class="n">u</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span><span class="n">u</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="s2">&quot; w=(</span><span class="si">%d</span><span class="s2">,</span><span class="si">%d</span><span class="s2">)&quot;</span><span class="o">%</span><span class="p">(</span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="s2">&quot;, &quot;</span> <span class="o">+</span> <span class="s2">&quot;b=</span><span class="si">%d</span><span class="s2">&quot;</span><span class="o">%</span><span class="k">b</span>)
        <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
        <span class="n">id_figure</span> <span class="o">+=</span> <span class="mi">1</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/d1de6c1a7782a749a99b9379a85739384f7af6022bef80405568fc93785112f6.png" src="../../_images/d1de6c1a7782a749a99b9379a85739384f7af6022bef80405568fc93785112f6.png" />
</div>
</div>
</section>
</section>
<section id="span-style-color-orange-optimizing-normalizing-flows-span">
<h2><span style="color:Orange">Optimizing Normalizing Flows</span><a class="headerlink" href="#span-style-color-orange-optimizing-normalizing-flows-span" title="Permalink to this heading">#</a></h2>
<p><a id="learning"></a>
Now that we have this magnificent tool, we would like to apply this in order to learn richer distributions and perform <em>inference</em>. Now, we have to deal with the fact that the <code class="docutils literal notranslate"><span class="pre">Transform</span></code> object is not inherently parametric and cannot yet be optimized similarly to other modules.</p>
<p>To do so, we will start by defining our own <code class="docutils literal notranslate"><span class="pre">Flow</span></code> class which can be seen both as a <code class="docutils literal notranslate"><span class="pre">Transform</span></code> and also a <code class="docutils literal notranslate"><span class="pre">Module</span></code>that can be optmized</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">Flow</span><span class="p">(</span><span class="n">transform</span><span class="o">.</span><span class="n">Transform</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">transform</span><span class="o">.</span><span class="n">Transform</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
    
    <span class="c1"># Init all parameters</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">init_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="o">-</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
            
    <span class="c1"># Hacky hash bypass</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__hash__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="o">.</span><span class="fm">__hash__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Thanks to this little trick, we can use the same <code class="docutils literal notranslate"><span class="pre">PlanarFlow</span></code> class as before, that we put back here just to show that the only change is that it now inherits from the <code class="docutils literal notranslate"><span class="pre">Flow</span></code> class (with the small added bonus that now parameters of this flow are also registered in the <code class="docutils literal notranslate"><span class="pre">Module</span></code> interface)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">PlanarFlow</span><span class="p">(</span><span class="n">Flow</span><span class="p">):</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PlanarFlow</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_parameters</span><span class="p">()</span>
        <span class="c1"># Define domain and codomain</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">domain</span> <span class="o">=</span> <span class="n">constraints</span><span class="o">.</span><span class="n">real</span>  <span class="c1"># Input domain is real numbers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">codomain</span> <span class="o">=</span> <span class="n">constraints</span><span class="o">.</span><span class="n">real</span> <span class="c1"># Output domain is real numbers</span>


    <span class="k">def</span><span class="w"> </span><span class="nf">_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">f_z</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">f_z</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">log_abs_det_jacobian</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">f_z</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
        <span class="n">psi</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">f_z</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span>
        <span class="n">det_grad</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">psi</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="o">.</span><span class="n">t</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">det_grad</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span> <span class="o">+</span> <span class="mf">1e-9</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now let’s say that we have a given complex density that we aim to model through normalizing flows, such as the following one</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">density_ring</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="n">z1</span><span class="p">,</span> <span class="n">z2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">chunks</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">z1</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="n">z2</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">exp1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="p">((</span><span class="n">z1</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="mf">0.8</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">exp2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="p">((</span><span class="n">z1</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="mf">0.8</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">((</span><span class="n">norm</span> <span class="o">-</span> <span class="mi">4</span><span class="p">)</span> <span class="o">/</span> <span class="mf">0.4</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">exp1</span> <span class="o">+</span> <span class="n">exp2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">u</span><span class="p">)</span>

<span class="c1"># Plot it</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="p">[</span><span class="n">z</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">z</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hexbin</span><span class="p">(</span><span class="n">z</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">z</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">C</span><span class="o">=</span><span class="n">density_ring</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">z</span><span class="p">))</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;rainbow&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Target density&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/19738b32cbf37841ccdf86a6791f8c0d08f97bf231872e6a7eee0b40c7384d64.png" src="../../_images/19738b32cbf37841ccdf86a6791f8c0d08f97bf231872e6a7eee0b40c7384d64.png" />
</div>
</div>
<p>Now to approximate such a complicated density, we will need to chain multiple planar flows and optimize their parameters to find a suitable approximation. We can do exactly that like in the following (you can see that we start by a simple normal density and perform 16 successive planar flows)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Main class for normalizing flow</span>
<span class="k">class</span><span class="w"> </span><span class="nc">NormalizingFlow</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">flow_length</span><span class="p">,</span> <span class="n">density</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">biject</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">flow_length</span><span class="p">):</span>
            <span class="n">biject</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">PlanarFlow</span><span class="p">(</span><span class="n">dim</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span> <span class="o">=</span> <span class="n">transform</span><span class="o">.</span><span class="n">ComposeTransform</span><span class="p">(</span><span class="n">biject</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bijectors</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">biject</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_density</span> <span class="o">=</span> <span class="n">density</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">final_density</span> <span class="o">=</span> <span class="n">distrib</span><span class="o">.</span><span class="n">TransformedDistribution</span><span class="p">(</span><span class="n">density</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_det</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_det</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># Applies series of flows</span>
        <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bijectors</span><span class="p">)):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log_det</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bijectors</span><span class="p">[</span><span class="n">b</span><span class="p">]</span><span class="o">.</span><span class="n">log_abs_det_jacobian</span><span class="p">(</span><span class="n">z</span><span class="p">))</span>
            <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bijectors</span><span class="p">[</span><span class="n">b</span><span class="p">](</span><span class="n">z</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_det</span>
    
<span class="c1"># Create normalizing flow</span>
<span class="n">flow</span> <span class="o">=</span> <span class="n">NormalizingFlow</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">flow_length</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="n">distrib</span><span class="o">.</span><span class="n">MultivariateNormal</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">2</span><span class="p">)))</span>
</pre></div>
</div>
</div>
</div>
<p>Now the only missing ingredient is the loss function that is simply defined as follows</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">loss</span><span class="p">(</span><span class="n">density</span><span class="p">,</span> <span class="n">zk</span><span class="p">,</span> <span class="n">log_jacobians</span><span class="p">):</span>
    <span class="n">sum_of_log_jacobians</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">log_jacobians</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="o">-</span><span class="n">sum_of_log_jacobians</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">density</span><span class="p">(</span><span class="n">zk</span><span class="p">)</span><span class="o">+</span><span class="mf">1e-9</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>We can now perform optimization as usual by defining an optimizer, the parameters it will act on and eventually a learning rate scheduler</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">optim</span>
<span class="c1"># Create optimizer algorithm</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">flow</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">2e-3</span><span class="p">)</span>
<span class="c1"># Add learning rate scheduler</span>
<span class="n">scheduler</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">ExponentialLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="mf">0.9999</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>And now we perform the loop by sampling a batch (here of 512) from the reference Normal distribution, and then evaluating our loss with respect to the density we want to approximate.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ref_distrib</span> <span class="o">=</span> <span class="n">distrib</span><span class="o">.</span><span class="n">MultivariateNormal</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
<span class="n">id_figure</span><span class="o">=</span><span class="mi">2</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">18</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hexbin</span><span class="p">(</span><span class="n">z</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">z</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">C</span><span class="o">=</span><span class="n">density_ring</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">z</span><span class="p">))</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;rainbow&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Target density&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">);</span>
<span class="c1"># Main optimization loop</span>
<span class="k">for</span> <span class="n">it</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10001</span><span class="p">):</span>
    <span class="c1"># Draw a sample batch from Normal</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="n">ref_distrib</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">512</span><span class="p">,</span> <span class="p">))</span>
    <span class="c1"># Evaluate flow of transforms</span>
    <span class="n">zk</span><span class="p">,</span> <span class="n">log_jacobians</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
    <span class="c1"># Evaluate loss and backprop</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">loss_v</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">density_ring</span><span class="p">,</span> <span class="n">zk</span><span class="p">,</span> <span class="n">log_jacobians</span><span class="p">)</span>
    <span class="n">loss_v</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">it</span> <span class="o">%</span> <span class="mi">1000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Loss (it. </span><span class="si">%i</span><span class="s1">) : </span><span class="si">%f</span><span class="s1">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">it</span><span class="p">,</span> <span class="n">loss_v</span><span class="o">.</span><span class="n">item</span><span class="p">()))</span>
        <span class="c1"># Draw random samples</span>
        <span class="n">samples</span> <span class="o">=</span> <span class="n">ref_distrib</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="nb">int</span><span class="p">(</span><span class="mf">1e5</span><span class="p">),</span> <span class="p">))</span>
        <span class="c1"># Evaluate flow and plot</span>
        <span class="n">zk</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">flow</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
        <span class="n">zk</span> <span class="o">=</span> <span class="n">zk</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="n">id_figure</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">hexbin</span><span class="p">(</span><span class="n">zk</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">zk</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;rainbow&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Iter.</span><span class="si">%i</span><span class="s1">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">it</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">);</span>
        <span class="n">id_figure</span> <span class="o">+=</span> <span class="mi">1</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Loss (it. 0) : 18.250095
Loss (it. 1000) : 1.947394
Loss (it. 2000) : 1.133390
Loss (it. 3000) : 1.006117
Loss (it. 4000) : 0.932710
Loss (it. 5000) : 0.885981
Loss (it. 6000) : 0.947523
Loss (it. 7000) : 0.850952
Loss (it. 8000) : 0.762654
Loss (it. 9000) : 0.853780
Loss (it. 10000) : 0.814227
</pre></div>
</div>
<img alt="../../_images/b0119f9104360fcef658ba79a803cc2d7b1c7b9c2ec49a4a5f06d7a4cce3ac4f.png" src="../../_images/b0119f9104360fcef658ba79a803cc2d7b1c7b9c2ec49a4a5f06d7a4cce3ac4f.png" />
</div>
</div>
</section>
<section id="span-style-color-orange-references-span">
<h2><span style="color:Orange">References</span><a class="headerlink" href="#span-style-color-orange-references-span" title="Permalink to this heading">#</a></h2>
<p><a id="reference1"></a>
[1] Rezende, Danilo Jimenez, and Shakir Mohamed. “Variational inference with normalizing flows.” <em>arXiv preprint arXiv:1505.05770</em> (2015). <a class="reference external" href="http://arxiv.org/pdf/1505.05770">link</a></p>
<p>[2] Kingma, Diederik P., Tim Salimans, and Max Welling. “Improving Variational Inference with Inverse Autoregressive Flow.” <em>arXiv preprint arXiv:1606.04934</em> (2016). <a class="reference external" href="https://arxiv.org/abs/1606.04934">link</a></p>
<p>[3] Germain, Mathieu, et al. “Made: masked autoencoder for distribution estimation.” International Conference on Machine Learning. 2015.</p>
<section id="span-style-color-lightgreen-inspirations-and-resources-span">
<h3><span style="color:LightGreen">Inspirations and resources</span><a class="headerlink" href="#span-style-color-lightgreen-inspirations-and-resources-span" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://blog.evjang.com/2018/01/nf1.html">https://blog.evjang.com/2018/01/nf1.html</a></p></li>
<li><p><a class="github reference external" href="https://github.com/ex4sperans/variational-inference-with-normalizing-flows">ex4sperans/variational-inference-with-normalizing-flows</a></p></li>
<li><p><a class="reference external" href="https://akosiorek.github.io/ml/2018/04/03/norm_flows.html">https://akosiorek.github.io/ml/2018/04/03/norm_flows.html</a></p></li>
<li><p><a class="github reference external" href="https://github.com/abdulfatir/normalizing-flows">abdulfatir/normalizing-flows</a></p></li>
<li><p><a class="github reference external" href="https://github.com/acids-ircam/pytorch_flows">acids-ircam/pytorch_flows</a></p></li>
<li><p><a class="reference external" href="https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial11/NF_image_modeling.html">https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial11/NF_image_modeling.html</a></p></li>
</ul>
</section>
</section>
<section id="span-style-color-orange-acknowledgments-span">
<h2><span style="color:Orange">Acknowledgments</span><a class="headerlink" href="#span-style-color-orange-acknowledgments-span" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Initial version: Mark Neubauer</p>
<ul>
<li><p>Modified from the following <a class="reference external" href="https://github.com/araomv/NormalizingFlow-Tutorial/">tutorial</a></p></li>
</ul>
</li>
</ul>
<p>© Copyright 2025</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./_sources/lectures"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="Diffusion.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Diffusion Models</p>
      </div>
    </a>
    <a class="right-next"
       href="SimulationBasedInference.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Simulation Based Inference</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-overview-span"><span style="color:Orange">Overview</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-normalizing-flows-as-a-generative-model-span"><span style="color:Orange">Normalizing Flows as a Generative Model</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-key-elements-and-implementation-span"><span style="color:Orange">Key Elements and Implementation</span></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-invertible-transformation-span"><span style="color:LightGreen">Invertible transformation</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-jacobian-matrix-and-determinant-span"><span style="color:LightGreen">Jacobian Matrix and Determinant</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-architectures-span"><span style="color:LightGreen">Architectures</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-pytorch-distributions-span"><span style="color:LightGreen">PyTorch Distributions</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-transforming-distributions-span"><span style="color:Orange">Transforming distributions</span></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-change-of-variables-and-flow-span"><span style="color:LightGreen">Change of Variables and Flow</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-chaining-variable-transforms-flows-span"><span style="color:LightGreen">Chaining Variable Transforms (flows)</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-normalizing-flows-span"><span style="color:Orange">Normalizing Flows</span></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-planar-flow-span"><span style="color:LightGreen">Planar Flow</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-visualizing-parameters-effects-span"><span style="color:LightGreen">Visualizing Parameters Effects</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-optimizing-normalizing-flows-span"><span style="color:Orange">Optimizing Normalizing Flows</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-references-span"><span style="color:Orange">References</span></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-inspirations-and-resources-span"><span style="color:LightGreen">Inspirations and resources</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-acknowledgments-span"><span style="color:Orange">Acknowledgments</span></a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Mark Neubauer
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>