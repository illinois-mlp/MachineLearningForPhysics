

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Unsupervised Learning and Anomaly Detection &#8212; PHYS 498 MLP</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_sources/lectures/UnsupervisedLearningAnomalyDetection';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Physics Informed Neural Networks" href="../Week_13.html" />
    <link rel="prev" title="Unsupervised Learning and Anomaly Detection" href="../Week_12.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.png" class="logo__image only-light" alt="PHYS 498 MLP - Home"/>
    <script>document.write(`<img src="../../_static/logo.png" class="logo__image only-dark" alt="PHYS 498 MLP - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    <span style="color:Blue">Machine Learning for Physics</span>
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_01.html"><span style="color: blue;"><b>Introduction to Data Science</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1cQJycGyQ07qSOoeskr6GjjTD3byIkxDbdi228NRgFeU/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="JupyterNumpy.html">Jupyter Notebooks and Numerical Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="Pandas.html">Handling Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="Visualization.html">Visualizing Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="Clustering.html">Finding Structure in Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="Dimensionality.html">Measuring and Reducing Dimensionality</a></li>
<li class="toctree-l2"><a class="reference internal" href="Nonlinear.html">Adapting Linear Methods to Non-Linear Data and Kernel Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_01.html">Homework 01: Introduction to Data Science</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_02.html"><span style="color: blue;"><b>Probability Theory and Density Estimation</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1o9tM9ppKZWIa9B3WIHy5JDF4myR5NkO02W6WAlyiTSg/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="ProbabilityTheory.html">Probability Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="ProbabilityDistributions.html">Important Probability Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="DensityEstimation.html">Estimating Probability Density from Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_02.html">Homework 02: Probability Theory and Density Estimation</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_03.html"><span style="color: blue;"><b>Bayesian Statistics I</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1h2SMuH-Z5a_OE6UMDbFjysEiL2NmYT1tGww6VF5jzsA/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="Statistics.html">Statistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="BayesianInference.html">Bayesian Statistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="MarkovChainMonteCarlo.html">Markov Chain Monte Carlo in Practice</a></li>
<li class="toctree-l2"><a class="reference internal" href="MarkovChains.html">Stochastic Processes and Markov-Chain Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_03.html">Homework 03: Bayesian Statistics and Markov Chains</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_04.html"><span style="color: blue;"><b>Bayesian Statistics II</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/18bft9_CiBLjjBy0MHvT_vN7E95kfakvhm_7d7WKHXyY/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="ModelSelection.html">Bayesian Model Selection</a></li>
<li class="toctree-l2"><a class="reference internal" href="VariationalInference.html">Variational Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="Optimization.html">Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="CrossValidation.html">Cross Validation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_04.html">Homework 04: Metropolis-Hastings and Cross Validation</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_05.html"><span style="color: blue;"><b>Introduction to Artificial Intelligence</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1by3-6jDEorKi7_WEr6PTMfEBE8f4xrS94fNdtSuATVg/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="SupervisedLearning.html">Supervised Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="Learning.html">Artificial Intelligence and Machine Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="ArtificialNeuralNetworks.html">Artificial Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="DeepLearning.html">Deep Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_05.html">Homework 05: Artificial Neural Networks</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_06.html"><span style="color: blue;"><b>Convolutional and Recurrent Neural Networks</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1cDFVtEVGLaWd4256OShSb3Roto0x4y4GwG6LkhVozg0/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="ConvolutionalRecurrentNeuralNetworks.html">Convolutional and Recurrent Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_06.html">Homework 06: Forecasting Projectile Motion with Recurrent Neural Networks</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_07.html"><span style="color: blue;"><b>Geometric Deep Learning and Graph Neural Networks</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1jK61M3QGH7bxFU7TMBm16G3YDb-7HOFtgNdqlj3Gs38/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="GraphNeuralNetworks.html">Geometric Deep Learning and Graph Neural Networks</a></li>





</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_08.html"><span style="color: blue;"><b>Attention Mechanism and Transformers</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1ZHuK7TopASFSoyUoELKeCGT8bullhtSLcEkrp4ZueGg/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="Attention.html">Attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="Transformers.html">Transformers</a></li>
<li class="toctree-l2"><a class="reference internal" href="VisionTransformer.html">Vision Transformer</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Project_01.html"><span style="color: blue;"><b>Project 01</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_01_HiggsTauTau.html">Higgs Boson Decaying to Tau Leptons</a></li>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_01_ExoticParticles.html">Searching for Exotic Particles</a></li>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_01_GalaxyZoo.html">Galaxy Zoo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_01_NuclearGeometryQGP.html">Nuclear Geometry and Characterization of the Quark Gluon Plasma</a></li>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_01_AberratedImages.html">Aberrated Image Recovery of Ultracold Atoms</a></li>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_01_DarkEnergySurvey.html">Dark Energy Survey</a></li>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_01_GravitationalWaves.html">Detection of Gravitational Waves</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_09.html"><span style="color: blue;"><b>Generative Modeling and Simulation-Based Inference</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1h13YeUjtTU_WHLxghxFBBQJO3uRr1GtsIyO4DVZviJo/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="GenerativeModeling.html">Generative Modeling</a></li>
<li class="toctree-l2"><a class="reference internal" href="AutoEncoders.html">Autoencoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="VariationalAutoEncoders.html">Variational AutoEncoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="GenerativeAdversarialNetworks.html">Generative Adversarial Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="Diffusion.html">Diffusion Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="NormalizingFlows.html">Normalizing Flows</a></li>
<li class="toctree-l2"><a class="reference internal" href="SimulationBasedInference.html">Simulation Based Inference</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_10.html"><span style="color: blue;"><b>Reinforcement Learning</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1EsW71u3hdNdXyhlDfkmOX__9c4wJZUee_pjlsmlv_Vg/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="ReinforcementLearning.html">Reinforcement Learning</a></li>




<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_07.html">Homework 07: Reinforcement Learning: Implementing a Deep Q-Network</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_11.html"><span style="color: blue;"><b>AI Explainablility and Uncertainty Quantification</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1ydzY7IEYzALTR6ez5gvwwKDduf_7wUtZddq0SUSuvI0/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="AIExplainabilityUncertaintyQuantification.html">AI Explainability and Uncertainty Quantification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_08.html">Homework 08: Detecting Distribution Shift on MNIST using Bayesian Neural Networks</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../Week_12.html"><span style="color: blue;"><b>Unsupervised Learning and Anomaly Detection</b></span></a><input checked="" class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1ydzY7IEYzALTR6ez5gvwwKDduf_7wUtZddq0SUSuvI0/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Unsupervised Learning and Anomaly Detection</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_13.html"><span style="color: blue;"><b>Physics Informed Neural Networks</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1C-Z8b6WP5rE8yohZQdSxyH8O_bHIbllq97QhEJYyh0w/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="PhysicsInformedNeuralNetworks.html">Physics Informed Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="LearningTheSchrodingerEquation.html">Solving the Time Dependent Schrodinger Equation with Physics-Informed Deep Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="SymbolicRegression.html">Introduction to Symbolic Regression</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Project_02.html"><span style="color: blue;"><b>Project 02</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_02_AnisotropyQGP.html">Anisotropy in the Quark Gluon Plasma</a></li>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_02_AberratedImages.html">Aberrated Image Recovery of Ultracold Atoms</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_14.html"><span style="color: blue;"><b>Learning from the Machines</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1hkfaU7JVy1f5S8jURZvTY67KRzP7I8zGRf4Zku_bpM4/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="LearningPhysicsMachines.html">Learning Physics from the Machines</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_15.html"><span style="color: blue;"><b>Future of AI and Physics: What Lies Ahead?</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-17"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1eB1qCn5J07D5he_DCpkBiKjbVjdI6OexUzMQ351GCaI/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="LookingForward.html">Future of AI and Physics: What Lies Ahead?</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/illinois-mlp/MachineLearningForPhysics/blob/main/_sources/lectures/UnsupervisedLearningAnomalyDetection.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>



<a href="https://github.com/illinois-mlp/MachineLearningForPhysics" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/_sources/lectures/UnsupervisedLearningAnomalyDetection.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Unsupervised Learning and Anomaly Detection</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-helpers-for-getting-loading-and-locating-data-span"><span style="color:LightPink">Helpers for Getting, Loading, and Locating Data</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-get-data-span"><span style="color:Orange">Get Data</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-networks-for-unsupervised-learning-span"><span style="color:Orange">Networks for Unsupervised Learning</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-example-time-series-anomaly-detection-using-lstm-autoencoders-span"><span style="color:Orange">Example: Time Series Anomaly Detection using LSTM Autoencoders</span></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-brief-lstm-review-span"><span style="color:LightGreen">Brief LSTM Review</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-data-span"><span style="color:LightGreen">Data</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-exploratory-data-analysis-span"><span style="color:LightGreen">Exploratory Data Analysis</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-lstm-autoencoder-span"><span style="color:LightGreen">LSTM Autoencoder</span></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-reconstruction-loss-span"><span style="color:LightPink">Reconstruction Loss</span></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-anomaly-detection-in-ecg-data-span"><span style="color:LightGreen">Anomaly Detection in ECG Data</span></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-data-preprocessing-span"><span style="color:LightPink">Data Preprocessing</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-lstm-autoencoder-span"><span style="color:LightPink">LSTM Autoencoder</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-training-span"><span style="color:LightPink">Training</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-saving-the-model-span"><span style="color:LightPink">Saving the Model</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-choosing-a-threshold-span"><span style="color:LightPink">Choosing a Threshold</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-evaluation-span"><span style="color:LightPink">Evaluation</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-normal-heartbeats-span"><span style="color:LightPink">Normal Heartbeats</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-anomalies-span"><span style="color:LightPink">Anomalies</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-looking-at-examples-span"><span style="color:LightPink">Looking at Examples</span></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-acknowledgments-span"><span style="color:Orange">Acknowledgments</span></a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="unsupervised-learning-and-anomaly-detection">
<h1>Unsupervised Learning and Anomaly Detection<a class="headerlink" href="#unsupervised-learning-and-anomaly-detection" title="Permalink to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span><span class="p">;</span> <span class="n">sns</span><span class="o">.</span><span class="n">set_theme</span><span class="p">()</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os.path</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">subprocess</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.collections</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">scipy.signal</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn</span><span class="w"> </span><span class="kn">import</span> <span class="n">model_selection</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">copy</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pylab</span><span class="w"> </span><span class="kn">import</span> <span class="n">rcParams</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">matplotlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">rc</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">optim</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.io</span><span class="w"> </span><span class="kn">import</span> <span class="n">arff</span>

<span class="n">RANDOM_SEED</span> <span class="o">=</span> <span class="mi">42</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">RANDOM_SEED</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">RANDOM_SEED</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;torch._C.Generator at 0x134200410&gt;
</pre></div>
</div>
</div>
</div>
<section id="span-style-color-lightpink-helpers-for-getting-loading-and-locating-data-span">
<h2><span style="color:LightPink">Helpers for Getting, Loading, and Locating Data</span><a class="headerlink" href="#span-style-color-lightpink-helpers-for-getting-loading-and-locating-data-span" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">wget_data</span><span class="p">(</span><span class="n">url</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">local_path</span><span class="o">=</span><span class="s1">&#39;./tmp_data&#39;</span><span class="p">):</span>
  <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">local_path</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

  <span class="n">p</span> <span class="o">=</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">Popen</span><span class="p">([</span><span class="s2">&quot;wget&quot;</span><span class="p">,</span> <span class="s2">&quot;-nc&quot;</span><span class="p">,</span> <span class="s2">&quot;-P&quot;</span><span class="p">,</span> <span class="n">local_path</span><span class="p">,</span> <span class="n">url</span><span class="p">],</span> <span class="n">stderr</span><span class="o">=</span><span class="n">subprocess</span><span class="o">.</span><span class="n">PIPE</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;UTF-8&#39;</span><span class="p">)</span>
  <span class="n">rc</span> <span class="o">=</span> <span class="kc">None</span>

  <span class="k">while</span> <span class="n">rc</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">line</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">stderr</span><span class="o">.</span><span class="n">readline</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">line</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
      <span class="nb">print</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
    <span class="n">rc</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">poll</span><span class="p">()</span>

<span class="k">def</span><span class="w"> </span><span class="nf">locate_data</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">check_exists</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="n">local_path</span><span class="o">=</span><span class="s1">&#39;./tmp_data&#39;</span>
    <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">local_path</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">check_exists</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
        <span class="k">raise</span> <span class="n">RuxntimeError</span><span class="p">(</span><span class="s1">&#39;No such data file: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">path</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">path</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="span-style-color-orange-get-data-span">
<h2><span style="color:Orange">Get Data</span><a class="headerlink" href="#span-style-color-orange-get-data-span" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">wget_data</span><span class="p">(</span><span class="s1">&#39;https://raw.githubusercontent.com/illinois-mlp/MachineLearningForPhysics/main/data/ECG5000_TRAIN.arff&#39;</span><span class="p">)</span>
<span class="n">wget_data</span><span class="p">(</span><span class="s1">&#39;https://raw.githubusercontent.com/illinois-mlp/MachineLearningForPhysics/main/data/ECG5000_TEST.arff&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>File ‘./tmp_data/ECG5000_TRAIN.arff’ already there; not retrieving.
File ‘./tmp_data/ECG5000_TEST.arff’ already there; not retrieving.
</pre></div>
</div>
</div>
</div>
</section>
<section id="span-style-color-orange-networks-for-unsupervised-learning-span">
<h2><span style="color:Orange">Networks for Unsupervised Learning</span><a class="headerlink" href="#span-style-color-orange-networks-for-unsupervised-learning-span" title="Permalink to this heading">#</a></h2>
<p>Neural networks are usually used for supervised learning since their learning is accomplished by optimizing a loss function that compares the network’s outputs with some target values. However, it is possible to perform unsupervised learning if we can somehow use the same data for both the input values and the target output values. This requires that the network have the same number of input and output nodes, and effectively means that we are asking it to learn the identify function, which does not sound obviously useful.</p>
<p>Suppose we have a single hidden layer with the same number of nodes as the input and output layers, then all the network has to do is pass each input value through to the output, which does not require any training at all!  However, if the hidden layer has fewer nodes then we are asking the network to solve a more interesting problem: how can the input dataset be encoded and then decoded. This is the same <span style="color:Violet">dimensionality reduction</span> problem we discussed <a class="reference external" href="https://illinois-mlp.github.io/MachineLearningForPhysics/_sources/lectures/Dimensionality.html">earlier</a>, and is known as an <span style="color:Violet">autoencoder network</span> as we covered in the <a class="reference external" href="https://illinois-mlp.github.io/MachineLearningForPhysics/_sources/lectures/AutoEncoders.html">AutoEncoders notebook</a> since it learns to encode itself:</p>
<div>
<img src="https://raw.githubusercontent.com/illinois-mlp/MachineLearningForPhysics/main/img/AutoEncoders-autoencoder-visual.png" width=1000></img>
</div><p>The network can be thought of as the combination of separate encoder and decoder networks, with the encoder feeding its output latent variables <span class="math notranslate nohighlight">\(\mathbf{z}\)</span> into the decoder. Although the architecture looks symmetric, the encoder and decoder will generally learn different parameters because of the asymmetry introduced by nonlinear activations. The figure represents a high-level design pattern and the internal architectures of the encoder and decoder networks should be customized for the type of data being encoded (and typically combined convolutional and dense layers).</p>
</section>
<section id="span-style-color-orange-example-time-series-anomaly-detection-using-lstm-autoencoders-span">
<h2><span style="color:Orange">Example: Time Series Anomaly Detection using LSTM Autoencoders</span><a class="headerlink" href="#span-style-color-orange-example-time-series-anomaly-detection-using-lstm-autoencoders-span" title="Permalink to this heading">#</a></h2>
<p>In this example, we will learn to:</p>
<ul class="simple">
<li><p>Prepare a dataset for Anomaly Detection from Time Series Data</p></li>
<li><p>Build an LSTM Autoencoder with PyTorch</p></li>
<li><p>Train and evaluate your model</p></li>
<li><p>Choose a threshold for anomaly detection</p></li>
<li><p>Classify unseen examples as normal or anomaly</p></li>
</ul>
<p>While our Time Series data is univariate (we have only 1 feature), the code should work for multivariate datasets (multiple features) with little or no modification. Feel free to try it!</p>
<section id="span-style-color-lightgreen-brief-lstm-review-span">
<h3><span style="color:LightGreen">Brief LSTM Review</span><a class="headerlink" href="#span-style-color-lightgreen-brief-lstm-review-span" title="Permalink to this heading">#</a></h3>
<p>A <span style="color:Violet">Long Short-Term Memory</span> (LSTM) is a type of Recurrent Neural Network (RNN) designed to handle long-term dependencies in sequential data, such as text, time series, and speech. LSTMs are known for their ability to mitigate the vanishing gradient problem that plagues standard RNNs, allowing them to learn and remember information over longer sequences of data.</p>
<p>Key Features of LSTMs:</p>
<ul class="simple">
<li><p><em><strong><span style="color:Violet">Memory Cell</span></strong></em>: LSTMs introduce a memory cell that acts as a “memory” for the network, allowing it to store and retrieve information over time.</p></li>
<li><p><em><strong><span style="color:Violet">Gates</span></strong></em>: LSTMs use “gates” (input, forget, and output gates) to control the flow of information into, out of, and within the memory cell.</p></li>
<li><p><em><strong><span style="color:Violet">Vanishing Gradient Problem</span></strong></em>: LSTMs are designed to prevent the gradients from vanishing or exploding as they propagate through the network over time, making them more effective for learning long-term relationships in sequential data.</p></li>
<li><p><em><strong><span style="color:Violet">Sequence Learning</span></strong></em>: LSTMs are particularly well-suited for tasks that involve processing sequential data, such as natural language processing (language modeling, machine translation), speech recognition, and time series forecasting.</p></li>
</ul>
<p>How LSTMs Work:</p>
<ol class="arabic simple">
<li><p><em><strong><span style="color:Violet">Input</span></strong></em>: The LSTM receives an input sequence, where each input represents a time step.</p></li>
<li><p><em><strong><span style="color:Violet">Gates</span></strong></em>: The gates regulate the flow of information into the memory cell and the output from the cell.</p></li>
<li><p><em><strong><span style="color:Violet">Memory Cell</span></strong></em>: The memory cell stores and updates its internal state based on the input and the previous state.</p></li>
<li><p><em><strong><span style="color:Violet">Output</span></strong></em>: The LSTM produces an output at each time step based on the current cell state and the input.</p></li>
</ol>
<p>Advantages of LSTMs:</p>
<ul class="simple">
<li><p><em><strong><span style="color:Violet">Long-term dependencies</span></strong></em>: LSTMs are capable of learning long-term dependencies in sequential data.</p></li>
<li><p><em><strong><span style="color:Violet">Vanishing gradient problem</span></strong></em>: LSTMs mitigate the vanishing gradient problem, making them more effective for processing long sequences.</p></li>
<li><p><em><strong><span style="color:Violet">Wide range of applications</span></strong></em>: LSTMs have been successfully applied to many sequence learning tasks.</p></li>
</ul>
</section>
<section id="span-style-color-lightgreen-data-span">
<h3><span style="color:LightGreen">Data</span><a class="headerlink" href="#span-style-color-lightgreen-data-span" title="Permalink to this heading">#</a></h3>
<p>The <a class="reference external" href="http://timeseriesclassification.com/description.php?Dataset=ECG5000">dataset</a> contains 5,000 Time Series examples (obtained with ECG) with 140 timesteps. Each sequence corresponds to a single heartbeat from a single patient with congestive heart failure.</p>
<blockquote>
<div><p>An electrocardiogram (ECG or EKG) is a test that checks how your heart is functioning by measuring the electrical activity of the heart. It measures the electrical activity of your heart. It uses small electrodes attached to your skin to detect the tiny electrical signals that control your heartbeat. With each heart beat, an electrical impulse (or wave) travels through your heart. This wave causes the muscle to squeeze and pump blood from the heart. <a class="reference external" href="https://www.heartandstroke.ca/heart/tests/electrocardiogram">Source</a></p>
</div></blockquote>
<ul class="simple">
<li><p><em><strong><span style="color:Violet">What it measures</span></strong></em>: An ECG records the electrical impulses that cause your heart to beat, showing how the signals travel through your heart’s chambers.</p></li>
<li><p><em><strong><span style="color:Violet">How it’s done</span></strong></em>: During an ECG, electrodes are attached to your chest, arms, and legs using adhesive patches or small suction cups.</p></li>
<li><p><em><strong><span style="color:Violet">What it shows</span></strong></em>: The ECG produces a graphical representation of your heart’s electrical activity, known as an ECG tracing.</p></li>
<li><p><em><strong><span style="color:Violet">Why it’s used</span></strong></em>: ECGs are used to diagnose and monitor various heart conditions, including arrhythmias, coronary artery disease, heart attacks, and heart failure.</p></li>
<li><p><em><strong><span style="color:Violet">What it can reveal</span></strong></em>: An ECG can help doctors detect changes in heart rate, rhythm, and electrical conduction, which may indicate a heart problem.</p></li>
</ul>
<p>We have 5 types of hearbeats (classes):</p>
<ul class="simple">
<li><p>Normal (N)</p></li>
<li><p>R-on-T Premature Ventricular Contraction (R-on-T PVC)</p></li>
<li><p>Premature Ventricular Contraction (PVC)</p></li>
<li><p>Supra-ventricular Premature or Ectopic Beat (SP or EB)</p></li>
<li><p>Unclassified Beat (UB).</p></li>
</ul>
<blockquote>
<div><p>Assuming a healthy heart and a typical rate of 70 to 75 beats per minute, each cardiac cycle, or heartbeat, takes about 0.8 seconds to complete the cycle.
Frequency: 60–100 per minute (Humans)
Duration: 0.6–1 second (Humans) <a class="reference external" href="https://en.wikipedia.org/wiki/Cardiac_cycle">Source</a></p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>cpu
</pre></div>
</div>
</div>
</div>
<p>The data comes in multiple formats. We’ll load the <code class="docutils literal notranslate"><span class="pre">arff</span></code> files into Pandas data frames:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">locate_data</span><span class="p">(</span><span class="s1">&#39;ECG5000_TRAIN.arff&#39;</span><span class="p">))</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
  <span class="n">data</span><span class="p">,</span> <span class="n">meta</span> <span class="o">=</span> <span class="n">arff</span><span class="o">.</span><span class="n">loadarff</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
  <span class="n">train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">locate_data</span><span class="p">(</span><span class="s1">&#39;ECG5000_TEST.arff&#39;</span><span class="p">))</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
  <span class="n">data</span><span class="p">,</span> <span class="n">meta</span> <span class="o">=</span> <span class="n">arff</span><span class="o">.</span><span class="n">loadarff</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
  <span class="n">test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(500, 141)
(4500, 141)
</pre></div>
</div>
</div>
</div>
<p>We’ll combine the training and test data into a single data frame. This will give us more data to train our Autoencoder. We’ll also shuffle it:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">])</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(5000, 141)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>att1</th>
      <th>att2</th>
      <th>att3</th>
      <th>att4</th>
      <th>att5</th>
      <th>att6</th>
      <th>att7</th>
      <th>att8</th>
      <th>att9</th>
      <th>att10</th>
      <th>...</th>
      <th>att132</th>
      <th>att133</th>
      <th>att134</th>
      <th>att135</th>
      <th>att136</th>
      <th>att137</th>
      <th>att138</th>
      <th>att139</th>
      <th>att140</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1001</th>
      <td>1.469756</td>
      <td>-1.048520</td>
      <td>-3.394356</td>
      <td>-4.254399</td>
      <td>-4.162834</td>
      <td>-3.822570</td>
      <td>-3.003609</td>
      <td>-1.799773</td>
      <td>-1.500033</td>
      <td>-1.025095</td>
      <td>...</td>
      <td>0.945178</td>
      <td>1.275588</td>
      <td>1.617218</td>
      <td>1.580279</td>
      <td>1.306195</td>
      <td>1.351674</td>
      <td>1.915517</td>
      <td>1.672103</td>
      <td>-1.039932</td>
      <td>b'1'</td>
    </tr>
    <tr>
      <th>2086</th>
      <td>-1.998602</td>
      <td>-3.770552</td>
      <td>-4.267091</td>
      <td>-4.256133</td>
      <td>-3.515288</td>
      <td>-2.554540</td>
      <td>-1.699639</td>
      <td>-1.566366</td>
      <td>-1.038815</td>
      <td>-0.425483</td>
      <td>...</td>
      <td>1.008577</td>
      <td>1.024698</td>
      <td>1.051141</td>
      <td>1.015352</td>
      <td>0.988475</td>
      <td>1.050191</td>
      <td>1.089509</td>
      <td>1.465382</td>
      <td>0.799517</td>
      <td>b'1'</td>
    </tr>
    <tr>
      <th>2153</th>
      <td>-1.187772</td>
      <td>-3.365038</td>
      <td>-3.695653</td>
      <td>-4.094781</td>
      <td>-3.992549</td>
      <td>-3.425381</td>
      <td>-2.057643</td>
      <td>-1.277729</td>
      <td>-1.307397</td>
      <td>-0.623098</td>
      <td>...</td>
      <td>1.085007</td>
      <td>1.467196</td>
      <td>1.413850</td>
      <td>1.283822</td>
      <td>0.923126</td>
      <td>0.759235</td>
      <td>0.932364</td>
      <td>1.216265</td>
      <td>-0.824489</td>
      <td>b'1'</td>
    </tr>
    <tr>
      <th>555</th>
      <td>0.604969</td>
      <td>-1.671363</td>
      <td>-3.236131</td>
      <td>-3.966465</td>
      <td>-4.067820</td>
      <td>-3.551897</td>
      <td>-2.582864</td>
      <td>-1.804755</td>
      <td>-1.688151</td>
      <td>-1.025897</td>
      <td>...</td>
      <td>0.545222</td>
      <td>0.649363</td>
      <td>0.986846</td>
      <td>1.234495</td>
      <td>1.280039</td>
      <td>1.215985</td>
      <td>1.617971</td>
      <td>2.196543</td>
      <td>0.023843</td>
      <td>b'1'</td>
    </tr>
    <tr>
      <th>205</th>
      <td>-1.197203</td>
      <td>-3.270123</td>
      <td>-3.778723</td>
      <td>-3.977574</td>
      <td>-3.405060</td>
      <td>-2.392634</td>
      <td>-1.726322</td>
      <td>-1.572748</td>
      <td>-0.920075</td>
      <td>-0.388731</td>
      <td>...</td>
      <td>0.828168</td>
      <td>0.914338</td>
      <td>1.063077</td>
      <td>1.393479</td>
      <td>1.469756</td>
      <td>1.392281</td>
      <td>1.144732</td>
      <td>1.668263</td>
      <td>1.734676</td>
      <td>b'1'</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 141 columns</p>
</div></div></div>
</div>
<p>We have 5,000 examples. Each row represents a single heartbeat record. Let’s name the possible classes:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">CLASS_NORMAL</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1">#class_names = [&#39;Normal&#39;,&#39;R on T&#39;,&#39;PVC&#39;,&#39;SP&#39;,&#39;UB&#39;] # This ordering sometimes produces wrong counts histogram. Need to check if it affects plots that use class_names</span>
<span class="n">class_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Normal&#39;</span><span class="p">,</span><span class="s1">&#39;PVC&#39;</span><span class="p">,</span><span class="s1">&#39;R on T&#39;</span><span class="p">,</span><span class="s1">&#39;SP&#39;</span><span class="p">,</span><span class="s1">&#39;UB&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Next, we’ll rename the last column to <code class="docutils literal notranslate"><span class="pre">target</span></code>, so its easier to reference it:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">new_columns</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">new_columns</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;target&#39;</span>
<span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">new_columns</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="span-style-color-lightgreen-exploratory-data-analysis-span">
<h3><span style="color:LightGreen">Exploratory Data Analysis</span><a class="headerlink" href="#span-style-color-lightgreen-exploratory-data-analysis-span" title="Permalink to this heading">#</a></h3>
<p>Let’s check how many examples for each heartbeat class do we have:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>target
b&#39;1&#39;    2919
b&#39;2&#39;    1767
b&#39;4&#39;     194
b&#39;3&#39;      96
b&#39;5&#39;      24
Name: count, dtype: int64
</pre></div>
</div>
</div>
</div>
<p>Let’s plot the results:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">class_names</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/a3fe6250458a3ee6f63e2df3c665109490bf6f07cbd31aa336f8db11378fe2c6.png" src="../../_images/a3fe6250458a3ee6f63e2df3c665109490bf6f07cbd31aa336f8db11378fe2c6.png" />
</div>
</div>
<p>The normal class, has by far, the most examples. This is great because we’ll use it to train our model.</p>
<p>Let’s have a look at an averaged (smoothed out with one standard deviation on top and bottom of it) Time Series for each class:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">plot_time_series_class</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">class_name</span><span class="p">,</span> <span class="n">ax</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
  <span class="n">time_series_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

  <span class="n">smooth_path</span> <span class="o">=</span> <span class="n">time_series_df</span><span class="o">.</span><span class="n">rolling</span><span class="p">(</span><span class="n">n_steps</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
  <span class="n">path_deviation</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">time_series_df</span><span class="o">.</span><span class="n">rolling</span><span class="p">(</span><span class="n">n_steps</span><span class="p">)</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>

  <span class="n">under_line</span> <span class="o">=</span> <span class="p">(</span><span class="n">smooth_path</span> <span class="o">-</span> <span class="n">path_deviation</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
  <span class="n">over_line</span> <span class="o">=</span> <span class="p">(</span><span class="n">smooth_path</span> <span class="o">+</span> <span class="n">path_deviation</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

  <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">smooth_path</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span>
    <span class="n">path_deviation</span><span class="o">.</span><span class="n">index</span><span class="p">,</span>
    <span class="n">under_line</span><span class="p">,</span>
    <span class="n">over_line</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">.125</span>
  <span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">class_name</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">classes</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span>
  <span class="n">nrows</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">classes</span><span class="p">)</span> <span class="o">//</span> <span class="mi">3</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
  <span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
  <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
  <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
<span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="bp">cls</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">classes</span><span class="p">):</span>
  <span class="n">ax</span> <span class="o">=</span> <span class="n">axs</span><span class="o">.</span><span class="n">flat</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
  <span class="n">data</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">target</span> <span class="o">==</span> <span class="bp">cls</span><span class="p">]</span> \
    <span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="s1">&#39;target&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
  <span class="n">plot_time_series_class</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">class_names</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">ax</span><span class="p">)</span>

<span class="n">fig</span><span class="o">.</span><span class="n">delaxes</span><span class="p">(</span><span class="n">axs</span><span class="o">.</span><span class="n">flat</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/297de7d4e9f2aa34398d40b3a259f90b9419606925171681f8e365b4c814fd4a.png" src="../../_images/297de7d4e9f2aa34398d40b3a259f90b9419606925171681f8e365b4c814fd4a.png" />
</div>
</div>
<p>It is very good that the normal class has a distinctly different pattern than all other classes. Maybe our model will be able to detect anomalies?</p>
</section>
<section id="span-style-color-lightgreen-lstm-autoencoder-span">
<h3><span style="color:LightGreen">LSTM Autoencoder</span><a class="headerlink" href="#span-style-color-lightgreen-lstm-autoencoder-span" title="Permalink to this heading">#</a></h3>
<p>The <a class="reference external" href="https://en.wikipedia.org/wiki/Autoencoder">Autoencoder’s</a> job is to get some input data, pass it through the model, and obtain a reconstruction of the input. The reconstruction should match the input as much as possible. The trick is to use a small number of parameters, so your model learns a compressed representation of the data.</p>
<p>In a sense, Autoencoders try to learn only the most important features (compressed version) of the data. Here, we’ll have a look at how to feed Time Series data to an Autoencoder. We’ll use a couple of LSTM layers (hence the LSTM Autoencoder) to capture the temporal dependencies of the data.</p>
<p>To classify a sequence as normal or an anomaly, we’ll pick a threshold above which a heartbeat is considered abnormal.</p>
<section id="span-style-color-lightpink-reconstruction-loss-span">
<h4><span style="color:LightPink">Reconstruction Loss</span><a class="headerlink" href="#span-style-color-lightpink-reconstruction-loss-span" title="Permalink to this heading">#</a></h4>
<p>When training an Autoencoder, the objective is to reconstruct the input as best as possible. This is done by minimizing a loss function (just like in supervised learning). This function is known as <em>reconstruction loss</em>. Cross-entropy loss and Mean squared error are common examples.</p>
</section>
</section>
<section id="span-style-color-lightgreen-anomaly-detection-in-ecg-data-span">
<h3><span style="color:LightGreen">Anomaly Detection in ECG Data</span><a class="headerlink" href="#span-style-color-lightgreen-anomaly-detection-in-ecg-data-span" title="Permalink to this heading">#</a></h3>
<p>We’ll use normal heartbeats as training data for our model and record the <em>reconstruction loss</em>. But first, we need to prepare the data:</p>
<section id="span-style-color-lightpink-data-preprocessing-span">
<h4><span style="color:LightPink">Data Preprocessing</span><a class="headerlink" href="#span-style-color-lightpink-data-preprocessing-span" title="Permalink to this heading">#</a></h4>
<p>Let’s get all normal heartbeats and drop the target (class) column:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">normal_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">target</span> <span class="o">==</span> <span class="nb">str</span><span class="p">(</span><span class="n">CLASS_NORMAL</span><span class="p">)</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)]</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="s1">&#39;target&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">normal_df</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(2919, 140)
</pre></div>
</div>
</div>
</div>
<p>We’ll merge all other classes and mark them as anomalies:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">anomaly_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">target</span> <span class="o">!=</span> <span class="nb">str</span><span class="p">(</span><span class="n">CLASS_NORMAL</span><span class="p">)</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)]</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="s1">&#39;target&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">anomaly_df</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(2081, 140)
</pre></div>
</div>
</div>
</div>
<p>We’ll split the normal examples into train, validation and test sets:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span><span class="p">,</span> <span class="n">val_df</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
  <span class="n">normal_df</span><span class="p">,</span>
  <span class="n">test_size</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span>
  <span class="n">random_state</span><span class="o">=</span><span class="n">RANDOM_SEED</span>
<span class="p">)</span>

<span class="n">val_df</span><span class="p">,</span> <span class="n">test_df</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
  <span class="n">val_df</span><span class="p">,</span>
  <span class="n">test_size</span><span class="o">=</span><span class="mf">0.33</span><span class="p">,</span>
  <span class="n">random_state</span><span class="o">=</span><span class="n">RANDOM_SEED</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We need to convert our examples into tensors, so we can use them to train our Autoencoder. Let’s write a helper function for that:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">create_dataset</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>

  <span class="n">sequences</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

  <span class="n">dataset</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">s</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">sequences</span><span class="p">]</span>

  <span class="n">n_seq</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>

  <span class="k">return</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">n_features</span>
</pre></div>
</div>
</div>
</div>
<p>Each Time Series will be converted to a 2D Tensor in the shape <em>sequence length</em> x <em>number of features</em> (140x1 in our case).</p>
<p>Let’s create some datasets:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">train_df</span><span class="p">)</span>
<span class="n">val_dataset</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">val_df</span><span class="p">)</span>
<span class="n">test_normal_dataset</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">test_df</span><span class="p">)</span>
<span class="n">test_anomaly_dataset</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">anomaly_df</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="span-style-color-lightpink-lstm-autoencoder-span">
<h4><span style="color:LightPink">LSTM Autoencoder</span><a class="headerlink" href="#span-style-color-lightpink-lstm-autoencoder-span" title="Permalink to this heading">#</a></h4>
<div>
<img src="https://raw.githubusercontent.com/illinois-mlp/MachineLearningForPhysics/main/img/UnsupervisedLearningAnomalyDetection-autoencoder_architecture.png" width=1000></img>
</div>
<p><em>Sample Autoencoder Architecture <a class="reference external" href="https://lilianweng.github.io/lil-log/2018/08/12/from-autoencoder-to-beta-vae.html">Image Source</a></em></p>
<p>The general Autoencoder architecture consists of two components. An <em>Encoder</em> that compresses the input and a <em>Decoder</em> that tries to reconstruct it.</p>
<p>We’ll use the LSTM Autoencoder from this <a class="reference external" href="https://github.com/shobrook/sequitur">GitHub repo</a> with some small tweaks. Our model’s job is to reconstruct Time Series data. Let’s start with the <em>Encoder</em>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">Encoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

  <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="o">=</span><span class="mi">64</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Encoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">seq_len</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_features</span> <span class="o">=</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">n_features</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">embedding_dim</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">rnn1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span>
      <span class="n">input_size</span><span class="o">=</span><span class="n">n_features</span><span class="p">,</span>
      <span class="n">hidden_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">,</span>
      <span class="n">num_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
      <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">rnn2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span>
      <span class="n">input_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">,</span>
      <span class="n">hidden_size</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">,</span>
      <span class="n">num_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
      <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>

  <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">seq_len</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_features</span><span class="p">))</span>

    <span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">hidden_n</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">hidden_n</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_features</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding_dim</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>The <em>Encoder</em> uses two LSTM layers to compress the Time Series data input.</p>
<p>Next, we’ll decode the compressed representation using a <em>Decoder</em>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">Decoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

  <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Decoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">seq_len</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">input_dim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_features</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">n_features</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">rnn1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span>
      <span class="n">input_size</span><span class="o">=</span><span class="n">input_dim</span><span class="p">,</span>
      <span class="n">hidden_size</span><span class="o">=</span><span class="n">input_dim</span><span class="p">,</span>
      <span class="n">num_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
      <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">rnn2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span>
      <span class="n">input_size</span><span class="o">=</span><span class="n">input_dim</span><span class="p">,</span>
      <span class="n">hidden_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">,</span>
      <span class="n">num_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
      <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span>

  <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seq_len</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_features</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_features</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">seq_len</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_dim</span><span class="p">))</span>

    <span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">hidden_n</span><span class="p">,</span> <span class="n">cell_n</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">hidden_n</span><span class="p">,</span> <span class="n">cell_n</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">seq_len</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">))</span>

    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Our Decoder contains two LSTM layers and an output layer that gives the final reconstruction.</p>
<p>Time to wrap everything into an easy to use module:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">RecurrentAutoencoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

  <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="o">=</span><span class="mi">64</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">RecurrentAutoencoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">(</span><span class="n">seq_len</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">Decoder</span><span class="p">(</span><span class="n">seq_len</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

  <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
<p>Our Autoencoder passes the input through the Encoder and Decoder. Let’s create an instance of it:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">RecurrentAutoencoder</span><span class="p">(</span><span class="n">seq_len</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="span-style-color-lightpink-training-span">
<h4><span style="color:LightPink">Training</span><a class="headerlink" href="#span-style-color-lightpink-training-span" title="Permalink to this heading">#</a></h4>
<p>Let’s write a helper function for our training process:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">val_dataset</span><span class="p">,</span> <span class="n">n_epochs</span><span class="p">):</span>
  <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
  <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">L1Loss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
  <span class="n">history</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">train</span><span class="o">=</span><span class="p">[],</span> <span class="n">val</span><span class="o">=</span><span class="p">[])</span>

  <span class="n">best_model_wts</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
  <span class="n">best_loss</span> <span class="o">=</span> <span class="mf">10000.0</span>

  <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

    <span class="n">train_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">seq_true</span> <span class="ow">in</span> <span class="n">train_dataset</span><span class="p">:</span>
      <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

      <span class="n">seq_true</span> <span class="o">=</span> <span class="n">seq_true</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
      <span class="n">seq_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">seq_true</span><span class="p">)</span>

      <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">seq_pred</span><span class="p">,</span> <span class="n">seq_true</span><span class="p">)</span>

      <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
      <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

      <span class="n">train_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

    <span class="n">val_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
      <span class="k">for</span> <span class="n">seq_true</span> <span class="ow">in</span> <span class="n">val_dataset</span><span class="p">:</span>

        <span class="n">seq_true</span> <span class="o">=</span> <span class="n">seq_true</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">seq_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">seq_true</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">seq_pred</span><span class="p">,</span> <span class="n">seq_true</span><span class="p">)</span>
        <span class="n">val_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

    <span class="n">train_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_losses</span><span class="p">)</span>
    <span class="n">val_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">val_losses</span><span class="p">)</span>

    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_loss</span><span class="p">)</span>
    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;val&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_loss</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">val_loss</span> <span class="o">&lt;</span> <span class="n">best_loss</span><span class="p">:</span>
      <span class="n">best_loss</span> <span class="o">=</span> <span class="n">val_loss</span>
      <span class="n">best_model_wts</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s1">: train loss </span><span class="si">{</span><span class="n">train_loss</span><span class="si">}</span><span class="s1"> val loss </span><span class="si">{</span><span class="n">val_loss</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

  <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">best_model_wts</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">(),</span> <span class="n">history</span>
</pre></div>
</div>
</div>
</div>
<p>At each epoch, the training process feeds our model with all training examples and evaluates the performance on the validation set. Note that we’re using a batch size of 1 (our model sees only 1 sequence at a time). We also record the training and validation set losses during the process.</p>
<p>Note that we’re minimizing the <a class="reference external" href="https://pytorch.org/docs/stable/nn.html#l1loss">L1Loss</a>, which measures the MAE (mean absolute error). Why? The reconstructions seem to be better than with MSE (mean squared error).</p>
<p>We’ll get the version of the model with the smallest validation error. Let’s do some training:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="p">,</span> <span class="n">history</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span>
  <span class="n">model</span><span class="p">,</span>
  <span class="n">train_dataset</span><span class="p">,</span>
  <span class="n">val_dataset</span><span class="p">,</span>
  <span class="n">n_epochs</span><span class="o">=</span><span class="mi">150</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1: train loss 70.19056519843167 val loss 55.545283333840224
Epoch 2: train loss 57.20439573393287 val loss 53.2183632053206
Epoch 3: train loss 53.80251925667175 val loss 51.787326721608025
Epoch 4: train loss 53.50249311915332 val loss 52.1923034850241
Epoch 5: train loss 51.639859836459976 val loss 50.23866700312384
Epoch 6: train loss 47.88762839923506 val loss 53.42915126813556
Epoch 7: train loss 44.5796035203853 val loss 42.75591913425068
Epoch 8: train loss 43.05668973250045 val loss 41.69073425136735
Epoch 9: train loss 36.804902854344384 val loss 28.941658182762588
Epoch 10: train loss 29.600385176948077 val loss 27.772434221599696
Epoch 11: train loss 29.258839591478733 val loss 33.79314185002558
Epoch 12: train loss 27.309336170271873 val loss 29.403204198583403
Epoch 13: train loss 26.56631477529702 val loss 25.562526377394743
Epoch 14: train loss 25.581571012771402 val loss 26.178377704815652
Epoch 15: train loss 24.73337686278079 val loss 28.74295396772261
Epoch 16: train loss 23.183967294735275 val loss 29.078925552628554
Epoch 17: train loss 23.142798073202407 val loss 21.02237903542893
Epoch 18: train loss 21.924223153738186 val loss 24.21762883052891
Epoch 19: train loss 21.104562202416712 val loss 20.23192710030201
Epoch 20: train loss 20.47691583152934 val loss 22.912674659755044
Epoch 21: train loss 20.040546160078684 val loss 18.938482645835485
Epoch 22: train loss 19.584992215019327 val loss 18.982437735938376
Epoch 23: train loss 19.018079930666424 val loss 20.806668545198928
Epoch 24: train loss 18.504388450567205 val loss 18.30796128491086
Epoch 25: train loss 18.096634402384637 val loss 19.596596021294186
Epoch 26: train loss 17.977364436698892 val loss 16.531875984660594
Epoch 27: train loss 17.49705117597353 val loss 18.28265956318826
Epoch 28: train loss 18.026098470253505 val loss 17.385052781869934
Epoch 29: train loss 17.374587030191663 val loss 18.157290784165316
Epoch 30: train loss 17.16383284534576 val loss 17.862681655753594
Epoch 31: train loss 16.66365962564729 val loss 15.49548804312436
Epoch 32: train loss 16.405945794229687 val loss 18.52142742143963
Epoch 33: train loss 16.062661001058608 val loss 14.830465095441904
Epoch 34: train loss 16.47399080707776 val loss 17.471961138598342
Epoch 35: train loss 15.997433853456927 val loss 15.624564058544692
Epoch 36: train loss 15.45416613021045 val loss 13.819568647052648
Epoch 37: train loss 15.674591416363176 val loss 15.529796063289707
Epoch 38: train loss 15.053373992947598 val loss 15.9429453696814
Epoch 39: train loss 15.373062103998752 val loss 15.99911313496352
Epoch 40: train loss 14.997124674242382 val loss 16.14874661090838
Epoch 41: train loss 14.78773114374692 val loss 15.053109400101489
Epoch 42: train loss 14.707472309187889 val loss 13.474772160370602
Epoch 43: train loss 14.391030698474113 val loss 16.305593604520727
Epoch 44: train loss 14.542153571219947 val loss 15.953227477675819
Epoch 45: train loss 15.172505170575365 val loss 13.980109895048695
Epoch 46: train loss 14.188497360749189 val loss 12.644973229222737
Epoch 47: train loss 14.156689580819723 val loss 21.353175908632245
Epoch 48: train loss 50.04139142169053 val loss 49.17329901477176
Epoch 49: train loss 46.201949142246946 val loss 43.659058691291676
Epoch 50: train loss 42.91428000155306 val loss 43.057076444398014
Epoch 51: train loss 41.81053997364221 val loss 41.106021588166016
Epoch 52: train loss 36.06166249520833 val loss 39.88905889100996
Epoch 53: train loss 29.183639168499074 val loss 26.974961004159557
Epoch 54: train loss 26.367558816420075 val loss 27.51501340508054
Epoch 55: train loss 26.53801757123671 val loss 39.89739027446447
Epoch 56: train loss 39.92649830161252 val loss 41.40678741663389
Epoch 57: train loss 35.69660516690458 val loss 29.03401455537451
Epoch 58: train loss 25.09197178486613 val loss 20.72612377401098
Epoch 59: train loss 23.13466597545152 val loss 18.418487984979517
Epoch 60: train loss 21.964455101193078 val loss 20.055133132804375
Epoch 61: train loss 40.05612799372706 val loss 37.54572868347168
Epoch 62: train loss 39.15776094146815 val loss 38.9643552929875
Epoch 63: train loss 38.448927825903134 val loss 35.390615183338774
Epoch 64: train loss 37.809167015509274 val loss 39.99620886141936
Epoch 65: train loss 34.09364483328608 val loss 27.30450067747982
Epoch 66: train loss 26.67849037619379 val loss 20.352936210892715
Epoch 67: train loss 24.84206325188129 val loss 33.320356661956055
Epoch 68: train loss 34.431856618586785 val loss 32.346698956278
Epoch 69: train loss 30.98668835096809 val loss 26.43371902960559
Epoch 70: train loss 26.04953423799502 val loss 24.974476687330434
Epoch 71: train loss 23.299769980058898 val loss 20.337625868084487
Epoch 72: train loss 21.48273552352985 val loss 18.126675771771843
Epoch 73: train loss 20.842392928366795 val loss 21.02987113991695
Epoch 74: train loss 20.490705648865827 val loss 20.880575531578714
Epoch 75: train loss 20.557456831065267 val loss 22.441138277281674
Epoch 76: train loss 20.451879095425774 val loss 35.61199761087984
Epoch 77: train loss 20.20753402740712 val loss 19.251601261490443
Epoch 78: train loss 19.92655499065081 val loss 20.376938081031774
Epoch 79: train loss 20.20205936293504 val loss 20.11863258348797
Epoch 80: train loss 19.13581985737325 val loss 17.33350148380006
Epoch 81: train loss 19.631320482105654 val loss 18.23948536960745
Epoch 82: train loss 19.085387102493783 val loss 22.58678812866732
Epoch 83: train loss 19.56715456567816 val loss 16.282159437498542
Epoch 84: train loss 18.86151957117901 val loss 22.12527833294136
Epoch 85: train loss 19.182493048778998 val loss 15.719699169588576
Epoch 86: train loss 18.786777692185154 val loss 15.68992683098178
Epoch 87: train loss 18.78033543017448 val loss 23.52071121528287
Epoch 88: train loss 18.26201426930026 val loss 18.25598847906744
Epoch 89: train loss 18.979437475769522 val loss 21.100039452822948
Epoch 90: train loss 18.26648298361185 val loss 19.28377089972382
Epoch 91: train loss 18.31599943064144 val loss 24.22523792449118
Epoch 92: train loss 18.298746783230776 val loss 28.706830978393555
Epoch 93: train loss 19.08678672833579 val loss 15.865922319197411
Epoch 94: train loss 18.08626968233108 val loss 23.420287727902775
Epoch 95: train loss 17.652017629900943 val loss 15.142815327888462
Epoch 96: train loss 18.181185933189592 val loss 25.33449844776974
Epoch 97: train loss 17.877270106969462 val loss 33.13134558615831
Epoch 98: train loss 17.836640245921185 val loss 15.37667643739095
Epoch 99: train loss 16.938111701351843 val loss 16.563636779785156
Epoch 100: train loss 17.732364453312275 val loss 14.672442454119999
Epoch 101: train loss 17.263540312341508 val loss 15.82090921532172
Epoch 102: train loss 16.891706773418903 val loss 16.7379050905794
Epoch 103: train loss 17.13709879594193 val loss 14.146806155455398
Epoch 104: train loss 16.764518058189505 val loss 19.440087813159305
Epoch 105: train loss 16.94334373873888 val loss 15.222742149040561
Epoch 106: train loss 16.183697756237198 val loss 13.306550038959386
Epoch 107: train loss 16.64517932262982 val loss 16.13168755488998
Epoch 108: train loss 16.37091232739548 val loss 14.694227990030022
Epoch 109: train loss 16.702855778624578 val loss 15.194658243615473
Epoch 110: train loss 16.91737700296669 val loss 15.045723869532042
Epoch 111: train loss 16.59945496970826 val loss 19.52368563759449
Epoch 112: train loss 16.260910302484675 val loss 16.171519328302896
Epoch 113: train loss 15.8463382732479 val loss 14.829655901157002
Epoch 114: train loss 16.28005094059241 val loss 16.68857728580566
Epoch 115: train loss 15.451319722195201 val loss 14.870933399265537
Epoch 116: train loss 15.672055015348706 val loss 13.178509814747365
Epoch 117: train loss 16.393067020122587 val loss 14.099442119077612
Epoch 118: train loss 15.825646905925955 val loss 13.307889482673932
Epoch 119: train loss 15.71289432418774 val loss 14.201728811036197
Epoch 120: train loss 15.860002806570106 val loss 13.228547328975013
Epoch 121: train loss 15.53800718537361 val loss 13.781301809252325
Epoch 122: train loss 15.34830952939945 val loss 13.269842797171947
Epoch 123: train loss 15.222065412820418 val loss 13.787556535961684
Epoch 124: train loss 15.34281487851218 val loss 22.795164147334702
Epoch 125: train loss 15.242534686076645 val loss 15.581529978599157
Epoch 126: train loss 14.984672280580273 val loss 13.194535392136297
Epoch 127: train loss 14.719113676262594 val loss 16.74072455383405
Epoch 128: train loss 14.400070794115909 val loss 14.215379734494988
Epoch 129: train loss 14.55763864036723 val loss 13.726758979693209
Epoch 130: train loss 14.519240352618315 val loss 12.753542180761135
Epoch 131: train loss 14.505081076816127 val loss 13.40780791324967
Epoch 132: train loss 14.800157288686252 val loss 12.927813090562006
Epoch 133: train loss 14.541326379257073 val loss 13.011886248409544
Epoch 134: train loss 14.405127430577185 val loss 12.052384399309908
Epoch 135: train loss 14.595999834759493 val loss 22.06686915960735
Epoch 136: train loss 14.226204098928653 val loss 12.305029219734791
Epoch 137: train loss 14.080185916144153 val loss 12.431378122075833
Epoch 138: train loss 14.08342739594939 val loss 12.217355282233436
Epoch 139: train loss 13.97979081998377 val loss 12.693149750550045
Epoch 140: train loss 13.63878089235176 val loss 12.318664846973615
Epoch 141: train loss 13.919130394315586 val loss 15.256824709856469
Epoch 142: train loss 16.13320877954682 val loss 17.077763248222272
Epoch 143: train loss 15.087361056686456 val loss 15.29185129107062
Epoch 144: train loss 14.432223819715754 val loss 12.79300432888721
Epoch 145: train loss 14.343365429390442 val loss 12.252096006894682
Epoch 146: train loss 13.892574746202241 val loss 13.744810376151023
Epoch 147: train loss 13.876122432002997 val loss 12.75807917891102
Epoch 148: train loss 13.617831775998935 val loss 12.758630116238121
Epoch 149: train loss 13.805896500145797 val loss 14.246482142816225
Epoch 150: train loss 13.779111992491199 val loss 15.29199789001673
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>

<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Loss over training epochs&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/8d229c41a9e660c1cf230221c886eb2011dc2a9accab515735d08de2d06a3c60.png" src="../../_images/8d229c41a9e660c1cf230221c886eb2011dc2a9accab515735d08de2d06a3c60.png" />
</div>
</div>
<p>Our model converged quite well. Seems like we might’ve needed a larger validation set to smoothen the results, but that’ll do for now.</p>
</section>
<section id="span-style-color-lightpink-saving-the-model-span">
<h4><span style="color:LightPink">Saving the Model</span><a class="headerlink" href="#span-style-color-lightpink-saving-the-model-span" title="Permalink to this heading">#</a></h4>
<p>Let’s store the model for later use:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">MODEL_PATH</span> <span class="o">=</span> <span class="s1">&#39;model.pth&#39;</span>

<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">MODEL_PATH</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Uncomment the next lines, if you want to download and load the pre-trained model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># !gdown --id 1jEYx5wGsb7Ix8cZAw3l5p5pOwHs3_I9A</span>
<span class="c1"># model = torch.load(&#39;model.pth&#39;)</span>
<span class="c1"># model = model.to(device)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="span-style-color-lightpink-choosing-a-threshold-span">
<h4><span style="color:LightPink">Choosing a Threshold</span><a class="headerlink" href="#span-style-color-lightpink-choosing-a-threshold-span" title="Permalink to this heading">#</a></h4>
<p>With our model at hand, we can have a look at the reconstruction error on the training set. Let’s start by writing a helper function to get predictions from our model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataset</span><span class="p">):</span>
  <span class="n">predictions</span><span class="p">,</span> <span class="n">losses</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
  <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">L1Loss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
  <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">seq_true</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>
      <span class="n">seq_true</span> <span class="o">=</span> <span class="n">seq_true</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
      <span class="n">seq_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">seq_true</span><span class="p">)</span>

      <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">seq_pred</span><span class="p">,</span> <span class="n">seq_true</span><span class="p">)</span>

      <span class="n">predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">seq_pred</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
      <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
  <span class="k">return</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">losses</span>
</pre></div>
</div>
</div>
</div>
<p>Our function goes through each example in the dataset and records the predictions and losses. Let’s get the losses and have a look at them:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">_</span><span class="p">,</span> <span class="n">losses</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">losses</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/25594de72da3d6ecb1040be3f14bb010d85c52845b88cac12afbd7145f635e24.png" src="../../_images/25594de72da3d6ecb1040be3f14bb010d85c52845b88cac12afbd7145f635e24.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">THRESHOLD</span> <span class="o">=</span> <span class="mi">26</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="span-style-color-lightpink-evaluation-span">
<h4><span style="color:LightPink">Evaluation</span><a class="headerlink" href="#span-style-color-lightpink-evaluation-span" title="Permalink to this heading">#</a></h4>
<p>Using the threshold, we can turn the problem into a simple binary classification task:</p>
<ul class="simple">
<li><p>If the reconstruction loss for an example is below the threshold, we’ll classify it as a <em>normal</em> heartbeat</p></li>
<li><p>Alternatively, if the loss is higher than the threshold, we’ll classify it as an anomaly</p></li>
</ul>
</section>
<section id="span-style-color-lightpink-normal-heartbeats-span">
<h4><span style="color:LightPink">Normal Heartbeats</span><a class="headerlink" href="#span-style-color-lightpink-normal-heartbeats-span" title="Permalink to this heading">#</a></h4>
<p>Let’s check how well our model does on normal heartbeats. We’ll use the normal heartbeats from the test set (our model haven’t seen those):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predictions</span><span class="p">,</span> <span class="n">pred_losses</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_normal_dataset</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">pred_losses</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/c6878a009ff30753c987b84d88d1bb04c9e5f2f8fda2ed78f80e6e11787616a2.png" src="../../_images/c6878a009ff30753c987b84d88d1bb04c9e5f2f8fda2ed78f80e6e11787616a2.png" />
</div>
</div>
<p>We’ll count the correct predictions:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">correct</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">l</span> <span class="o">&lt;=</span> <span class="n">THRESHOLD</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">pred_losses</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Correct normal predictions: </span><span class="si">{</span><span class="n">correct</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">test_normal_dataset</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Correct normal predictions: 139/145
</pre></div>
</div>
</div>
</div>
</section>
<section id="span-style-color-lightpink-anomalies-span">
<h4><span style="color:LightPink">Anomalies</span><a class="headerlink" href="#span-style-color-lightpink-anomalies-span" title="Permalink to this heading">#</a></h4>
<p>We’ll do the same with the anomaly examples, but their number is much higher. We’ll get a subset that has the same size as the normal heartbeats:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">anomaly_dataset</span> <span class="o">=</span> <span class="n">test_anomaly_dataset</span><span class="p">[:</span><span class="nb">len</span><span class="p">(</span><span class="n">test_normal_dataset</span><span class="p">)]</span>
</pre></div>
</div>
</div>
</div>
<p>Now we can take the predictions of our model for the subset of anomalies:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predictions</span><span class="p">,</span> <span class="n">pred_losses</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">anomaly_dataset</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">pred_losses</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/59839d17b456d9af27dbe8eee67e891cca99134c641a3451b088af90f4f6d23d.png" src="../../_images/59839d17b456d9af27dbe8eee67e891cca99134c641a3451b088af90f4f6d23d.png" />
</div>
</div>
<p>Finally, we can count the number of examples above the threshold (considered as anomalies):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">correct</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">l</span> <span class="o">&gt;</span> <span class="n">THRESHOLD</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">pred_losses</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Correct anomaly predictions: </span><span class="si">{</span><span class="n">correct</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">anomaly_dataset</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Correct anomaly predictions: 143/145
</pre></div>
</div>
</div>
</div>
<p>We have very good results. In the real world, you can tweak the threshold depending on what kind of errors you want to tolerate. In this case, you might want to have more false positives (normal heartbeats considered as anomalies) than false negatives (anomalies considered as normal).</p>
</section>
<section id="span-style-color-lightpink-looking-at-examples-span">
<h4><span style="color:LightPink">Looking at Examples</span><a class="headerlink" href="#span-style-color-lightpink-looking-at-examples-span" title="Permalink to this heading">#</a></h4>
<p>We can overlay the real and reconstructed Time Series values to see how close they are. We’ll do it for some normal and anomaly cases:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">plot_prediction</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">title</span><span class="p">,</span> <span class="n">ax</span><span class="p">):</span>
  <span class="n">predictions</span><span class="p">,</span> <span class="n">pred_losses</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">[</span><span class="n">data</span><span class="p">])</span>

  <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;true&#39;</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">predictions</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;reconstructed&#39;</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">title</span><span class="si">}</span><span class="s1"> (loss: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">around</span><span class="p">(</span><span class="n">pred_losses</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span>
  <span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
  <span class="n">ncols</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span>
  <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
  <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
  <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">22</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
<span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">test_normal_dataset</span><span class="p">[:</span><span class="mi">6</span><span class="p">]):</span>
  <span class="n">plot_prediction</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Normal&#39;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">])</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">test_anomaly_dataset</span><span class="p">[:</span><span class="mi">6</span><span class="p">]):</span>
  <span class="n">plot_prediction</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Anomaly&#39;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">])</span>

<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/f2cc1373d4c917e887f5d948a989911de09cdfee12cab6b03d2bb868df74db36.png" src="../../_images/f2cc1373d4c917e887f5d948a989911de09cdfee12cab6b03d2bb868df74db36.png" />
</div>
</div>
</section>
</section>
</section>
<section id="span-style-color-orange-acknowledgments-span">
<h2><span style="color:Orange">Acknowledgments</span><a class="headerlink" href="#span-style-color-orange-acknowledgments-span" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Initial version: Mark Neubauer</p></li>
<li><p>Modified from this <a class="reference external" href="https://colab.research.google.com/github/curiousily/Getting-Things-Done-with-Pytorch/blob/master/06.time-series-anomaly-detection-ecg.ipynb">notebook</a></p></li>
</ul>
<p>© Copyright 2025</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./_sources/lectures"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../Week_12.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span style="color: blue;"><b>Unsupervised Learning and Anomaly Detection</b></span></p>
      </div>
    </a>
    <a class="right-next"
       href="../Week_13.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span style="color: blue;"><b>Physics Informed Neural Networks</b></span></p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-helpers-for-getting-loading-and-locating-data-span"><span style="color:LightPink">Helpers for Getting, Loading, and Locating Data</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-get-data-span"><span style="color:Orange">Get Data</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-networks-for-unsupervised-learning-span"><span style="color:Orange">Networks for Unsupervised Learning</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-example-time-series-anomaly-detection-using-lstm-autoencoders-span"><span style="color:Orange">Example: Time Series Anomaly Detection using LSTM Autoencoders</span></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-brief-lstm-review-span"><span style="color:LightGreen">Brief LSTM Review</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-data-span"><span style="color:LightGreen">Data</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-exploratory-data-analysis-span"><span style="color:LightGreen">Exploratory Data Analysis</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-lstm-autoencoder-span"><span style="color:LightGreen">LSTM Autoencoder</span></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-reconstruction-loss-span"><span style="color:LightPink">Reconstruction Loss</span></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-anomaly-detection-in-ecg-data-span"><span style="color:LightGreen">Anomaly Detection in ECG Data</span></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-data-preprocessing-span"><span style="color:LightPink">Data Preprocessing</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-lstm-autoencoder-span"><span style="color:LightPink">LSTM Autoencoder</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-training-span"><span style="color:LightPink">Training</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-saving-the-model-span"><span style="color:LightPink">Saving the Model</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-choosing-a-threshold-span"><span style="color:LightPink">Choosing a Threshold</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-evaluation-span"><span style="color:LightPink">Evaluation</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-normal-heartbeats-span"><span style="color:LightPink">Normal Heartbeats</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-anomalies-span"><span style="color:LightPink">Anomalies</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-looking-at-examples-span"><span style="color:LightPink">Looking at Examples</span></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-acknowledgments-span"><span style="color:Orange">Acknowledgments</span></a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Mark Neubauer
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>