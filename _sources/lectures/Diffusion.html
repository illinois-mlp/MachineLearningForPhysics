

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Diffusion Models &#8212; PHYS 498 MLP</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_sources/lectures/Diffusion';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Normalizing Flows" href="NormalizingFlows.html" />
    <link rel="prev" title="Generative Adversarial Networks" href="GenerativeAdversarialNetworks.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.png" class="logo__image only-light" alt="PHYS 498 MLP - Home"/>
    <script>document.write(`<img src="../../_static/logo.png" class="logo__image only-dark" alt="PHYS 498 MLP - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    <span style="color:Blue">Machine Learning for Physics</span>
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_01.html"><span style="color: blue;"><b>Introduction to Data Science</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1cQJycGyQ07qSOoeskr6GjjTD3byIkxDbdi228NRgFeU/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="JupyterNumpy.html">Jupyter Notebooks and Numerical Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="Pandas.html">Handling Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="Visualization.html">Visualizing Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="Clustering.html">Finding Structure in Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="Dimensionality.html">Measuring and Reducing Dimensionality</a></li>
<li class="toctree-l2"><a class="reference internal" href="Nonlinear.html">Adapting Linear Methods to Non-Linear Data and Kernel Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_01.html">Homework 01: Introduction to Data Science</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_02.html"><span style="color: blue;"><b>Probability Theory and Density Estimation</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1o9tM9ppKZWIa9B3WIHy5JDF4myR5NkO02W6WAlyiTSg/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="ProbabilityTheory.html">Probability Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="ProbabilityDistributions.html">Important Probability Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="DensityEstimation.html">Estimating Probability Density from Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_02.html">Homework 02: Probability Theory and Density Estimation</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_03.html"><span style="color: blue;"><b>Bayesian Statistics I</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1h2SMuH-Z5a_OE6UMDbFjysEiL2NmYT1tGww6VF5jzsA/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="Statistics.html">Statistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="BayesianInference.html">Bayesian Statistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="MarkovChainMonteCarlo.html">Markov Chain Monte Carlo in Practice</a></li>
<li class="toctree-l2"><a class="reference internal" href="MarkovChains.html">Stochastic Processes and Markov-Chain Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_03.html">Homework 03: Bayesian Statistics and Markov Chains</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_04.html"><span style="color: blue;"><b>Bayesian Statistics II</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/18bft9_CiBLjjBy0MHvT_vN7E95kfakvhm_7d7WKHXyY/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="ModelSelection.html">Bayesian Model Selection</a></li>
<li class="toctree-l2"><a class="reference internal" href="VariationalInference.html">Variational Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="Optimization.html">Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="CrossValidation.html">Cross Validation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_04.html">Homework 04: Metropolis-Hastings and Cross Validation</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_05.html"><span style="color: blue;"><b>Introduction to Artificial Intelligence</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1by3-6jDEorKi7_WEr6PTMfEBE8f4xrS94fNdtSuATVg/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="SupervisedLearning.html">Supervised Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="Learning.html">Artificial Intelligence and Machine Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="ArtificialNeuralNetworks.html">Artificial Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="DeepLearning.html">Deep Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_05.html">Homework 05: Artificial Neural Networks</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_06.html"><span style="color: blue;"><b>Convolutional and Recurrent Neural Networks</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1cDFVtEVGLaWd4256OShSb3Roto0x4y4GwG6LkhVozg0/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="ConvolutionalRecurrentNeuralNetworks.html">Convolutional and Recurrent Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_06.html">Homework 06: Forecasting Projectile Motion with Recurrent Neural Networks</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_07.html"><span style="color: blue;"><b>Geometric Deep Learning and Graph Neural Networks</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1jK61M3QGH7bxFU7TMBm16G3YDb-7HOFtgNdqlj3Gs38/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="GraphNeuralNetworks.html">Geometric Deep Learning and Graph Neural Networks</a></li>





</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_08.html"><span style="color: blue;"><b>Attention Mechanism and Transformers</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1ZHuK7TopASFSoyUoELKeCGT8bullhtSLcEkrp4ZueGg/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="Attention.html">Attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="Transformers.html">Transformers</a></li>
<li class="toctree-l2"><a class="reference internal" href="VisionTransformer.html">Vision Transformer</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Project_01.html"><span style="color: blue;"><b>Project 01</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_01_HiggsTauTau.html">Higgs Boson Decaying to Tau Leptons</a></li>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_01_ExoticParticles.html">Searching for Exotic Particles</a></li>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_01_GalaxyZoo.html">Galaxy Zoo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_01_NuclearGeometryQGP.html">Nuclear Geometry and Characterization of the Quark Gluon Plasma</a></li>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_01_AberratedImages.html">Aberrated Image Recovery of Ultracold Atoms</a></li>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_01_DarkEnergySurvey.html">Dark Energy Survey</a></li>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_01_GravitationalWaves.html">Detection of Gravitational Waves</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../Week_09.html"><span style="color: blue;"><b>Generative Modeling and Simulation-Based Inference</b></span></a><input checked="" class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1h13YeUjtTU_WHLxghxFBBQJO3uRr1GtsIyO4DVZviJo/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="GenerativeModeling.html">Generative Modeling</a></li>
<li class="toctree-l2"><a class="reference internal" href="AutoEncoders.html">Autoencoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="VariationalAutoEncoders.html">Variational AutoEncoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="GenerativeAdversarialNetworks.html">Generative Adversarial Networks</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Diffusion Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="NormalizingFlows.html">Normalizing Flows</a></li>
<li class="toctree-l2"><a class="reference internal" href="SimulationBasedInference.html">Simulation Based Inference</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_10.html"><span style="color: blue;"><b>Reinforcement Learning</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1EsW71u3hdNdXyhlDfkmOX__9c4wJZUee_pjlsmlv_Vg/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="ReinforcementLearning.html">Reinforcement Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_07.html">Homework 07: Reinforcement Learning: Implementing a Deep Q-Network</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_11.html"><span style="color: blue;"><b>AI Explainablility and Uncertainty Quantification</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1ydzY7IEYzALTR6ez5gvwwKDduf_7wUtZddq0SUSuvI0/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="AIExplainabilityUncertaintyQuantification.html">AI Explainability and Uncertainty Quantification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_08.html">Homework 08: Detecting Distribution Shift on MNIST using Bayesian Neural Networks</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_12.html"><span style="color: blue;"><b>Unsupervised Learning and Anomaly Detection</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1ydzY7IEYzALTR6ez5gvwwKDduf_7wUtZddq0SUSuvI0/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="UnsupervisedLearningAnomalyDetection.html">Unsupervised Learning and Anomaly Detection</a></li>

</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_13.html"><span style="color: blue;"><b>Physics Informed Neural Networks</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1C-Z8b6WP5rE8yohZQdSxyH8O_bHIbllq97QhEJYyh0w/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="PhysicsInformedNeuralNetworks.html">Physics Informed Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="LearningTheSchrodingerEquation.html">Solving the Time Dependent Schrodinger Equation with Physics-Informed Deep Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="SymbolicRegression.html">Introduction to Symbolic Regression</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Project_02.html"><span style="color: blue;"><b>Project 02</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_02_AnisotropyQGP.html">Anisotropy in the Quark Gluon Plasma</a></li>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_02_AberratedImages.html">Aberrated Image Recovery of Ultracold Atoms</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_14.html"><span style="color: blue;"><b>Learning from the Machines</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1hkfaU7JVy1f5S8jURZvTY67KRzP7I8zGRf4Zku_bpM4/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="LearningPhysicsMachines.html">Learning Physics from the Machines</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_15.html"><span style="color: blue;"><b>Future of AI and Physics: What Lies Ahead?</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-17"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1eB1qCn5J07D5he_DCpkBiKjbVjdI6OexUzMQ351GCaI/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="LookingForward.html">Future of AI and Physics: What Lies Ahead?</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/illinois-mlp/MachineLearningForPhysics/blob/main/_sources/lectures/Diffusion.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>



<a href="https://github.com/illinois-mlp/MachineLearningForPhysics" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/_sources/lectures/Diffusion.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Diffusion Models</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-diffusion-intuition-span"><span style="color:Orange">Diffusion Intuition</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-a-mathematical-overview-to-understand-diffusion-span"><span style="color:Orange">A Mathematical Overview to Understand Diffusion</span></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-forward-diffusion-span"><span style="color:LightGreen">Forward Diffusion</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-linear-scheduler-span"><span style="color:LightGreen">Linear Scheduler</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-alpha-computation-span"><span style="color:LightGreen">Alpha Computation</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-backward-diffusion-span"><span style="color:LightGreen">Backward Diffusion</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-how-do-we-learn-this-span"><span style="color:LightGreen">How do we learn this?</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-define-sampler-span"><span style="color:LightGreen">Define Sampler</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-lets-test-our-scheduler-span"><span style="color:LightGreen">Lets Test our Scheduler</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-define-model-span"><span style="color:LightGreen">Define Model</span></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-selfattention-mlp-and-transformerblock-span"><span style="color:LightPink">SelfAttention, MLP, and TransformerBlock</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-sinusoidal-time-embeddings-span"><span style="color:LightPink">Sinusoidal Time Embeddings</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-unet-residual-blocks-upsample-blocks-span"><span style="color:LightPink">UNet, Residual Blocks, Upsample Blocks</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-lets-start-with-the-first-piece-residualblocks-span"><span style="color:LightPink">Lets Start with the first piece: ResidualBlocks</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-upsampling-span"><span style="color:LightPink">Upsampling</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-building-the-unet-span"><span style="color:LightPink">Building the UNet</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-high-level-overview-of-some-of-the-specifics-of-the-unet-architecture-span"><span style="color:LightPink">High-level overview of some of the specifics of the UNet architecture</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-putting-it-all-together-the-diffusion-model-span"><span style="color:LightPink">Putting it all together: The Diffusion Model</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-some-helper-functions-span"><span style="color:LightPink">Some Helper Functions</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-get-celeba-dataset-span"><span style="color:LightPink">Get CelebA dataset</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-untar-celeba-dataset-span"><span style="color:LightPink">Untar CelebA dataset</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-train-function-span"><span style="color:LightPink">Train Function</span></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-acknowledgments-span"><span style="color:Orange">Acknowledgments</span></a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="diffusion-models">
<h1>Diffusion Models<a class="headerlink" href="#diffusion-models" title="Permalink to this heading">#</a></h1>
<p>In this lecutre, we will be exploring the architecture of Diffusion models! To understand the details, you will need to know about Self-Attention and Transformers. Please refer the <a class="reference external" href="https://illinois-mlp.github.io/MachineLearningForPhysics/_sources/lectures/Attention.html">Attention</a>, <a class="reference external" href="https://illinois-mlp.github.io/MachineLearningForPhysics/_sources/lectures/Transformers.html">Transformers</a>, and <a class="reference external" href="https://illinois-mlp.github.io/MachineLearningForPhysics/_sources/lectures/VisionTransformer.html">Vision Transformer</a> notebooks for some help if you need it!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">subprocess</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">math</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torchvision</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tqdm.auto</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchvision.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">ImageFolder</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchvision</span><span class="w"> </span><span class="kn">import</span> <span class="n">transforms</span> 
<span class="kn">from</span><span class="w"> </span><span class="nn">PIL</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_cosine_schedule_with_warmup</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">itertools</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">wget_data</span><span class="p">(</span><span class="n">url</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">local_path</span><span class="o">=</span><span class="s1">&#39;./tmp_data&#39;</span><span class="p">):</span>
  <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">local_path</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

  <span class="n">p</span> <span class="o">=</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">Popen</span><span class="p">([</span><span class="s2">&quot;wget&quot;</span><span class="p">,</span> <span class="s2">&quot;-nc&quot;</span><span class="p">,</span> <span class="s2">&quot;-P&quot;</span><span class="p">,</span> <span class="n">local_path</span><span class="p">,</span> <span class="n">url</span><span class="p">],</span> <span class="n">stderr</span><span class="o">=</span><span class="n">subprocess</span><span class="o">.</span><span class="n">PIPE</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;UTF-8&#39;</span><span class="p">)</span>
  <span class="n">rc</span> <span class="o">=</span> <span class="kc">None</span>

  <span class="k">while</span> <span class="n">rc</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">line</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">stderr</span><span class="o">.</span><span class="n">readline</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">line</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
      <span class="nb">print</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
    <span class="n">rc</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">poll</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<section id="span-style-color-orange-diffusion-intuition-span">
<h2><span style="color:Orange">Diffusion Intuition</span><a class="headerlink" href="#span-style-color-orange-diffusion-intuition-span" title="Permalink to this heading">#</a></h2>
<div>
<img src="https://raw.githubusercontent.com/illinois-mlp/MachineLearningForPhysics/main/img/Diffusion-diffusion.png" width=1000></img>
<p><a class="reference external" href="https://scholar.harvard.edu/binxuw/classes/machine-learning-scratch/materials/foundation-diffusion-generative-models">Image Source</a></p>
</div><p>Diffusion models are a powerful form for generative AI that intuitively works pretty easily! We first add noise to an image (forward diffusion process) and then learn how to remove noise from the image (backward diffusion process). Although we add random noise to the image, the noise is not added randomly! More specifically, the noise we add to an image follows a specific noise schedule. In modern diffusion models, there are a large variety of noise schedulers available, but they all do something similar, scheduling of the variance. Therefore, adding noise is easy and follows some rules but removing noise is hard and has to be learned!</p>
<p>The noise we add to the image is always gaussian noise, and a gaussian distribution is characterized by only two parameters, the mean <span class="math notranslate nohighlight">\(\mu\)</span> and variance <span class="math notranslate nohighlight">\(\sigma^2\)</span>. When we sample noise from this distribution, we assume the mean is 0, so we will be scheduling just the variance.</p>
<p>I keep saying schedule but why is this? We don’t actually add noise once, but multiple times! In most diffusion models today, we will add noise 1000 times to the image. By doing so, the original image will become essentially gaussian noise. The scheduler controls the intensity of noise at every step. If you have small variance, then the noise is very small, and if you have a large variance then the noise will be large. You could add the same amount of noise repeatedly to an image 1000 times but that may not be preferable. The scheduler can start by adding small amounts of noise that the beginning, and gradually increase the intensity of noise at every step. The reverse diffusion process then takes the noisy image, the number of times noise was added, and then attempts to remove the noise.</p>
<p>A couple of really important clarifications before we go into the math though!</p>
<ul class="simple">
<li><p>If we add 500 steps of noise to an image, the model will attempt to reconstruct it back to the case where there was NO noise (the original image at step 0)</p></li>
<li><p>During inference, we pass in <span style="color:Violet">random noise</span> with the maximum timesteps of our model, lets pretend its 1000. Then the model will then remove as much noise as it can. We can then pass this denoised image with timestep of 999, and the model will attempt to denoise again. We take the denoised image again, pass it in with timestep 998, rinse and repeat!</p></li>
</ul>
<p>Therefore <span style="color:Violet">inferencing is slightly different than training</span>. When training, we are passing in actual images that have been destroyed with noise. But, even if we add noise to an image, the original image is still somewhere in there, just hidden away. When inferencing, we will only provide true noise, and the model attempts to create something from nothing. This is why we have repeated applications of the denoising model for all timesteps from 1000 down to 1. Even though the model was trained to undo all the timesteps of noise (if we pass in an image with 500 timesteps of noise go back to original image with 0 steps of noise), when the image is actually noise, we will have to reapply the denoising repeatedly to hopefully generate something useful!</p>
</section>
<section id="span-style-color-orange-a-mathematical-overview-to-understand-diffusion-span">
<h2><span style="color:Orange">A Mathematical Overview to Understand Diffusion</span><a class="headerlink" href="#span-style-color-orange-a-mathematical-overview-to-understand-diffusion-span" title="Permalink to this heading">#</a></h2>
<p>There is a lot of interesting math that goes into diffusion, making statisticians super excited (physicists like me less so). There is quite a bit of it and some of it is nice to know, but there are more heavy details that are necessary to get a better grasp. There are things in the derivation that still don’t make total sense to me so I will try to highlights some of the most important parts here. Lets break this up into bite size pieces.</p>
<section id="span-style-color-lightgreen-forward-diffusion-span">
<h3><span style="color:LightGreen">Forward Diffusion</span><a class="headerlink" href="#span-style-color-lightgreen-forward-diffusion-span" title="Permalink to this heading">#</a></h3>
<p><span style="color:Violet">Forward diffusion</span> is the process of iteratively adding noise to data according to some variance schedule for <span class="math notranslate nohighlight">\(T\)</span> timesteps. We will identify the forward process with the variable <span class="math notranslate nohighlight">\(q\)</span> which will identify the conditional distribution of some noise image <span class="math notranslate nohighlight">\(X_T\)</span> given the original image <span class="math notranslate nohighlight">\(X_0\)</span>. We can then write all the steps <span class="math notranslate nohighlight">\(1,...T\)</span> of noise as the following:</p>
<div class="math notranslate nohighlight">
\[ \Large
q(x_{1:T}|x_0) = \prod_{t=1}^Tq(x_t|x_{t-1})
\]</div>
<p>As you can see, we are just multiplying every consecutive pairs of timesteps together to get our full probability distribution of all the timesteps together. The original DDPM paper then says that we can write a single one of these consecutive timestep probabilities as follows:</p>
<div class="math notranslate nohighlight">
\[ \Large
\boxed{
q(x_t|x_{t-1}) = N(x_t;\sqrt{1-B_t}x_{t-1}, B_t) }
\]</div>
<p>where <span class="math notranslate nohighlight">\(B_1, B_2, ..., B_T\)</span> is a fixed noise schedule for the variance.</p>
<p>Basically, <span class="math notranslate nohighlight">\(x_t\)</span> should be sampled from a normal distribution with a mean centered at <span class="math notranslate nohighlight">\(\sqrt{1-B_t}x_{t-1}\)</span>, based on the previous timestep, and variance of <span class="math notranslate nohighlight">\(B_t\)</span>. But where did this even come from? At every step we add some noise, but if we dont scale the x down as we add noise we will have a variance explosion, therefore we can do this proof:</p>
<hr class="docutils" />
<p><em><strong><span style="color:Violet">Proof</span></strong></em></p>
<p>Let <span class="math notranslate nohighlight">\(x_0 \sim N(\mu, 1)\)</span>, so it has some arbritary mean and a variance of 1. We want to add noise to the image <span class="math notranslate nohighlight">\(x_0\)</span> but <strong>ALWAYS KEEP THE VARIANCE AT 1</strong> to avoid any variance explosions. Lets pretend our nosie is just randomly sampled from a standard normal distribution:</p>
<div class="math notranslate nohighlight">
\[ \Large
\epsilon \sim N(0,1)
\]</div>
<p>To compute <span class="math notranslate nohighlight">\(x_1\)</span> we will scale <span class="math notranslate nohighlight">\(x_0\)</span> by some unknown factor <span class="math notranslate nohighlight">\(a\)</span> and scale the added noise by another unknown factor <span class="math notranslate nohighlight">\(b\)</span>. Therefore we can write it as:</p>
<div class="math notranslate nohighlight">
\[ \Large
x_1 = ax_0 + b\epsilon
\]</div>
<p>Now a quick review of normal distributions! If we multiply a normal distribution by some constant what happens?</p>
<div class="math notranslate nohighlight">
\[ \Large
Var(aX) = a^2Var(x)
\]</div>
<p>Remember again, our variance scheduler determines the amount of noise added at every step, but currently the noise is just standard normal, but we want <span class="math notranslate nohighlight">\(\epsilon_1\)</span> to have variance <span class="math notranslate nohighlight">\(B_1\)</span>. That should be easy enough to do because of the variance product rule! If <span class="math notranslate nohighlight">\(\epsilon_1\)</span> has variance 1, then:</p>
<div class="math notranslate nohighlight">
\[ \Large
Var(\sqrt{B_1}\epsilon_1) = (\sqrt{B_1})^2Var(\epsilon_1) = B_1 * 1 = B_1
\]</div>
<p>So now we know in our equation <span class="math notranslate nohighlight">\(x_1 = ax_0 + b\epsilon\)</span> that b should be <span class="math notranslate nohighlight">\(\sqrt{B_1}\)</span>, so we can write our first step out as:</p>
<div class="math notranslate nohighlight">
\[ \Large
x_1 = ax_0 + \sqrt{B_1}\epsilon
\]</div>
<p>Now the second condition! We want to make sure that <span class="math notranslate nohighlight">\(x_1\)</span> has an overall variance of 1 at the end to avoid variance explosions, so we can compute a to make that happen.</p>
<div class="math notranslate nohighlight">
\[ \Large
Var(x_1) = Var(ax_0 + \sqrt{B_1}\epsilon) = Var(ax_0) + Var(\sqrt{B_1}\epsilon)
\]</div>
<p>Again remember, <span class="math notranslate nohighlight">\(x_0\)</span> has a variance of 1 and <span class="math notranslate nohighlight">\(\epsilon\)</span> also has a variance of 1, so by the variance rule we can compute:</p>
<div class="math notranslate nohighlight">
\[ \Large
Var(x_1) = a^2Var(x_0) + B_1Var(\epsilon) = a^2 + B_1
\]</div>
<p>This variance then has to have a sum of 1, so we can solve for a,</p>
<div class="math notranslate nohighlight">
\[ \Large
a^2 + B_1 = 1 ~~~\text{  therefore  }~~~ a = \sqrt{1 - B_1}
\]</div>
<p>Therefore we have:</p>
<div class="math notranslate nohighlight">
\[ \Large
x_1 = \sqrt{1-b_1}x_0 + \sqrt{B_1}\epsilon
\]</div>
<p>and we can write the more general form for an arbritrary <span class="math notranslate nohighlight">\(t\)</span>:</p>
<div class="math notranslate nohighlight">
\[ \Large
x_t = \sqrt{1-b_t}x_{t-1} + \sqrt{B_t}\epsilon
\]</div>
<p>Which can also be written as <span class="math notranslate nohighlight">\(q(x_t|x_{t-1}) = N(x_t;\sqrt{1-B_t}x_t, B_t)\)</span></p>
<hr class="docutils" />
<p>So first things first, we need a list of numbers to be our schedule for noise! There are a ton of schedulers out there (linear, cosine, etc…) so lets just go with a simple linear scheduler:</p>
</section>
<section id="span-style-color-lightgreen-linear-scheduler-span">
<h3><span style="color:LightGreen">Linear Scheduler</span><a class="headerlink" href="#span-style-color-lightgreen-linear-scheduler-span" title="Permalink to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">beta_start</span> <span class="o">=</span> <span class="mf">0.0001</span>
<span class="n">beta_end</span> <span class="o">=</span> <span class="mf">0.2</span>
<span class="n">num_training_steps</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">beta_schedule</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">beta_start</span><span class="p">,</span> <span class="n">beta_end</span><span class="p">,</span> <span class="n">num_training_steps</span><span class="p">)</span>
</pre></div>
</div>
<p><span style="color:Violet">Increasing Computational Efficiency</span></p>
<p>So we have made it back to our original equation! But we still have a problem, which has more to do with practical efficiency rather than theory. If we want an image with 500 steps of noise added to it, we actually need to do a for loop to repeatedly add noise, but would’t it be nice to be able to add all 500 steps of noise in just a single calculation? We are just adding gaussian noise over and over to an image, and we know the sum of gaussians are also a gaussian, so we should be able to do this.</p>
<p>In the paper they do this by introducing a new variable that is just a manipulation of our old variable <span class="math notranslate nohighlight">\(B_t\)</span></p>
<div class="math notranslate nohighlight">
\[ \Large
a_t = 1 - B_t \text{ and } \bar{a}_t = \prod_{s=1}^t\alpha_s
\]</div>
<p>for example:</p>
<div class="math notranslate nohighlight">
\[ \Large
\bar{a}_2 = a_1 * a_2 = (1-B_1)*(1-B_2)
\]</div>
<p>We can go ahead and compute these pieces as well then!</p>
</section>
<section id="span-style-color-lightgreen-alpha-computation-span">
<h3><span style="color:LightGreen">Alpha Computation</span><a class="headerlink" href="#span-style-color-lightgreen-alpha-computation-span" title="Permalink to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="c1">### Compute Alpha ###</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">beta_schedule</span>

<span class="c1">### Compute Cumulative Alpha ###</span>
<span class="n">alpha_cumulative_prod</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cumprod</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>
</pre></div>
</div>
<p>So time for some fun algebraic manipipulations! Rember our previous eqation for <span class="math notranslate nohighlight">\(x_t\)</span>?</p>
<div class="math notranslate nohighlight">
\[ \Large
x_t = \sqrt{1-b_t}x_{t-1} + \sqrt{B_t}\epsilon
\]</div>
<p>Lets rewrite this in terms of our new variable <span class="math notranslate nohighlight">\(a_t\)</span></p>
<div class="math notranslate nohighlight">
\[ \Large
x_t = \sqrt{a_t}x_{t-1} + \sqrt{1 - a_t}\epsilon
\]</div>
<p>Well <span class="math notranslate nohighlight">\(x_{t-1}\)</span> can be written very similarly:</p>
<div class="math notranslate nohighlight">
\[ \Large
x_{t-1} = \sqrt{a_{t-1}}x_{t-2} + \sqrt{1-a_{t-1}}\epsilon
\]</div>
<p>Lets substitute <span class="math notranslate nohighlight">\(x_{t-1}\)</span> into our formula for <span class="math notranslate nohighlight">\(x_t\)</span></p>
<div class="math notranslate nohighlight">
\[ \Large
x_t = \sqrt{a_t} [ \sqrt{a_{t-1}}x_{t-2} + \sqrt{1-a_{t-1}}\epsilon]  + \sqrt{1 - a_t}\epsilon
\]</div>
<div class="math notranslate nohighlight">
\[ \Large
= \sqrt{a_t}\sqrt{a_{t-1}}x_{t-2} + \sqrt{a_t}\sqrt{1 - a_{t-1}}\epsilon + \sqrt{1 - a_t}\epsilon
\]</div>
<p>Now how can we simplify this? This was probably one of the tricker parts of the derivation that I didn’t catch at first glance. Remember again, <span class="math notranslate nohighlight">\(\epsilon\)</span> is just a random variable coming from a standard normal distribution, and by multiplying it by some constant, we are adjusting its variance. We have two parts of our equation above using epsilon, so lets try to combine them! Therefore lets create some temporary random variables using our variance rule from earlier:</p>
<div class="math notranslate nohighlight">
\[ \Large
\sqrt{a_t}\sqrt{1 - a_{t-1}}\epsilon = X \sim N(0, a_t(1 - a_{t-1}))
\]</div>
<div class="math notranslate nohighlight">
\[ \Large
\sqrt{1 - a_t}\epsilon = Y \sim N(0, 1 - a_t)
\]</div>
<p>Therefore <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> are both normal distributions with different variances. So a quick review, what happens when we add two normal distributions together with different means and variances?</p>
<div class="math notranslate nohighlight">
\[ \Large
N(\mu_1, \sigma_1^2) + N(\mu_2, \sigma_2^2) = N(\mu_1+\mu_2, \sigma_1^2+\sigma_2^2)
\]</div>
<p>So similarly, lets add together our two normal distributions <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> above.</p>
<div class="math notranslate nohighlight">
\[ \Large
X + Y = N(0, a_t(1 - a_{t-1})) + N(0, 1 - a_t) = N(0, a_t(1 - a_{t-1}) + (1 - a_t))
\]</div>
<div class="math notranslate nohighlight">
\[ \Large
= N(0, 1 - a_ta_{t-1})
\]</div>
<p>Again by the variance rule we can write this normal distribution as the standard normal epsilon, multiplied by the sqrt of the variance we want:</p>
<div class="math notranslate nohighlight">
\[ \Large
N(0, 1 - a_ta_{t-1}) = \sqrt{1 - a_ta_{t-1}}\epsilon
\]</div>
<p>Therefore our final equation for <span class="math notranslate nohighlight">\(x_t\)</span> can be written as:</p>
<div class="math notranslate nohighlight">
\[ \Large
x_t = \sqrt{a_t}\sqrt{a_{t-1}}x_{t-2} + (\sqrt{1 - a_ta_{t-1}})\epsilon
\]</div>
<p>Now what if we substituted in the equation for <span class="math notranslate nohighlight">\(x_{t-2}\)</span> like we did earlier for <span class="math notranslate nohighlight">\(x_{t-1}\)</span>? Well the same thing! Actually we can continue substituting repeatedly and you will see a pattern emerge that,</p>
<div class="math notranslate nohighlight">
\[ \Large
q(x_t|x_0) = \prod_{i=1}^t\sqrt{a_i}x_0 + (\sqrt{1 - \prod_{i=1}^ta_i})\epsilon
\]</div>
<p>Which is then written with the shorthand <span class="math notranslate nohighlight">\(\bar{a}_t\)</span> notation.</p>
<div class="math notranslate nohighlight">
\[ \Large
q(x_t|x_0) = \sqrt{\bar{a}_t}x_0 + (\sqrt{1 - \bar{a}_t})\epsilon
\]</div>
<p>So we did it! If you made it this far, you should now understand all the details about the forward diffusion process and ways we can make it more efficient. Lets do a quick implementation of the formulas above:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="c1">### What is the image we want to add noise to ? ###</span>
<span class="n">x_0</span> <span class="o">=</span> <span class="n">IMAGE</span>

<span class="c1">### What is the timestep we want? Lets add 500 steps of noise ###</span>
<span class="n">timestep</span> <span class="o">=</span> <span class="mi">500</span>

<span class="c1">### Grab the corresponding cumulative alpha for 500 steps of noise ###</span>
<span class="n">alpha_bar_t</span> <span class="o">=</span> <span class="n">alpha</span><span class="p">[</span><span class="n">timestep</span><span class="p">]</span>

<span class="c1">### Compute Mean Coefficient ###</span>
<span class="n">mean_coeff</span> <span class="o">=</span> <span class="n">alpha_bar_t</span> <span class="o">**</span> <span class="mf">0.5</span>

<span class="c1">### Compute Variance Coefficient ###</span>
<span class="n">var_coeff</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha_bar_t</span><span class="p">)</span> <span class="o">**</span> <span class="mf">0.5</span>

<span class="c1">### Generate some Random Noise for the Episilon ###</span>
<span class="n">epsilon</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">x_0</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1">### Use the reparamaterization trick to sample from distribution ###</span>
<span class="n">noisy_image</span> <span class="o">=</span> <span class="n">mean_coef</span><span class="o">*</span><span class="n">inputs</span> <span class="o">+</span> <span class="n">var_coef</span><span class="o">*</span><span class="n">epsilon</span>

</pre></div>
</div>
</section>
<section id="span-style-color-lightgreen-backward-diffusion-span">
<h3><span style="color:LightGreen">Backward Diffusion</span><a class="headerlink" href="#span-style-color-lightgreen-backward-diffusion-span" title="Permalink to this heading">#</a></h3>
<p>Forward diffusion is not too bad! Basically we have a scheduler, so we know the sequence of gaussian distributions we want to sample noise from, and we iteratively add steps of noise to our image.</p>
<p>On the other hand, how do we undo the steps of noise? Unfortunately, this is much harder and we will have to use a Neural Network to approximate this <span style="color:Violet">Backward Diffusion</span> step.</p>
<p>Lets write out this with some math again where we want to represent, what is the distribution of the removal of <span class="math notranslate nohighlight">\(T\)</span> steps of noise?</p>
<div class="math notranslate nohighlight">
\[ \Large
P_\theta(x_{0:T}) = P(X_T)\prod_{t=1}^TP_\theta(X_{t-1}|x_t)
\]</div>
<p>Notice the conditional <span class="math notranslate nohighlight">\(P_\theta(X_{t-1}|x_t)\)</span>, we want the previous timestep given a future one, which is backwards from the forward diffusion process. We can represent this probability as the following:</p>
<div class="math notranslate nohighlight">
\[ \Large
P(X_T)\prod_{t=1}^TP_\theta(X_{t-1}|x_t) \sim N(x_{t-1}; \mu_\theta(x_t, t), \Sigma_\theta(x_t,t))
\]</div>
<p>where <span class="math notranslate nohighlight">\(\mu_\theta(x_t, t), \Sigma_\theta(x_t,t)\)</span> have to be learned by the neural network.</p>
<p>Again we have no idea what these reverse probability distributions are. But what was the original problem we want to solve? We want to compute <span class="math notranslate nohighlight">\(P(x_0)\)</span>, the distribution of the original image data. But right now we will have the joint distribution of <span class="math notranslate nohighlight">\(P_\theta(x_{0:T})\)</span> which means we need to marginalize our distribution. If you don’t know what marginalizaing a distribution means just take a quick look <a class="reference external" href="https://en.wikipedia.org/wiki/Marginal_distribution">here</a>. At a high level, if you have a joint distribution in two variables, and you only want one of them, you can integrate out the ones that you dont. In our case it will look something like this:</p>
<div class="math notranslate nohighlight">
\[ \Large
P(x_0) = \int_{x_1}\int_{x_2}\int_{x_3}...\int_{x_T} P(x_{0:T})dx_1dx_2...dx_T
\]</div>
<p>This would be an incredibly expensive process though so instead we will take a hint from Variational AutoEncoders and use the <em>Evidence Lower Bound</em>.</p>
<p>The mathematical derivation is out of the scope of gathering some intuition for diffusion models as I try to push a more hands-on approach than a theory driven one. I was writing the derivation out myself when making this lecture and then I found an incredible resource! Author Lilian Weng has this great blog post <a class="reference external" href="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/">What are Diffusion Models?</a> where it covers all the ground level math for you to really know the reverse process. Definitely give it a read, you will need to know a bit about ELBO and Bayes rule to do it but it should be pretty intuitive. In our case, lets just go over the results of the reverse diffusion process rather than the derivation. This was the given recipie by the original DDPM paper.</p>
<p>First we will have a small change in the forward diffusion process. Up to now, we have been doing forward diffusion as <span class="math notranslate nohighlight">\(q(x_t|x_{t-1})\)</span>. Instead, we will also condition <span class="math notranslate nohighlight">\(x_t\)</span> on <span class="math notranslate nohighlight">\(x_0\)</span>, so it will look like <span class="math notranslate nohighlight">\(q(x_t|x_{t-1}, x_0)\)</span>. We can then use Bayes rule to get an expression for <span class="math notranslate nohighlight">\(q(x_{t-1}|x_t, x_0)\)</span>. The reason for this is, if you do the derivation, you will see that the reverse conditional probability actually isn’t possible to solve without conditioning on <span class="math notranslate nohighlight">\(x_0\)</span>. This is the first main derivation showed in Lilian Weng’s blog post that you can look at. But the result is:</p>
<div class="math notranslate nohighlight">
\[ \Large
q(x_{t-1}|x_t, x_0) \sim N(x_{t-1}; \tilde{\mu}(x_t, x_0), \Sigma_\theta(x_t,t))
\]</div>
<p>We can then write <span class="math notranslate nohighlight">\(\tilde{\mu}_t\)</span> as:</p>
<div class="math notranslate nohighlight">
\[ \Large
\tilde{\mu}_t = \frac{1}{\sqrt{a_t}}(x_t - \frac{1-a_t}{\sqrt{1-\bar{a_t}}}e_t)
\]</div>
<p>and our full expression for <span class="math notranslate nohighlight">\(q(x_{t-1}|x_t, x_0)\)</span> becomes:</p>
<div class="math notranslate nohighlight">
\[ \Large
q(x_{t-1}|x_t, x_0) \sim N(x_{t-1}; \frac{1}{\sqrt{a_t}}(x_t - \frac{1-a_t}{\sqrt{1-\bar{a_t}}}e_t), \Sigma_\theta(x_t,t))
\]</div>
<p>In the original DDPM paper <strong>ONLY</strong> the mean of the reverse process is learned, <span class="math notranslate nohighlight">\(\mu_\theta\)</span> and the variance <span class="math notranslate nohighlight">\(\Sigma_t\)</span> is fixed according to the scheduler. So we can then set <span class="math notranslate nohighlight">\(\Sigma_\theta(x_t,t) \to \sigma_t^2I\)</span>.</p>
<p>In later papers like the <a class="reference external" href="https://openreview.net/pdf?id=-NEXDKk8gZ">Improved Diffusion Models</a> paper, the model will learn both the mean and variance of the reverse process. Because <span class="math notranslate nohighlight">\(\sigma_t^2I\)</span> is set ahead of time, we can directly compute it. The paper sets this as:</p>
<div class="math notranslate nohighlight">
\[ \Large
\sigma_t^2I = \frac{1-\bar{a}_{t-1}}{1-\bar{a}_{t}}B_t
\]</div>
<p>We could also have done <span class="math notranslate nohighlight">\(\sigma_t^2I = B_t\)</span> and directly used our beta schedule only but the DDPM paper found no difference experimentally between using one or the other, so we will just go with the previous expression as its typically used in implementations I’ve seen!</p>
<p>So our final form of the reverse process is:</p>
<div class="math notranslate nohighlight">
\[ \Large
\boxed{
    q(x_{t-1}|x_t, x_0) \sim N(x_{t-1}; \frac{1}{\sqrt{a_t}}(x_t - \frac{1-a_t}{\sqrt{1-\bar{a_t}}}e_t), \sigma_t^2I) }
\]</div>
<p>I know I skipped over a ton of mathematical detail again, maybe later I’ll make a deeper dive into the reverse process! But for now this should be enough to get started and have a basic understanding.</p>
<p>Lets quickly look at the simplified code that will compute all of this! There are three things we need: (1) the noisy image, (2) what timestep we are on, and (3) the predicted noise.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="c1">### Pass in the things we need ###</span>
<span class="n">timestep</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">noisy_image</span> <span class="o">=</span> <span class="n">NOISY_IMAGE</span>
<span class="n">predicted_noise</span> <span class="o">=</span> <span class="n">PREDICTED_NOISE</span>

<span class="c1">### Compute Sigma (b_t * (1 - cumulative_a_(t-1)) / (1 - cumulative_a)) * noise ###</span>
<span class="n">alpha_bar_t</span> <span class="o">=</span> <span class="n">alpha_cumulative_prod</span><span class="p">[</span><span class="n">timestep</span><span class="p">]</span>
<span class="n">alpha_bar_t_prev</span> <span class="o">=</span> <span class="n">alpha_cumulative_prod</span><span class="p">[</span><span class="n">timestep</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">beta_t</span> <span class="o">=</span> <span class="n">beta_schedule</span><span class="p">[</span><span class="n">timestep</span><span class="p">]</span>
<span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="n">variance</span> <span class="o">=</span> <span class="n">beta_t</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha_cumulative_prod_t_prev</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha_cumulative_t</span><span class="p">)</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="n">noise</span> <span class="o">*</span> <span class="n">variance</span><span class="o">**</span><span class="mf">0.5</span>

<span class="c1">### Compute Noise Coefficient (1 - a_t / sqrt(1 - cumulative_a)) where 1 - a_t = b_t ###</span>
<span class="n">beta_t</span> <span class="o">=</span> <span class="n">beta_schedule</span><span class="p">[</span><span class="n">timestep</span><span class="p">]</span>
<span class="n">alpha_bar_t</span> <span class="o">=</span> <span class="n">alpha_cumulative_prod</span><span class="p">[</span><span class="n">timestep</span><span class="p">]</span>
<span class="n">root_one_minus_alpha_bar_t</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha_bar_t</span><span class="p">)</span> <span class="o">**</span> <span class="mf">0.5</span>
<span class="n">noise_coefficient</span> <span class="o">=</span> <span class="n">beta_t</span> <span class="o">/</span> <span class="n">root_one_minus_alpha_bar_t</span>

<span class="c1">### Compute 1 / sqrt(a_t) ###</span>
<span class="n">reciprocal_root_a_t</span> <span class="o">=</span> <span class="p">(</span><span class="n">alpha</span><span class="p">[</span><span class="n">timestep</span><span class="p">]</span><span class="o">**-</span><span class="mf">0.5</span><span class="p">)</span>

<span class="c1">### Compute Denoised Image ###</span>
<span class="n">denoised</span> <span class="o">=</span> <span class="n">reciprocal_root_a_t</span> <span class="o">*</span> <span class="p">(</span><span class="n">noisy_image</span> <span class="o">-</span> <span class="p">(</span><span class="n">noise_coefficient</span> <span class="o">*</span> <span class="n">predicted_noise</span><span class="p">))</span> <span class="o">+</span> <span class="n">sigma_z</span>

</pre></div>
</div>
</section>
<section id="span-style-color-lightgreen-how-do-we-learn-this-span">
<h3><span style="color:LightGreen">How do we learn this?</span><a class="headerlink" href="#span-style-color-lightgreen-how-do-we-learn-this-span" title="Permalink to this heading">#</a></h3>
<p>As you can see, the entire problem now boils down to: given an image that is noisy, predict the noise so we can remove it!</p>
<p>The DDPM paper states that we can then  take an image, predict the noise, and use Mean Squared Error as our loss function between the predicted and true noise. In practice though you could also use Mean Absolute Error or the Huber Loss (L1 + L2 Error). There are some mathematical justifications for this too. If you think back to Variational Autoencoders, what are trying to do is to maximize the Evidence Lower Bound (ELBO) because learning the likelihood of the data generating distribution is impossible, but we can learn the minmum bound of that function and continue to maximize it. The reason we are not taking a similar approach here is, the authors of DDPM claim that as long as the steps of noise added to the image is sufficiently small, we can approximate it with Mean Squared Error. You can take a closer look <a class="reference external" href="https://jaketae.github.io/study/elbo/">here</a> if you want to see more!</p>
</section>
<section id="span-style-color-lightgreen-define-sampler-span">
<h3><span style="color:LightGreen">Define Sampler</span><a class="headerlink" href="#span-style-color-lightgreen-define-sampler-span" title="Permalink to this heading">#</a></h3>
<p>We will now take everything we say previously and put it all together to create our scheduler! There are again a lot of different schedulers that exist, but for now we will stick to the basis linear beta scheduler. Again, at a high level, the sampler will have two methods:</p>
<ul class="simple">
<li><p><em><strong><span style="color:Violet">add_noise</span></strong></em>: will take an image and add some timesteps amount of noise to it</p></li>
<li><p><em><strong><span style="color:Violet">remove_noise</span></strong></em>: will take a noisy image, which timestep of noise it was at, models predicted noise, and removes the noise accoring the scheduling parameters</p></li>
</ul>
<p>The other change that will be made from the pseudocode before is we need to make sure out adding/removing noise can be applied to batches of images, and can occur on the correct device if it isn’t running on the CPU!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">Sampler</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_training_steps</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">beta_start</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">beta_end</span><span class="o">=</span><span class="mf">0.02</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_training_steps</span> <span class="o">=</span> <span class="n">num_training_steps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta_start</span> <span class="o">=</span> <span class="n">beta_start</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta_end</span> <span class="o">=</span> <span class="n">beta_end</span>

        <span class="c1">### Define Basic Beta Scheduler ###</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta_schedule</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_beta_schedule</span><span class="p">()</span>

        <span class="c1">### Compute Alphas for Direction 0 &gt; t Noise Calculation ###</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta_schedule</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha_cumulative_prod</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cumprod</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">linear_beta_schedule</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">beta_start</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta_end</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_training_steps</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_repeated_unsqueeze</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target_shape</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="k">while</span> <span class="n">target_shape</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&gt;</span> <span class="nb">input</span><span class="o">.</span><span class="n">dim</span><span class="p">():</span>
            <span class="nb">input</span> <span class="o">=</span> <span class="nb">input</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">input</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">add_noise</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">):</span>

        <span class="n">batch_size</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">shape</span>

        <span class="c1">### Grab the Device we want to place tensors on ###</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">device</span>
        
        <span class="n">alpha_cumulative_prod_timesteps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha_cumulative_prod</span><span class="p">[</span><span class="n">timesteps</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        
        <span class="c1">### Compute Mean Coefficient ###</span>
        <span class="n">mean_coeff</span> <span class="o">=</span> <span class="n">alpha_cumulative_prod_timesteps</span> <span class="o">**</span> <span class="mf">0.5</span>

        <span class="c1">### Compute Variance Coefficient ###</span>
        <span class="n">var_coeff</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha_cumulative_prod_timesteps</span><span class="p">)</span> <span class="o">**</span> <span class="mf">0.5</span>

        <span class="c1">### Reshape mean_coeff and var_coeff to have shape (batch x 1 x 1 x 1) so we can broadcast with input (batch x c x height x width) ###</span>
        <span class="n">mean_coeff</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_repeated_unsqueeze</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">mean_coeff</span><span class="p">)</span>
        <span class="n">var_coeff</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_repeated_unsqueeze</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">var_coeff</span><span class="p">)</span>

        <span class="c1">### Generate some Noise X ~ N(0,1) (rand_like will automatically place on same device as the inputs) ###</span>
        <span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        
        <span class="c1">### Compute Mean (mean_coef * x_0) ###</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">mean_coeff</span> <span class="o">*</span> <span class="n">inputs</span>

        <span class="c1">### Compute Variance ###</span>
        <span class="n">var</span> <span class="o">=</span> <span class="n">var_coeff</span> <span class="o">*</span> <span class="n">noise</span>

        <span class="c1">### Compute Noisy Data ###</span>
        <span class="n">noisy_image</span> <span class="o">=</span> <span class="n">mean</span> <span class="o">+</span> <span class="n">var</span>

        <span class="k">return</span> <span class="n">noisy_image</span><span class="p">,</span> <span class="n">noise</span>
        
    <span class="k">def</span><span class="w"> </span><span class="nf">remove_noise</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">timestep</span><span class="p">,</span> <span class="n">predicted_noise</span><span class="p">):</span>

        <span class="k">assert</span> <span class="p">(</span><span class="nb">input</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">predicted_noise</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span> <span class="s2">&quot;Shapes of noise pattern and input image must be identical!!&quot;</span>
        
        <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="nb">input</span><span class="o">.</span><span class="n">shape</span>

        <span class="c1">### Grab Device to Place Tensors On ###</span>
        <span class="n">device</span> <span class="o">=</span> <span class="nb">input</span><span class="o">.</span><span class="n">device</span>

        <span class="c1">### Create a mask (if timestep == 0 sigma_z will also be 0 so we need to save this for later ###</span>
        <span class="n">greater_than_0_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">timestep</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">int</span><span class="p">()</span>

        
        <span class="c1">### Compute Sigma (b_t * (1 - cumulative_a_(t-1)) / (1 - cumulative_a)) * noise ###</span>
        <span class="n">alpha_cumulative_t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha_cumulative_prod</span><span class="p">[</span><span class="n">timestep</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">alpha_cumulative_prod_t_prev</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha_cumulative_prod</span><span class="p">[</span><span class="n">timestep</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="c1"># (timestep - 1) if timestep is 0 is WRONG! we will multiply by 0 later</span>
        <span class="n">beta_t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta_schedule</span><span class="p">[</span><span class="n">timestep</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="n">variance</span> <span class="o">=</span> <span class="n">beta_t</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha_cumulative_prod_t_prev</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha_cumulative_t</span><span class="p">)</span>

        <span class="c1">### 0 out the variance for if the timestep == 0 ###</span>
        <span class="n">variance</span> <span class="o">=</span> <span class="n">variance</span> <span class="o">*</span> <span class="n">greater_than_0_mask</span>
        <span class="n">variance</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_repeated_unsqueeze</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">variance</span><span class="p">)</span>
        <span class="n">sigma_z</span> <span class="o">=</span> <span class="n">noise</span> <span class="o">*</span> <span class="n">variance</span><span class="o">**</span><span class="mf">0.5</span>

        <span class="c1">### Compute Noise Coefficient (1 - a_t / sqrt(1 - cumulative_a)) where 1 - a_t = b_t ###</span>
        <span class="n">beta_t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta_schedule</span><span class="p">[</span><span class="n">timestep</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">alpha_cumulative_t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha_cumulative_prod</span><span class="p">[</span><span class="n">timestep</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">root_one_minus_cumulative_alpha_t</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha_cumulative_t</span><span class="p">)</span> <span class="o">**</span> <span class="mf">0.5</span>
        <span class="n">noise_coefficient</span> <span class="o">=</span> <span class="n">beta_t</span> <span class="o">/</span> <span class="n">root_one_minus_cumulative_alpha_t</span>
        <span class="n">noise_coefficient</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_repeated_unsqueeze</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">noise_coefficient</span><span class="p">)</span>
        

        <span class="c1">### Compute 1 / sqrt(a_t) ###</span>
        <span class="n">reciprocal_root_a_t</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">[</span><span class="n">timestep</span><span class="p">]</span><span class="o">**-</span><span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">reciprocal_root_a_t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_repeated_unsqueeze</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">reciprocal_root_a_t</span><span class="p">)</span>
        
        <span class="c1">### Compute Denoised Image ###</span>
        <span class="n">denoised</span> <span class="o">=</span> <span class="n">reciprocal_root_a_t</span> <span class="o">*</span> <span class="p">(</span><span class="nb">input</span> <span class="o">-</span> <span class="p">(</span><span class="n">noise_coefficient</span> <span class="o">*</span> <span class="n">predicted_noise</span><span class="p">))</span> <span class="o">+</span> <span class="n">sigma_z</span>
 
        <span class="k">return</span> <span class="n">denoised</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="span-style-color-lightgreen-lets-test-our-scheduler-span">
<h3><span style="color:LightGreen">Lets Test our Scheduler</span><a class="headerlink" href="#span-style-color-lightgreen-lets-test-our-scheduler-span" title="Permalink to this heading">#</a></h3>
<p>For this, we need a sample image, transformations to go from images to tensors, and to go back to images from tensors. For the transformations, we will make use of the ones give in the <a class="reference external" href="https://huggingface.co/blog/annotated-diffusion">Huggingface Annotated Diffusion</a>!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">wget_data</span><span class="p">(</span><span class="s1">&#39;https://raw.githubusercontent.com/illinois-mlp/MachineLearningForPhysics/main/data/kitten.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>File ‘./tmp_data/kitten.png’ already there; not retrieving.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">### Define an Image Size ###</span>
<span class="n">image_size</span> <span class="o">=</span> <span class="mi">256</span>

<span class="c1">### Load Image ###</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">&quot;./tmp_data/kitten.png&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s2">&quot;RGB&quot;</span><span class="p">)</span>

<span class="c1">### Init Sampler ###</span>
<span class="n">sampler</span> <span class="o">=</span> <span class="n">Sampler</span><span class="p">()</span>

<span class="c1">### Transformations ###</span>
<span class="n">image2tensor_transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
                    <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">((</span><span class="n">image_size</span><span class="p">,</span> <span class="n">image_size</span><span class="p">)),</span> <span class="c1"># Resize Image</span>
                    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> <span class="c1"># Convert to tensor (will scale from 0 to 1)</span>
                    <span class="n">transforms</span><span class="o">.</span><span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="p">(</span><span class="n">t</span><span class="o">*</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span> <span class="c1"># Change scale to be -1 to 1</span>
                    <span class="n">transforms</span><span class="o">.</span><span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
<span class="p">])</span>

<span class="n">tensor2image_transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)),</span> <span class="c1"># Remove batch dimension on</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="p">(</span><span class="n">t</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">),</span> <span class="c1"># Scale back to 0 to 1</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)),</span> <span class="c1"># Make channels last </span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span> <span class="o">*</span> <span class="mf">255.</span><span class="p">),</span> <span class="c1"># Scale back to 0 to 255</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)),</span> <span class="c1"># Convert to numpy</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">ToPILImage</span><span class="p">(),</span> <span class="c1"># Conver to PIL</span>
    <span class="p">])</span>


<span class="c1">### Check Transforms ###</span>
<span class="n">tensor2image_transform</span><span class="p">(</span><span class="n">image2tensor_transform</span><span class="p">(</span><span class="n">image</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/c6b956bbcf05335d4b00af86164adea2fe75af6f05abd8cd46121c07738181ca.png" src="../../_images/c6b956bbcf05335d4b00af86164adea2fe75af6f05abd8cd46121c07738181ca.png" />
</div>
</div>
</section>
<section id="span-style-color-lightgreen-define-model-span">
<h3><span style="color:LightGreen">Define Model</span><a class="headerlink" href="#span-style-color-lightgreen-define-model-span" title="Permalink to this heading">#</a></h3>
<p>We can now define the structure of the model. The parts are:</p>
<section id="span-style-color-lightpink-selfattention-mlp-and-transformerblock-span">
<h4><span style="color:LightPink">SelfAttention, MLP, and TransformerBlock</span><a class="headerlink" href="#span-style-color-lightpink-selfattention-mlp-and-transformerblock-span" title="Permalink to this heading">#</a></h4>
<p>Please refer the <a class="reference external" href="https://illinois-mlp.github.io/MachineLearningForPhysics/_sources/lectures/Attention.html">Attention</a>, <a class="reference external" href="https://illinois-mlp.github.io/MachineLearningForPhysics/_sources/lectures/Transformers.html">Transformers</a>, and <a class="reference external" href="https://illinois-mlp.github.io/MachineLearningForPhysics/_sources/lectures/VisionTransformer.html">Vision Transformer</a> notebooks for some help if you need it to understand the code below.</p>
<div>
<img src="https://raw.githubusercontent.com/illinois-mlp/MachineLearningForPhysics/main/img/Diffusion-computing_attention.png" width=1000></img>
</div><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">SelfAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

  <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">in_channels</span><span class="p">,</span>
               <span class="n">num_heads</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> 
               <span class="n">attn_p</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
               <span class="n">proj_p</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
               <span class="n">fused_attn</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>

    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="k">assert</span> <span class="n">in_channels</span> <span class="o">%</span> <span class="n">num_heads</span> <span class="o">==</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span> <span class="o">=</span> <span class="n">num_heads</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">in_channels</span> <span class="o">/</span> <span class="n">num_heads</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span> <span class="o">**</span> <span class="o">-</span><span class="mf">0.5</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fused_attn</span> <span class="o">=</span> <span class="n">fused_attn</span>  

    <span class="bp">self</span><span class="o">.</span><span class="n">qkv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">in_channels</span><span class="o">*</span><span class="mi">3</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">attn_p</span> <span class="o">=</span> <span class="n">attn_p</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">attn_drop</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">attn_p</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">proj_drop</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">proj_p</span><span class="p">)</span>

  <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">batch_size</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">embed_dim</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
      
    <span class="n">qkv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qkv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span><span class="p">)</span>
    <span class="n">qkv</span> <span class="o">=</span> <span class="n">qkv</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>
    <span class="n">q</span><span class="p">,</span><span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="o">=</span> <span class="n">qkv</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fused_attn</span><span class="p">:</span>
      <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">scaled_dot_product_attention</span><span class="p">(</span><span class="n">q</span><span class="p">,</span><span class="n">k</span><span class="p">,</span><span class="n">v</span><span class="p">,</span> <span class="n">dropout_p</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">attn_p</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">attn</span> <span class="o">=</span> <span class="p">(</span><span class="n">q</span> <span class="o">@</span> <span class="n">k</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span>
      <span class="n">attn</span> <span class="o">=</span> <span class="n">attn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
      <span class="n">attn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn_drop</span><span class="p">(</span><span class="n">attn</span><span class="p">)</span>
      <span class="n">x</span> <span class="o">=</span> <span class="n">attn</span> <span class="o">@</span> <span class="n">v</span>
    
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">proj</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">proj_drop</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">x</span>

<span class="k">class</span><span class="w"> </span><span class="nc">MLP</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                 <span class="n">in_channels</span><span class="p">,</span>
                 <span class="n">mlp_ratio</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> 
                 <span class="n">act_layer</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">,</span>
                 <span class="n">mlp_p</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">hidden_features</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">in_channels</span> <span class="o">*</span> <span class="n">mlp_ratio</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">hidden_features</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">act</span> <span class="o">=</span> <span class="n">act_layer</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">drop1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">mlp_p</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_features</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">drop2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">mlp_p</span><span class="p">)</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">act</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
        
<span class="k">class</span><span class="w"> </span><span class="nc">TransformerBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">in_channels</span><span class="p">,</span>
                 <span class="n">fused_attention</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">num_heads</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> 
                 <span class="n">mlp_ratio</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                 <span class="n">proj_p</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                 <span class="n">attn_p</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                 <span class="n">mlp_p</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                 <span class="n">act_layer</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">,</span>
                 <span class="n">norm_layer</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">):</span>
        
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span> <span class="o">=</span> <span class="n">norm_layer</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">SelfAttention</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span>
                                  <span class="n">num_heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span> 
                                  <span class="n">attn_p</span><span class="o">=</span><span class="n">attn_p</span><span class="p">,</span>
                                  <span class="n">proj_p</span><span class="o">=</span><span class="n">proj_p</span><span class="p">,</span>
                                  <span class="n">fused_attn</span><span class="o">=</span><span class="n">fused_attention</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span> <span class="o">=</span> <span class="n">norm_layer</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span>
                       <span class="n">mlp_ratio</span><span class="o">=</span><span class="n">mlp_ratio</span><span class="p">,</span>
                       <span class="n">act_layer</span><span class="o">=</span><span class="n">act_layer</span><span class="p">,</span>
                       <span class="n">mlp_p</span><span class="o">=</span><span class="n">mlp_p</span><span class="p">)</span>
        
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">batch_size</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
      
        <span class="c1">### Reshape to batch_size x (height*width) x channels</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">height</span><span class="o">*</span><span class="n">width</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">norm1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">norm2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="n">rand_img</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span><span class="mi">64</span><span class="p">)</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">TransformerBlock</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="n">t</span><span class="p">(</span><span class="n">rand_img</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([4, 32, 64, 64])
</pre></div>
</div>
</div>
</div>
</section>
<section id="span-style-color-lightpink-sinusoidal-time-embeddings-span">
<h4><span style="color:LightPink">Sinusoidal Time Embeddings</span><a class="headerlink" href="#span-style-color-lightpink-sinusoidal-time-embeddings-span" title="Permalink to this heading">#</a></h4>
<p>The model needs to have some idea of “time”. In this case, it will be, what timestep of noise am I at? To do so, we can directly use sinusoidal time embeddings proposed in the <a class="reference external" href="https://arxiv.org/pdf/1706.03762.pdf">Attention is all you need</a> paper. If you haven’t seen this before, here is a super high level overview. The formula for the embeddings is as follows:</p>
<div class="math notranslate nohighlight">
\[ \Large
PE_{position, 2i} = sin(\frac{position}{10000^{2i/d_{model}}})
\]</div>
<div class="math notranslate nohighlight">
\[ \Large
PE_{position, 2i+1} = cos(\frac{position}{10000^{2i+1/d_{model}}})
\]</div>
<p>The position in our case is the <span style="color:Violet">timestep</span> (for the 1000 timesteps of noise we want to have) and <span class="math notranslate nohighlight">\(d_{model}\)</span> is actually a hyperparameter in this case. If you remember back to Language models, we actually know <span class="math notranslate nohighlight">\(d_{model}\)</span> ahead of time, the length of the vectors we use to represent tokens. We do know it here, but the embedding depth will change, because if you again think about how typical Convolutional models work, as we go deeper into the model we will have <span style="color:Violet">more channels</span>. So at the beginning, we may only have 64 channels, so the <span class="math notranslate nohighlight">\(d_{model}\)</span> is 64, but later we may have 512 channels, so then the <span class="math notranslate nohighlight">\(d_{model}\)</span> is 512. Therefore we will create time embeddings for now for some given length <span class="math notranslate nohighlight">\(d_{model}\)</span>, and then expand as needed in the later architecture.</p>
<p>The index <span class="math notranslate nohighlight">\(i\)</span> refers to, which index are we are accessing in the <span class="math notranslate nohighlight">\(d_{model}\)</span>. Technically we should be interleaving <span class="math notranslate nohighlight">\(sin\)</span> and <span class="math notranslate nohighlight">\(cos\)</span> for every even and odd index (<span class="math notranslate nohighlight">\(2i\)</span> and <span class="math notranslate nohighlight">\(2i+1\)</span>), but experimentally I dont think it matters if we take all our our even sin values and then just concatenate all the odd cos values, so we will just do that to keep it easy.</p>
<p>We can then use linear layers to pick the length of these vectors, so we can pass in two hyperparameters <code class="docutils literal notranslate"><span class="pre">time_embed_dim</span></code>, which will be the initial dimension of our time embeddings and <code class="docutils literal notranslate"><span class="pre">scaled_time_embed_dim</span></code>, which will be the size of the projected time embed dim after some linear layers. We will also use the <span style="color:Violet">SiLU</span> activation function for no reason other than that’s what I’ve seen people use online!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">SinusoidalTimeEmbedding</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">time_embed_dim</span><span class="p">,</span> <span class="n">scaled_time_embed_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inv_freqs</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="mi">10000</span> <span class="o">**</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">time_embed_dim</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="n">time_embed_dim</span><span class="o">/</span><span class="mi">2</span><span class="p">))),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">time_mlp</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">time_embed_dim</span><span class="p">,</span> <span class="n">scaled_time_embed_dim</span><span class="p">),</span> 
                                      <span class="n">nn</span><span class="o">.</span><span class="n">SiLU</span><span class="p">(),</span> 
                                      <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">scaled_time_embed_dim</span><span class="p">,</span> <span class="n">scaled_time_embed_dim</span><span class="p">),</span> 
                                      <span class="n">nn</span><span class="o">.</span><span class="n">SiLU</span><span class="p">())</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">):</span>
        <span class="n">timestep_freqs</span> <span class="o">=</span> <span class="n">timesteps</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">inv_freqs</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">embeddings</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">timestep_freqs</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">timestep_freqs</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">time_mlp</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">embeddings</span>

<span class="n">s</span> <span class="o">=</span> <span class="n">SinusoidalTimeEmbedding</span><span class="p">(</span><span class="n">time_embed_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span><span class="n">scaled_time_embed_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span>
<span class="n">timesteps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
<span class="n">s</span><span class="p">(</span><span class="n">timesteps</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([3, 256])
</pre></div>
</div>
</div>
</div>
</section>
<section id="span-style-color-lightpink-unet-residual-blocks-upsample-blocks-span">
<h4><span style="color:LightPink">UNet, Residual Blocks, Upsample Blocks</span><a class="headerlink" href="#span-style-color-lightpink-unet-residual-blocks-upsample-blocks-span" title="Permalink to this heading">#</a></h4>
<p>Our implementation of UNets will be pretty similar to the UNet proposed except for one key difference:</p>
<p>In the original UNet, the upsampling (decoder) was done through a series of Transpose Convolutions. Transpose Convolutions are fine for image segmentation, but when it comes to image generation it can lead to a problem known as a checkerboard effect. You can see some cool examples of this <a class="reference external" href="https://distill.pub/2016/deconv-checkerboard/">here!</a>. At a high level, transpose conovolutions sometimes can overlap more in some areas of an image than another, do during generation, it will put more emphasis in specific locations of an image than other parts. This leads to darker or more saturated chunks in the image leading to the checkerboard pattern. In practice, using a simple Upsampling method like nearest neighbors or linear interpolation followed by a regular convolution works best so thats what we will do!</p>
<p>This implementation is also more for teaching, and we will be dynamically defining the structure of the model before building the layers so you can see how it comes together.</p>
<div>
<img src="https://raw.githubusercontent.com/illinois-mlp/MachineLearningForPhysics/main/img/Diffusion-Unet.png" width=1000></img>
</div><p><em><strong><span style="color:Violet">Sidenote</span></strong></em>: We will be utilizing a method known as GroupNorm in this archietcture.</p>
<div>
<img src="https://raw.githubusercontent.com/illinois-mlp/MachineLearningForPhysics/main/img/Diffusion-dl_normalizations.png" width=1000></img>
<p><a class="reference external" href="https://arxiv.org/pdf/1803.08494.pdf">source</a></p>
</div><p>Layernorm that we have been using for transformers normalize across all channels (in this case normalize across all channels of our image). Groupnorm will chunk across channels so each block of channels are normalized. This in practice gives better location specific normalization and can be used instead of layernorm or batchnorm.</p>
</section>
<section id="span-style-color-lightpink-lets-start-with-the-first-piece-residualblocks-span">
<h4><span style="color:LightPink">Lets Start with the first piece: ResidualBlocks</span><a class="headerlink" href="#span-style-color-lightpink-lets-start-with-the-first-piece-residualblocks-span" title="Permalink to this heading">#</a></h4>
<p>The <span style="color:Violet">ResidualBlock</span> will be a block of convolutions, normalizations and where we incorporate our time embeddings intot he model. The crucial part of our residual block is <span style="color:Violet">NO UPSAMPLING OR DOWNSAMPLING SHOULD OCCUR</span>. The shape of image (image shape and number of channels) that go into the ResidualBlock must come out identically! And you may be wondering, how do we incorporate time embeddigs? Time embeddings are a vector, but our image is a 3d tensor? Easy! We just reshape, broadcast and add it together! Lets just look at that piece first.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">4</span>

<span class="c1">### Create some random images with 64 channels, and size of 32 by 32 ###</span>
<span class="n">random_image</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Image Tensor&quot;</span><span class="p">,</span> <span class="n">random_image</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1">### Our random images have 64 channels, so our embeddings need to have a d_model of 64 ###</span>
<span class="n">random_time_embeddings</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Original Time Embeddings&quot;</span><span class="p">,</span> <span class="n">random_time_embeddings</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1">### To add together a (b, 64, 32, 32) with a (b, 64) we need to add some extra dimensions to our embeddings ###</span>
<span class="n">random_time_embeddings</span> <span class="o">=</span> <span class="n">random_time_embeddings</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Reshaped Time Embeddings&quot;</span><span class="p">,</span> <span class="n">random_time_embeddings</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1">## Add them together! ##</span>
<span class="n">timed_images</span> <span class="o">=</span> <span class="n">random_image</span> <span class="o">+</span> <span class="n">random_time_embeddings</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Output&quot;</span><span class="p">,</span> <span class="n">timed_images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Image Tensor torch.Size([4, 64, 32, 32])
Original Time Embeddings torch.Size([4, 64])
Reshaped Time Embeddings torch.Size([4, 64, 1, 1])
Output torch.Size([4, 64, 32, 32])
</pre></div>
</div>
</div>
</div>
<p>One thing to keep in mind though is, our random_time_embeddings had exactly the number of channels we needed. In our case, we need to make sure to resize the original output from our <code class="docutils literal notranslate"><span class="pre">SinusoidalTimeEmbeddings</span></code> to match our required channels. Lets put it together!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">ResidualBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">groupnorm_num_groups</span><span class="p">,</span> <span class="n">time_embed_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        
        <span class="c1">### Time Embedding Expansion to Out Channels ###</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">time_expand</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">time_embed_dim</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">)</span>

        <span class="c1">### Input Convolutions + GroupNorm ###</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">groupnorm_1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GroupNorm</span><span class="p">(</span><span class="n">groupnorm_num_groups</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv_1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">)</span>

        <span class="c1">### Input + Time Embedding Convolutions + GroupNorm ###</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">groupnorm_2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GroupNorm</span><span class="p">(</span><span class="n">groupnorm_num_groups</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv_2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">)</span>

        <span class="c1">### Residual Layer ###</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">residual_connection</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">in_channels</span> <span class="o">!=</span> <span class="n">out_channels</span> <span class="k">else</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">time_embeddings</span><span class="p">):</span>

        <span class="n">residual_connection</span> <span class="o">=</span> <span class="n">x</span>

        <span class="c1">### Time Expansion to Out Channels ###</span>
        <span class="n">time_embed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">time_expand</span><span class="p">(</span><span class="n">time_embeddings</span><span class="p">)</span>
        
        <span class="c1">### Input GroupNorm and Convolutions ###</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">groupnorm_1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">silu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1">### Add Time Embeddings ###</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">time_embed</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">*</span><span class="n">time_embed</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

        <span class="c1">### Group Norm and Conv Again! ###</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">groupnorm_2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">silu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1">### Add Residual and Return ###</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">residual_connection</span><span class="p">(</span><span class="n">residual_connection</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">x</span>
        
</pre></div>
</div>
</div>
</div>
</section>
<section id="span-style-color-lightpink-upsampling-span">
<h4><span style="color:LightPink">Upsampling</span><a class="headerlink" href="#span-style-color-lightpink-upsampling-span" title="Permalink to this heading">#</a></h4>
<p>The next step is easy. Like we had seen before, we just want to do a regular upsample using any type of interpolation by a factor of 2, and then use a convolutional layer afterwards that will return the same size as the upsampled image.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">UpSampleBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">upsample</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Upsample</span><span class="p">(</span><span class="n">scale_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="n">batch</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">upsampled</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">upsample</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="k">assert</span> <span class="p">(</span><span class="n">upsampled</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">height</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span> <span class="n">width</span><span class="o">*</span><span class="mi">2</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">upsampled</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="span-style-color-lightpink-building-the-unet-span">
<h4><span style="color:LightPink">Building the UNet</span><a class="headerlink" href="#span-style-color-lightpink-building-the-unet-span" title="Permalink to this heading">#</a></h4>
<p>This is probably the hardest part, especially for someone who hasn’t made a UNet before. Lets take it a piece at a time! The things we need to let our UNet know are:</p>
<ul class="simple">
<li><p><em><strong><span style="color:Violet">in_channels</span></strong></em>: How many input channels does our input image have? Probably 3 if RGB</p></li>
<li><p><em><strong><span style="color:Violet">start_dim</span></strong></em>: What is the starting dimension of the first convolution projection? There will be 3 channels into the first convolution, but how many channels do you want out? This should be 128 for a good model, but we will keep it 64 so its not too big and you can train it!</p></li>
<li><p><em><strong><span style="color:Violet">dim_mults</span></strong></em>: A tuple of expansion factors. For example if our start_dim is 64 and the dim_mults are (1,2,4), then the number of channels in the following conovlution blocks will be (64*1, 64*2, 64*4). Therefore our final output of the encoder will be 256. The decoder will also use the dim mults but in reverse order. Meaning it will start at 64*4 and work its way back to 64*1.</p></li>
<li><p><em><strong><span style="color:Violet">residual_blocks_per_group</span></strong></em>: After every down or upsample, we can repeat Residual blocks (which dont change any shape) multiple times to have more parameters in our model</p></li>
<li><p><em><strong><span style="color:Violet">time_embed_dim</span></strong></em>: What is the expected time embedding size from our SinusoidalTimeEmbeddings</p></li>
</ul>
</section>
<section id="span-style-color-lightpink-high-level-overview-of-some-of-the-specifics-of-the-unet-architecture-span">
<h4><span style="color:LightPink">High-level overview of some of the specifics of the UNet architecture</span><a class="headerlink" href="#span-style-color-lightpink-high-level-overview-of-some-of-the-specifics-of-the-unet-architecture-span" title="Permalink to this heading">#</a></h4>
<p>For this drawing, we will only use 1 residual blocks per group just to keep it simple!</p>
<div>
<img src="https://raw.githubusercontent.com/illinois-mlp/MachineLearningForPhysics/main/img/Diffusion-simple_UNet.png" width=1000></img>
</div><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">UNET</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">start_dim</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">dim_mults</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">residual_blocks_per_group</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">groupnorm_num_groups</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">time_embed_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1">#######################################</span>
        <span class="c1">### COMPUTE ALL OF THE CONVOLUTIONS ###</span>
        <span class="c1">#######################################</span>
        
        <span class="c1">### Store Number of Input channels from Original Image ###</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_image_channels</span> <span class="o">=</span> <span class="n">in_channels</span>
        
        <span class="c1">### Get Number of Channels at Each Block ###</span>
        <span class="n">channel_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="n">start_dim</span><span class="o">*</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">dim_mults</span><span class="p">]</span>
        <span class="n">starting_channel_size</span><span class="p">,</span> <span class="n">ending_channel_size</span> <span class="o">=</span> <span class="n">channel_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">channel_sizes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="c1">### Compute the Input/Output Channel Sizes for Every Convolution of Encoder ###</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder_config</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">channel_sizes</span><span class="p">):</span>
            <span class="c1">### For Every Channel Size add &quot;residual_blocks_per_group&quot; number of Residual Blocks that DONT Change the number of channels ###</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">residual_blocks_per_group</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">encoder_config</span><span class="o">.</span><span class="n">append</span><span class="p">(((</span><span class="n">d</span><span class="p">,</span> <span class="n">d</span><span class="p">),</span> <span class="s2">&quot;residual&quot;</span><span class="p">))</span> <span class="c1"># Shape: (Batch x Channels x Height x Width) -&gt; (Batch x Channels x Height x Width)</span>

            <span class="c1">### After Residual Blocks include Downsampling (by factor of 2) but dont change number of channels ###</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">encoder_config</span><span class="o">.</span><span class="n">append</span><span class="p">(((</span><span class="n">d</span><span class="p">,</span><span class="n">d</span><span class="p">),</span> <span class="s2">&quot;downsample&quot;</span><span class="p">))</span> <span class="c1"># Shape: (Batch x Channels x Height x Width) -&gt; (Batch x Channels x Height/2 x Width/2)</span>

            <span class="c1">### Compute Attention ###</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">encoder_config</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">d</span><span class="p">,</span> <span class="s2">&quot;attention&quot;</span><span class="p">))</span>
            
            <span class="c1">### If we are not at the last channel size include a channel upsample (typically by factor of 2) ###</span>
            <span class="k">if</span> <span class="n">idx</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">channel_sizes</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">encoder_config</span><span class="o">.</span><span class="n">append</span><span class="p">(((</span><span class="n">d</span><span class="p">,</span><span class="n">channel_sizes</span><span class="p">[</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="p">]),</span> <span class="s2">&quot;residual&quot;</span><span class="p">))</span> <span class="c1"># Shape: (Batch x Channels x Height x Width) -&gt; (Batch x Channels*2 x Height x Width)</span>
            
        <span class="c1">### The Bottleneck will have &quot;residual_blocks_per_group&quot; number of ResidualBlocks each with the input/output of our final channel size###</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bottleneck_config</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">residual_blocks_per_group</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bottleneck_config</span><span class="o">.</span><span class="n">append</span><span class="p">(((</span><span class="n">ending_channel_size</span><span class="p">,</span> <span class="n">ending_channel_size</span><span class="p">),</span> <span class="s2">&quot;residual&quot;</span><span class="p">))</span>

        <span class="c1">### Store a variable of the final Output Shape of our Encoder + Bottleneck so we can compute Decoder Shapes ###</span>
        <span class="n">out_dim</span> <span class="o">=</span> <span class="n">ending_channel_size</span>

        <span class="c1">### Reverse our Encoder config to compute the Decoder ###</span>
        <span class="n">reversed_encoder_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder_config</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="c1">### The output of our reversed encoder will be the number of channels added for residual connections ###</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder_config</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="p">(</span><span class="n">metadata</span><span class="p">,</span> <span class="nb">type</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">reversed_encoder_config</span><span class="p">):</span>
            <span class="c1">### Flip in_channels, out_channels with the previous out_dim added on ###</span>
            <span class="k">if</span> <span class="nb">type</span> <span class="o">!=</span> <span class="s2">&quot;attention&quot;</span><span class="p">:</span>
                <span class="n">enc_in_channels</span><span class="p">,</span> <span class="n">enc_out_channels</span> <span class="o">=</span> <span class="n">metadata</span>
            
                <span class="bp">self</span><span class="o">.</span><span class="n">decoder_config</span><span class="o">.</span><span class="n">append</span><span class="p">(((</span><span class="n">out_dim</span><span class="o">+</span><span class="n">enc_out_channels</span><span class="p">,</span> <span class="n">enc_in_channels</span><span class="p">),</span> <span class="s2">&quot;residual&quot;</span><span class="p">))</span>
                        
                <span class="k">if</span> <span class="nb">type</span> <span class="o">==</span> <span class="s2">&quot;downsample&quot;</span><span class="p">:</span>
                    <span class="c1">### If we did a downsample in our encoder, we need to upsample in our decoder ###</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">decoder_config</span><span class="o">.</span><span class="n">append</span><span class="p">(((</span><span class="n">enc_in_channels</span><span class="p">,</span> <span class="n">enc_in_channels</span><span class="p">),</span> <span class="s2">&quot;upsample&quot;</span><span class="p">))</span>
    
                <span class="c1">### The new out_dim will be the number of output channels from our block (or the cooresponding encoder input channels) ###</span>
                <span class="n">out_dim</span> <span class="o">=</span> <span class="n">enc_in_channels</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">in_channels</span> <span class="o">=</span> <span class="n">metadata</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">decoder_config</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">in_channels</span><span class="p">,</span> <span class="s2">&quot;attention&quot;</span><span class="p">))</span>

        <span class="c1">### Add Extra Residual Block for residual from input convolution ###</span>
        <span class="c1"># hint: We know that the initial convolution will have starting_channel_size</span>
        <span class="c1"># and the output of our decoder will also have starting_channel_size, so the</span>
        <span class="c1"># final ResidualBlock we need will need to go from starting_channel_size*2 to starting_channel_size</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">decoder_config</span><span class="o">.</span><span class="n">append</span><span class="p">(((</span><span class="n">starting_channel_size</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span> <span class="n">starting_channel_size</span><span class="p">),</span> <span class="s2">&quot;residual&quot;</span><span class="p">))</span>
        
        <span class="c1">#######################################</span>
        <span class="c1">### ACTUALLY BUILD THE CONVOLUTIONS ###</span>
        <span class="c1">#######################################</span>

        <span class="c1">### Intial Convolution Block ###</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv_in_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_image_channels</span><span class="p">,</span> 
                                      <span class="n">starting_channel_size</span><span class="p">,</span> 
                                      <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
                                      <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">metadata</span><span class="p">,</span> <span class="nb">type</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder_config</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">type</span> <span class="o">==</span> <span class="s2">&quot;residual&quot;</span><span class="p">:</span>
                <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span> <span class="o">=</span> <span class="n">metadata</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ResidualBlock</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span>
                                                  <span class="n">out_channels</span><span class="o">=</span><span class="n">out_channels</span><span class="p">,</span>
                                                  <span class="n">groupnorm_num_groups</span><span class="o">=</span><span class="n">groupnorm_num_groups</span><span class="p">,</span>
                                                  <span class="n">time_embed_dim</span><span class="o">=</span><span class="n">time_embed_dim</span><span class="p">))</span>
            <span class="k">elif</span> <span class="nb">type</span> <span class="o">==</span> <span class="s2">&quot;downsample&quot;</span><span class="p">:</span>
                <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span> <span class="o">=</span> <span class="n">metadata</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> 
                              <span class="n">out_channels</span><span class="p">,</span> 
                              <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
                              <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
                              <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                    <span class="p">)</span>
            <span class="k">elif</span> <span class="nb">type</span> <span class="o">==</span> <span class="s2">&quot;attention&quot;</span><span class="p">:</span>
                <span class="n">in_channels</span> <span class="o">=</span> <span class="n">metadata</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">TransformerBlock</span><span class="p">(</span><span class="n">in_channels</span><span class="p">))</span>

        
        <span class="c1">### Build Encoder Blocks ###</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bottleneck</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
        
        <span class="k">for</span> <span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">),</span> <span class="n">_</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">bottleneck_config</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bottleneck</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ResidualBlock</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span>
                                                 <span class="n">out_channels</span><span class="o">=</span><span class="n">out_channels</span><span class="p">,</span>
                                                 <span class="n">groupnorm_num_groups</span><span class="o">=</span><span class="n">groupnorm_num_groups</span><span class="p">,</span>
                                                 <span class="n">time_embed_dim</span><span class="o">=</span><span class="n">time_embed_dim</span><span class="p">))</span>

        <span class="c1">### Build Decoder Blocks ###</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">metadata</span><span class="p">,</span> <span class="nb">type</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_config</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">type</span> <span class="o">==</span> <span class="s2">&quot;residual&quot;</span><span class="p">:</span>
                <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span> <span class="o">=</span> <span class="n">metadata</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ResidualBlock</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span>
                                                  <span class="n">out_channels</span><span class="o">=</span><span class="n">out_channels</span><span class="p">,</span>
                                                  <span class="n">groupnorm_num_groups</span><span class="o">=</span><span class="n">groupnorm_num_groups</span><span class="p">,</span>
                                                  <span class="n">time_embed_dim</span><span class="o">=</span><span class="n">time_embed_dim</span><span class="p">))</span>
            <span class="k">elif</span> <span class="nb">type</span> <span class="o">==</span> <span class="s2">&quot;upsample&quot;</span><span class="p">:</span>
                <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span> <span class="o">=</span> <span class="n">metadata</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">UpSampleBlock</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span> 
                                                  <span class="n">out_channels</span><span class="o">=</span><span class="n">out_channels</span><span class="p">))</span>

            <span class="k">elif</span> <span class="nb">type</span> <span class="o">==</span> <span class="s2">&quot;attention&quot;</span><span class="p">:</span>
                <span class="n">in_channels</span> <span class="o">=</span> <span class="n">metadata</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">TransformerBlock</span><span class="p">(</span><span class="n">in_channels</span><span class="p">))</span>

        <span class="c1">### Output Convolution ###</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv_out_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">starting_channel_size</span><span class="p">,</span> 
                                       <span class="n">out_channels</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">input_image_channels</span><span class="p">,</span>
                                       <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
                                       <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">)</span>

        
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">time_embeddings</span><span class="p">):</span>
        <span class="n">residuals</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1">### Pass Through Projection and Store Residual ###</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_in_proj</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">residuals</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1">### Pass through encoder and store residuals ##</span>
        <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="p">(</span><span class="n">ResidualBlock</span><span class="p">)):</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">time_embeddings</span><span class="p">)</span>
                <span class="n">residuals</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">):</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                <span class="n">residuals</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1">### Pass Through BottleNeck ###</span>
        <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">bottleneck</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">time_embeddings</span><span class="p">)</span>

        <span class="c1">### Pass through Decoder while Concatenating Residuals ###</span>
        <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">ResidualBlock</span><span class="p">):</span>
                <span class="n">residual_tensor</span> <span class="o">=</span> <span class="n">residuals</span><span class="o">.</span><span class="n">pop</span><span class="p">()</span>
                <span class="n">x</span>  <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">residual_tensor</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">time_embeddings</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1">### Map back to num_channels for final output ###</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_out_proj</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">x</span>

<span class="n">m</span> <span class="o">=</span> <span class="n">UNET</span><span class="p">(</span><span class="n">start_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">dim_mults</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
<span class="n">rand_image</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<span class="n">rand_time_embeddings</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="n">rand_image</span><span class="p">,</span> <span class="n">rand_time_embeddings</span><span class="p">)</span>
<span class="n">out</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([4, 3, 256, 256])
</pre></div>
</div>
</div>
</div>
</section>
<section id="span-style-color-lightpink-putting-it-all-together-the-diffusion-model-span">
<h4><span style="color:LightPink">Putting it all together: The Diffusion Model</span><a class="headerlink" href="#span-style-color-lightpink-putting-it-all-together-the-diffusion-model-span" title="Permalink to this heading">#</a></h4>
<p>Lets stick together all the modules we have constructed to define our final Diffusion model!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">Diffusion</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                 <span class="n">in_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
                 <span class="n">start_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> 
                 <span class="n">dim_mults</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> 
                 <span class="n">residual_blocks_per_group</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                 <span class="n">groupnorm_num_groups</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> 
                 <span class="n">time_embed_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> 
                 <span class="n">time_embed_dim_ratio</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">in_channels</span> <span class="o">=</span> <span class="n">in_channels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">start_dim</span> <span class="o">=</span> <span class="n">start_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dim_mults</span> <span class="o">=</span> <span class="n">dim_mults</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">residual_blocks_per_group</span> <span class="o">=</span> <span class="n">residual_blocks_per_group</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">groupnorm_num_groups</span> <span class="o">=</span> <span class="n">groupnorm_num_groups</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">time_embed_dim</span> <span class="o">=</span> <span class="n">time_embed_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scaled_time_embed_dim</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">time_embed_dim</span> <span class="o">*</span> <span class="n">time_embed_dim_ratio</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">sinusoid_time_embeddings</span> <span class="o">=</span> <span class="n">SinusoidalTimeEmbedding</span><span class="p">(</span><span class="n">time_embed_dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">time_embed_dim</span><span class="p">,</span>
                                                                <span class="n">scaled_time_embed_dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scaled_time_embed_dim</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">unet</span> <span class="o">=</span> <span class="n">UNET</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span> 
                         <span class="n">start_dim</span><span class="o">=</span><span class="n">start_dim</span><span class="p">,</span> 
                         <span class="n">dim_mults</span><span class="o">=</span><span class="n">dim_mults</span><span class="p">,</span> 
                         <span class="n">residual_blocks_per_group</span><span class="o">=</span><span class="n">residual_blocks_per_group</span><span class="p">,</span> 
                         <span class="n">groupnorm_num_groups</span><span class="o">=</span><span class="n">groupnorm_num_groups</span><span class="p">,</span>  
                         <span class="n">time_embed_dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scaled_time_embed_dim</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">noisy_inputs</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">):</span>

        <span class="c1">### Embed the Timesteps ###</span>
        <span class="n">timestep_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sinusoid_time_embeddings</span><span class="p">(</span><span class="n">timesteps</span><span class="p">)</span>
        
        <span class="c1">### Pass Images + Time Embeddings through UNET ###</span>
        <span class="n">noise_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unet</span><span class="p">(</span><span class="n">noisy_inputs</span><span class="p">,</span> <span class="n">timestep_embeddings</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">noise_pred</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="span-style-color-lightpink-some-helper-functions-span">
<h4><span style="color:LightPink">Some Helper Functions</span><a class="headerlink" href="#span-style-color-lightpink-some-helper-functions-span" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="k">def</span><span class="w"> </span><span class="nf">sample_plot_image</span><span class="p">(</span><span class="n">step_idx</span><span class="p">,</span> 
                      <span class="n">total_timesteps</span><span class="p">,</span> 
                      <span class="n">sampler</span><span class="p">,</span> 
                      <span class="n">image_size</span><span class="p">,</span>
                      <span class="n">num_channels</span><span class="p">,</span>
                      <span class="n">plot_freq</span><span class="p">,</span> 
                      <span class="n">model</span><span class="p">,</span>
                      <span class="n">num_gens</span><span class="p">,</span>
                      <span class="n">path_to_generated_dir</span><span class="p">,</span>
                      <span class="n">device</span><span class="p">):</span>

    <span class="c1">### Conver Tensor back to Image (From Huggingface Annotated Diffusion) ###</span>
    <span class="n">tensor2image_transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="p">(</span><span class="n">t</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span> <span class="o">*</span> <span class="mf">255.</span><span class="p">),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">ToPILImage</span><span class="p">(),</span>
    <span class="p">])</span>

    <span class="n">images</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="n">num_gens</span><span class="p">,</span> <span class="n">num_channels</span><span class="p">,</span> <span class="n">image_size</span><span class="p">,</span> <span class="n">image_size</span><span class="p">))</span>
    <span class="n">num_images_per_gen</span> <span class="o">=</span> <span class="p">(</span><span class="n">total_timesteps</span> <span class="o">//</span> <span class="n">plot_freq</span><span class="p">)</span>

    <span class="n">images_to_vis</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_gens</span><span class="p">)]</span>
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">total_timesteps</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">ts</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="n">num_gens</span><span class="p">,</span> <span class="p">),</span> <span class="n">t</span><span class="p">)</span>
        <span class="n">noise_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">ts</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
        <span class="n">images</span> <span class="o">=</span> <span class="n">sampler</span><span class="o">.</span><span class="n">remove_noise</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">ts</span><span class="p">,</span> <span class="n">noise_pred</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">t</span> <span class="o">%</span> <span class="n">plot_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">image</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">images</span><span class="p">):</span>
                <span class="n">images_to_vis</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tensor2image_transform</span><span class="p">(</span><span class="n">image</span><span class="p">))</span>


    <span class="n">images_to_vis</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="n">images_to_vis</span><span class="p">))</span>

    <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="n">num_gens</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="n">num_images_per_gen</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="n">num_images_per_gen</span><span class="p">,</span> <span class="n">num_gens</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">image</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">images_to_vis</span><span class="p">):</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">wspace</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path_to_generated_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;step_</span><span class="si">{</span><span class="n">step_idx</span><span class="si">}</span><span class="s2">.png&quot;</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="span-style-color-lightpink-get-celeba-dataset-span">
<h4><span style="color:LightPink">Get CelebA dataset</span><a class="headerlink" href="#span-style-color-lightpink-get-celeba-dataset-span" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">wget_data</span><span class="p">(</span><span class="s1">&#39;https://courses.physics.illinois.edu/phys503/fa2023/data/celeba.tgz&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>File ‘./tmp_data/celeba.tgz’ already there; not retrieving.
</pre></div>
</div>
</div>
</div>
</section>
<section id="span-style-color-lightpink-untar-celeba-dataset-span">
<h4><span style="color:LightPink">Untar CelebA dataset</span><a class="headerlink" href="#span-style-color-lightpink-untar-celeba-dataset-span" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">subprocess</span><span class="o">.</span><span class="n">call</span><span class="p">(</span> <span class="p">[</span><span class="s1">&#39;/usr/bin/pwd&#39;</span><span class="p">])</span>
<span class="n">subprocess</span><span class="o">.</span><span class="n">call</span><span class="p">(</span> <span class="p">[</span><span class="s1">&#39;tar&#39;</span><span class="p">,</span><span class="s1">&#39;zxvpf&#39;</span><span class="p">,</span> <span class="s1">&#39;./tmp_data/celeba.tgz&#39;</span><span class="p">,</span> <span class="s1">&#39;--exclude=._*&#39;</span><span class="p">]</span> <span class="p">)</span>
<span class="n">subprocess</span><span class="o">.</span><span class="n">call</span><span class="p">(</span> <span class="p">[</span><span class="s1">&#39;mv&#39;</span><span class="p">,</span> <span class="s1">&#39;./celeba&#39;</span><span class="p">,</span> <span class="s1">&#39;./tmp_data/&#39;</span><span class="p">]</span> <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="span-style-color-lightpink-train-function-span">
<h4><span style="color:LightPink">Train Function</span><a class="headerlink" href="#span-style-color-lightpink-train-function-span" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="n">image_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> 
        <span class="n">evaluation_interval</span><span class="o">=</span><span class="mi">3750</span><span class="p">,</span>
          <span class="n">total_timesteps</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> 
          <span class="n">plot_freq_interval</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> 
          <span class="n">num_generations</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> 
          <span class="n">num_training_steps</span><span class="o">=</span><span class="mi">75000</span><span class="p">,</span> 
          <span class="n">num_input_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
          <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
          <span class="n">path_to_generated</span><span class="o">=</span><span class="s2">&quot;./tmp_data&quot;</span><span class="p">):</span> 
    
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>
        
    <span class="c1">### Define Basic Image Transformations (From Huggingface Annotated Diffusion) ###</span>
    <span class="n">image2tensor</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
                    <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">((</span><span class="n">image_size</span><span class="p">,</span> <span class="n">image_size</span><span class="p">)),</span>
                    <span class="n">transforms</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(),</span>
                    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> 
                    <span class="n">transforms</span><span class="o">.</span><span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="p">(</span><span class="n">t</span><span class="o">*</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
                <span class="p">])</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">ImageFolder</span><span class="p">(</span><span class="s1">&#39;./tmp_data/celeba&#39;</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">image2tensor</span><span class="p">)</span>
    <span class="n">trainloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> 
                             <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                             <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                             <span class="n">num_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
<span class="c1">#                             num_workers=0,</span>
                            <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">Diffusion</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">num_input_channels</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="n">model_parameters</span> <span class="o">=</span> <span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
    <span class="n">params</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">size</span><span class="p">())</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model_parameters</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of Parameters:&quot;</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>

    <span class="c1">### MODEL TRAINING INPUTS ###</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.0005</span><span class="p">)</span>
    <span class="n">scheduler</span> <span class="o">=</span> <span class="n">get_cosine_schedule_with_warmup</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> 
                                                <span class="n">num_warmup_steps</span><span class="o">=</span><span class="mi">2500</span><span class="p">,</span> 
                                                <span class="n">num_training_steps</span><span class="o">=</span><span class="n">num_training_steps</span><span class="p">)</span>

    <span class="n">ddpm_sampler</span> <span class="o">=</span> <span class="n">Sampler</span><span class="p">(</span><span class="n">num_training_steps</span><span class="o">=</span><span class="n">total_timesteps</span><span class="p">)</span>

    <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>

    <span class="n">progress_bar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_training_steps</span><span class="p">))</span>
    <span class="n">completed_steps</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">train</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">while</span> <span class="n">train</span><span class="p">:</span>
        <span class="n">training_losses</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">trainloader</span><span class="p">:</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        
            <span class="c1">### Random Sample T ###</span>
            <span class="n">timesteps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">total_timesteps</span><span class="p">,(</span><span class="n">batch_size</span><span class="p">,))</span>
        
            <span class="c1">### Get Noisy Images ###</span>
            <span class="n">noisy_images</span><span class="p">,</span> <span class="n">noise</span> <span class="o">=</span> <span class="n">ddpm_sampler</span><span class="o">.</span><span class="n">add_noise</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">)</span>
        
            <span class="c1">### Get Noise Prediction ###</span>
            <span class="n">noise_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">noisy_images</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">timesteps</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>

            <span class="c1">### Compute Error ###</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">noise_pred</span><span class="p">,</span> <span class="n">noise</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>

            <span class="n">training_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="mf">1.0</span><span class="p">)</span>

            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="n">progress_bar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">completed_steps</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="k">if</span> <span class="p">(</span><span class="n">completed_steps</span> <span class="o">%</span> <span class="n">evaluation_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
                <span class="n">loss_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">training_losses</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training Loss:&quot;</span><span class="p">,</span> <span class="n">loss_mean</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Learning Rate:&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="s2">&quot;lr&quot;</span><span class="p">])</span>

                <span class="n">training_losses</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Saving Image Generation&quot;</span><span class="p">)</span>
                <span class="n">sample_plot_image</span><span class="p">(</span><span class="n">step_idx</span><span class="o">=</span><span class="n">completed_steps</span><span class="p">,</span> 
                                  <span class="n">total_timesteps</span><span class="o">=</span><span class="n">total_timesteps</span><span class="p">,</span> 
                                  <span class="n">sampler</span><span class="o">=</span><span class="n">ddpm_sampler</span><span class="p">,</span> 
                                  <span class="n">image_size</span><span class="o">=</span><span class="n">image_size</span><span class="p">,</span>
                                  <span class="n">num_channels</span><span class="o">=</span><span class="n">num_input_channels</span><span class="p">,</span>
                                  <span class="n">plot_freq</span><span class="o">=</span><span class="n">plot_freq_interval</span><span class="p">,</span> 
                                  <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
                                  <span class="n">num_gens</span><span class="o">=</span><span class="n">num_generations</span><span class="p">,</span>
                                  <span class="n">path_to_generated_dir</span><span class="o">=</span><span class="n">path_to_generated</span><span class="p">,</span>
                                  <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
                
            <span class="k">if</span> <span class="n">completed_steps</span> <span class="o">&gt;=</span> <span class="n">num_training_steps</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training Completed!!!&quot;</span><span class="p">)</span>
                <span class="n">train</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="k">break</span>
<span class="n">train</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of Parameters: 52956419
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "46863b91a5164c408cb3cecf5774e6d1", "version_major": 2, "version_minor": 0}</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training Loss: 0.027614978325476693
Learning Rate: 0.0004996333534627809
Saving Image Generation
</pre></div>
</div>
<img alt="../../_images/ff41ffac63aa22577dd837f196d252226fa5d6f5bf8213e54daf55f6372c6c17.png" src="../../_images/ff41ffac63aa22577dd837f196d252226fa5d6f5bf8213e54daf55f6372c6c17.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training Loss: 0.025593497773651545
Learning Rate: 0.0004941551389275216
Saving Image Generation
</pre></div>
</div>
<img alt="../../_images/e0b69b0d6a70fca2a8b619fdc6db6de9bc9ffc508fbcebb5b61a43b787de13a2.png" src="../../_images/e0b69b0d6a70fca2a8b619fdc6db6de9bc9ffc508fbcebb5b61a43b787de13a2.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training Loss: 0.025227434365461543
Learning Rate: 0.0004822441799541979
Saving Image Generation
</pre></div>
</div>
<img alt="../../_images/1e8a13fcc3751b52a433bd5fc5d136b0b31618fd0d3c7584e2830e384123e91e.png" src="../../_images/1e8a13fcc3751b52a433bd5fc5d136b0b31618fd0d3c7584e2830e384123e91e.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training Loss: 0.024866870749177258
Learning Rate: 0.0004642142940418973
Saving Image Generation
</pre></div>
</div>
<img alt="../../_images/5e5edb216f6220d6d1e016a89ede0cc5f5109c6324edfddde4c2338ef904dcb4.png" src="../../_images/5e5edb216f6220d6d1e016a89ede0cc5f5109c6324edfddde4c2338ef904dcb4.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training Loss: 0.024508819502956962
Learning Rate: 0.0004405405137819091
Saving Image Generation
</pre></div>
</div>
<img alt="../../_images/c8c903ef6d598e83bb42f164b6ffdd7caae6ad1851230c24230e68fb3211e83a.png" src="../../_images/c8c903ef6d598e83bb42f164b6ffdd7caae6ad1851230c24230e68fb3211e83a.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training Loss: 0.02422389824263002
Learning Rate: 0.00041184657119545693
Saving Image Generation
</pre></div>
</div>
<img alt="../../_images/50aedc8104b12c41be5f591efe347333fab005e7d2dba51d41aea46efa18cf5b.png" src="../../_images/50aedc8104b12c41be5f591efe347333fab005e7d2dba51d41aea46efa18cf5b.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training Loss: 0.023754292109136727
Learning Rate: 0.00037888846429425546
Saving Image Generation
</pre></div>
</div>
<img alt="../../_images/7a1fd77f3df1b81462b68773e8e6d30ac0368b5598fedba375b9d10e6a9ba811.png" src="../../_images/7a1fd77f3df1b81462b68773e8e6d30ac0368b5598fedba375b9d10e6a9ba811.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training Loss: 0.023777675831005235
Learning Rate: 0.00034253453883497867
Saving Image Generation
</pre></div>
</div>
<img alt="../../_images/f70691fa0a01c34fe57f1194b5d5bd3c85811ce7da25eba9fa9ef6cef0e5366c.png" src="../../_images/f70691fa0a01c34fe57f1194b5d5bd3c85811ce7da25eba9fa9ef6cef0e5366c.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training Loss: 0.023423723777551114
Learning Rate: 0.00030374261005275605
Saving Image Generation
</pre></div>
</div>
<img alt="../../_images/44d76c4737cd3e49433ea58633ce0e0ee6540d0563a0c9c5627e7f6bf007f192.png" src="../../_images/44d76c4737cd3e49433ea58633ce0e0ee6540d0563a0c9c5627e7f6bf007f192.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training Loss: 0.023408989196680847
Learning Rate: 0.0002635347271463544
Saving Image Generation
</pre></div>
</div>
<img alt="../../_images/a580cb768b8a775a0c40c9ed72641141e6f500ad515a155cbdf4453148ad060a.png" src="../../_images/a580cb768b8a775a0c40c9ed72641141e6f500ad515a155cbdf4453148ad060a.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training Loss: 0.02353073466245247
Learning Rate: 0.0002229702453940146
Saving Image Generation
</pre></div>
</div>
<img alt="../../_images/2c36905e6dd32660501a9349017cf30b0ee6625aeab4b0c5275d73185822450c.png" src="../../_images/2c36905e6dd32660501a9349017cf30b0ee6625aeab4b0c5275d73185822450c.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training Loss: 0.022872181113302355
Learning Rate: 0.00018311791536769484
Saving Image Generation
</pre></div>
</div>
<img alt="../../_images/710fb0613f5b55003fa36b2966860db0bc281e5785e7aa2fe03d15cbfbd782f9.png" src="../../_images/710fb0613f5b55003fa36b2966860db0bc281e5785e7aa2fe03d15cbfbd782f9.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training Loss: 0.022874412042576644
Learning Rate: 0.00014502772460993384
Saving Image Generation
</pre></div>
</div>
<img alt="../../_images/ef5ff19642d531281aa2fba471c6a9ebe0f7076b857abaf36f9322f203a87526.png" src="../../_images/ef5ff19642d531281aa2fba471c6a9ebe0f7076b857abaf36f9322f203a87526.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training Loss: 0.022812383052935408
Learning Rate: 0.00010970323365940444
Saving Image Generation
</pre></div>
</div>
<img alt="../../_images/865f65895acb03b4959e706b41655073df77789667dd7b0a3290ca4084ba1045.png" src="../../_images/865f65895acb03b4959e706b41655073df77789667dd7b0a3290ca4084ba1045.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training Loss: 0.022587639776394507
Learning Rate: 7.807513528664414e-05
Saving Image Generation
</pre></div>
</div>
<img alt="../../_images/e303cfc405670e99c0eaf52529288d3e3d9141fc3f8da5712b52a6d58e447ff4.png" src="../../_images/e303cfc405670e99c0eaf52529288d3e3d9141fc3f8da5712b52a6d58e447ff4.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training Loss: 0.022739307398649346
Learning Rate: 5.097673357358906e-05
Saving Image Generation
</pre></div>
</div>
<img alt="../../_images/080e1bb6d74a1881ad2a10a528bf3762e339e792fa7c14ca8f19e1fe14f9a6fa.png" src="../../_images/080e1bb6d74a1881ad2a10a528bf3762e339e792fa7c14ca8f19e1fe14f9a6fa.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training Loss: 0.0229581450047188
Learning Rate: 2.9121988888494292e-05
Saving Image Generation
</pre></div>
</div>
<img alt="../../_images/911b1360eb5ac6b02eb247d22ab3a8e19c61a759237aa2ebffe59579dace8ac9.png" src="../../_images/911b1360eb5ac6b02eb247d22ab3a8e19c61a759237aa2ebffe59579dace8ac9.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training Loss: 0.02254007502479196
Learning Rate: 1.3086707204299414e-05
Saving Image Generation
</pre></div>
</div>
<img alt="../../_images/81a4c492c0e4811ee6346896f13e05aa76563d3e63562739440054316a9a4270.png" src="../../_images/81a4c492c0e4811ee6346896f13e05aa76563d3e63562739440054316a9a4270.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training Loss: 0.02248887126526337
Learning Rate: 3.293369364618465e-06
Saving Image Generation
</pre></div>
</div>
<img alt="../../_images/e5799c3845ac8c1e72bbdab4ef4eb52912a501c232c7eeb9e12a0c51e38a50c8.png" src="../../_images/e5799c3845ac8c1e72bbdab4ef4eb52912a501c232c7eeb9e12a0c51e38a50c8.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training Loss: 0.022647713878687973
Learning Rate: 0.0
Saving Image Generation
</pre></div>
</div>
<img alt="../../_images/63d444deae24ad5eed1e6ed3c59f63159c0da3c9e21e7e4274356993e71ef6c3.png" src="../../_images/63d444deae24ad5eed1e6ed3c59f63159c0da3c9e21e7e4274356993e71ef6c3.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training Completed!!!
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="span-style-color-orange-acknowledgments-span">
<h2><span style="color:Orange">Acknowledgments</span><a class="headerlink" href="#span-style-color-orange-acknowledgments-span" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Initial version: Mark Neubauer</p>
<ul>
<li><p>Modified from the following <a class="reference external" href="https://github.com/priyammaz/PyTorch-Adventures/blob/main/PyTorch%20for%20Generation/Diffusion/Intro%20to%20Diffusion/Diffusion.ipynb">tutorial</a></p></li>
</ul>
</li>
</ul>
<p>© Copyright 2025</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./_sources/lectures"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="GenerativeAdversarialNetworks.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Generative Adversarial Networks</p>
      </div>
    </a>
    <a class="right-next"
       href="NormalizingFlows.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Normalizing Flows</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-diffusion-intuition-span"><span style="color:Orange">Diffusion Intuition</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-a-mathematical-overview-to-understand-diffusion-span"><span style="color:Orange">A Mathematical Overview to Understand Diffusion</span></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-forward-diffusion-span"><span style="color:LightGreen">Forward Diffusion</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-linear-scheduler-span"><span style="color:LightGreen">Linear Scheduler</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-alpha-computation-span"><span style="color:LightGreen">Alpha Computation</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-backward-diffusion-span"><span style="color:LightGreen">Backward Diffusion</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-how-do-we-learn-this-span"><span style="color:LightGreen">How do we learn this?</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-define-sampler-span"><span style="color:LightGreen">Define Sampler</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-lets-test-our-scheduler-span"><span style="color:LightGreen">Lets Test our Scheduler</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-define-model-span"><span style="color:LightGreen">Define Model</span></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-selfattention-mlp-and-transformerblock-span"><span style="color:LightPink">SelfAttention, MLP, and TransformerBlock</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-sinusoidal-time-embeddings-span"><span style="color:LightPink">Sinusoidal Time Embeddings</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-unet-residual-blocks-upsample-blocks-span"><span style="color:LightPink">UNet, Residual Blocks, Upsample Blocks</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-lets-start-with-the-first-piece-residualblocks-span"><span style="color:LightPink">Lets Start with the first piece: ResidualBlocks</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-upsampling-span"><span style="color:LightPink">Upsampling</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-building-the-unet-span"><span style="color:LightPink">Building the UNet</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-high-level-overview-of-some-of-the-specifics-of-the-unet-architecture-span"><span style="color:LightPink">High-level overview of some of the specifics of the UNet architecture</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-putting-it-all-together-the-diffusion-model-span"><span style="color:LightPink">Putting it all together: The Diffusion Model</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-some-helper-functions-span"><span style="color:LightPink">Some Helper Functions</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-get-celeba-dataset-span"><span style="color:LightPink">Get CelebA dataset</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-untar-celeba-dataset-span"><span style="color:LightPink">Untar CelebA dataset</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightpink-train-function-span"><span style="color:LightPink">Train Function</span></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-acknowledgments-span"><span style="color:Orange">Acknowledgments</span></a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Mark Neubauer
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>